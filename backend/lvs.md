# [Linux Virtual Server LVS](http://www.linuxvirtualserver.org/index.html)

* 基于第四层传输层来做流量分发方案，负载均衡工作在传输层，对数据包中的IP地址和端口进行修改，从而达到转发的目的，支持 TCP/UDP 负载均衡
* LVS在Linux内核态获取到IP报文后，根据特定负载均衡算法将IP报文转发到整个集群的某台服务器中去
* 服务器集群系统组成：
  - 最前端负载均衡层 Load Balancer
    + 服务器群集系统的单个入口点，可运行 IPVS，该 IPVS 在 Linux 内核或 KTCPVS 内部实现 IP 负载均衡技术，在 Linux 内核中实现应用程序级负载平衡。
    + 使用 IPVS 时，要求所有服务器提供相同的服务和内容，负载均衡器根据指定的调度算法和每个服务器的负载将新的客户端请求转发到服务器。
    + 无论选择哪个服务器，客户端都应获得相同的结果。使用 KTCPVS 时，服务器可以具有不同的内容，负载均衡器可以根据请求的内容将请求转发到其他服务器。
    + 由于 KTCPVS 是在 Linux 内核内部实现的，因此中继数据的开销很小，因此仍可以具有较高的吞吐量。
  - 中间服务器集群层 Server Array|pool
    + 每个节点具有独立的真实 IP 地址，只处理调度器分发过来的客户机请求
    + 节点可根据系统所承受的负载进行分担。当所有服务器过载时，可添加多台服务器来处理不断增加的工作负载.随着服务器群集的节点数增加，整体性能几乎可以线性扩展
  - 最底端数据共享存储层 Shared Storage
    + 为服务器池中的所有节点提供稳定、一致的文件存储服务，确保整个群集的统一性，可使用 NAS 设备或提供 NFS （Network File System）网络文件系统共享服务的专用服务器。
    + 可以是数据库系统，网络文件系统或分布式文件系统。
    + 服务器节点需要动态更新的数据应存储在基于数据的系统中，当服务器节点并行在数据库系统中读写数据时，数据库系统可以保证并发数据访问的一致性。
    + 静态数据通常保存在网络文件系统（例如 NFS 和 CIFS）中，以便可以由所有服务器节点共享数据
    + 单个网络文件系统的可伸缩性受到限制，例如，单个 NFS / CIFS 只能支持 4 到 8 个服务器的数据访问。
    + 对于大型集群系统，分布式/集群文件系统可以用于共享存储，例如 GPFS，Coda 和 GFS，然后共享存储也可以根据系统需求进行扩展。
* 原理
  - netfilter 基本原理
    + LVS 是基于 Linux 内核中 netfilter 框架实现的负载均衡系统
    + 平时说的 Linux 防火墙就是 netfilter,iptables 和 netfilter 是 Linux 防火墙组合工具，是一起来完成系统防护工作的
    + iptables 是位于用户空间，而 Netfilter 是位于内核空间。iptables 只是用户空间编写和传递规则的工具而已，真正工作的还是 netfilter
    + 区别
      * Netfilter 是内核态的 Linux 防火墙机制，它作为一个通用、抽象的框架，提供了一整套的 hook 函数管理机制，提供数据包过滤、网络地址转换、基于协议类型的连接跟踪的功能，可在数据包流经过程中，根据规则设置若干个关卡（hook 函数）来执行相关操作，共设置了 5 个点，包括：PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUTING。
        - prerouting： 在对数据包做路由选择之前，将应用此链中的规则；
        - input： 当收到访问防火墙本机地址的数据包时，将应用此链中的规则；
        - forward： 当收到需要通过防火中转发给其他地址的数据包时，将应用此链中的规则；
        - output： 当防火墙本机向外发送数据包时，将应用此链中的规则；
        - postrouting： 在对数据包做路由选择之后，将应用此链中的规则；
      * iptable 是用户层的工具，提供命令行接口，能够向 Netfilter 中添加规则策略，从而实现报文过滤，修改等功能
  - LVS 基于 netfilter 框架，工作在 INPUT 链上，在 INPUT 链上注册 ip_vs_in HOOK 函数，进行 IPVS 相关主流程
    + IPVS 工作在 INPUT 链上，会根据访问的VIP和端口判断请求是否为 IPVS 服务，是的情况下，则调用注册的IPVS HOOK 函数，进行IPVS相关流程，并强制修改数据包的相关数据，并将数据包发往POSTROUTING链中
    + POSTROUTING链收到数据包后，将根据目标 IP 地址服务器，通过路由选路，将数据包最终发送至后端真实服务器中
* 特点
  * 基于 4 层的网络协议的，抗负载能力强，对于服务器的硬件要求除了网卡外，其他没有太多要求
  * 配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，大大减少了人为出错的几率
  * 应用范围比较广，不仅仅对 web 服务做负载均衡，还可以对其他应用（mysql）做负载均衡
  * LVS 架构中存在一个虚拟 IP 的概念，需要向 IDC 多申请一个 IP 来做虚拟 IP

+ 组成
  ipvs(ip virtual server)：LVS 是基于内核态的 netfilter 框架实现的 IPVS 功能，工作在内核态。用户配置 VIP 等相关信息并传递到 IPVS 就需要用到 ipvsadm 工具。
  - ipvsadm：ipvsadm 是 LVS 用户态的配套工具，可以实现 VIP 和 RS 的增删改查功能，是基于 netlink 或 raw socket 方式与内核 LVS 进行通信的，如果 LVS 类比于 netfilter，那 ipvsadm 就是类似 iptables 工具的地位

* 转发主要通过修改 IP 地址（NAT 模式，分为源地址修改 SNAT 和目标地址修改 DNAT）
  - NAT Network Address Translatio 是一种外网和内网地址映射的技术
    + 客户端发出的请求数据包经过网络到达 LVS 网卡，数据包源 IP 为 CIP，目的 IP 为 VIP
    + 进入 PREROUTING 链中，根据目的 IP 查找路由，确定是否为本机 IP 地址，随后将数据包转发至 INPUT 链中，源 IP 和 目的 IP 不变
    + 到达 LVS 后，通过目的 IP 和目的 PORT 查找是否为 IPVS 服务，如是 IPVS 服务，将会选择一个 RS 来作为后端服务器(目标地址转换 DNAT)，数据包的目的 IP 地址将会修改为 RIP，这时并以 RIP 为目的 IP 去查找路由，确定下一跳及 PORT 信息后，数据包将会转发至 OUTPUT 链中
    + 被修改过的数据包经过 POSTROUTING 链后，到达 RS 服务器，数据包源 IP 为 CIP，目的 IP 为 RIP
    + RS 服务器经过处理后，将会把数据包发送至用户空间的应用程序，待处理完成后，发送响应数据包，RS 服务器的默认网关为 LVS 的 IP，应用程序将会把数据包转发至下一跳 LVS 服务器，数据包源 IP 为 RIP，目的 IP 为 CIP
    + LVS 服务器收到 RS 服务器响应的数据包后，查找路由，目的 IP 不是本机并且 LVS 服务器开启了 FORWARD 模式，会将数据包转发给它，数据包不变
    + LVS 服务器收到响应数据包后，根据目的 IP 和 目的 PORT 查找相应的服务，这时，源 IP 为 VIP(源地址转换 SNAT），通过查找路由，确定下一跳信息并将数据包发送至网关，最终回应给客户端用户

    + NAT服务器（前端服务器）必须作为实际服务器（后端服务器）的网关，否则数据包被转发后将一去不返
    + 从Linux2.4内核开始，内置Neftilter模块在内核中维护着一些数据包过滤表，这些表包含了用于控制数据包过滤的规则
    + Linux提供了iptables来对过滤表进行插入、修改和删除等操作
    + Linux2.6.x内核中内置了IPVS模块，工作性质类型于Netfilter模块，不过更专注于实现IP负载均衡
    + `modprobe -l  | grep ipvs` 管理工具是ipvsadm
      * `ipvsadm -A -t 111.11.11.11:80 -s rr`: 添加一台虚拟服务器，-t 后面是服务器的外网ip和端口，-s rr是指采用简单轮询的RR调度策略
      * `ipvsadm -a -t 111.11.11.11:80 -r 10.10.120.210:8000 -m`  -r后面是实际服务器的内网ip和端口，-m表示采用NAT方式来转发数据包
    + 作为调度器的NAT服务器可以将吞吐率提升到一个新的高度，几乎是反向代理服务器的两倍以上，这大多归功于在内核中进行请求转发的较低开销。
    + 优点：
      * 支持 Windows 操作系统；
      * 支持端口映射，如 RS 服务器 PORT 与 VPORT 不一致的话，LVS 会修改目的 IP 地址和 DPORT 以支持端口映射；
    + 缺点：
      * RS 服务器需配置网关；
      * 双向流量对 LVS 会产生较大的负载压力
    + 瓶颈:NAT服务器的网络带宽，包括内部网络和外部网络- 网络地址转换(NAT)
  - 直接路由：Direct Routing DR:需要 LVS 和 RS 集群绑定同一个 VIP（RS 通过将 VIP 绑定在 loopback 实现），但与 NAT 的不同点在于：请求由 LVS 接受，由真实提供服务的服务器（RealServer，RS）直接返回给用户，返回的时候不经过 LVS
    + 与 TUN 模式的结构类似，但各节点并不是分散在各个地方，而是与调度器位于同一个物理网络，负载调度器与各节点服务器通过本地网络连接，不需要建立专用的 IP 隧道
    + 工作在数据链路层（第二层）,通过修改数据包的目标MAC地址（没有修改目标IP），将数据包转发到实际服务器上
    + 原理
      * 当客户端用户发送请求给 www.baidu.com 网站时，首先经过 DNS 解析到 IP 后并向百度服务器发送请求，数据包经过网络到百度 LVS 负载均衡服务器，这时到达 LVS 网卡时的数据包包括：源 IP 地址（客户端地址）、目的 IP 地址（百度对外服务器 IP 地址，也就是 VIP）、源 MAC 地址（CMAC / LVS 连接路由器的 MAC 地址）、目标 MAC 地址（VMAC / VIP 对应的 MAC 地址）。
      * 数据包到达网卡后，经过链路层到达 PREROUTING 链，进行查找路由，发现目的 IP 是 LVS 的 VIP，这时就会发送至 INPUT 链中并且数据包的 IP 地址、MAC 地址、Port 都未经过修改。
      * 数据包到达 INPUT 链中，LVS 会根据目的 IP 和 Port（端口）确认是否为 LVS 定义的服务，如是定义过的 VIP 服务，会根据配置的服务信息，从 RealServer 中选择一个后端服务器 RS1，然后 RS1 作为目标出方向的路由，确定下一跳信息及数据包通过具体的哪个网卡发出，最好将数据包通过       * 数据包通过 POSTROUTING 链后，目的 MAC 地址将会修改为 RealServer 服务器 MAC 地址（RMAC）源 MAC 地址修改为 LVS 与 RS 同网段的 IP 地址的 MAC 地址（DMAC）此时，数据包将会发至 RealServer 服务器。
      * 数据包到达 RealServer 服务器后，发现请求报文的 MAC 地址是自己的网卡 MAC 地址，将会接受此报文，待处理完成之后，将响应报文通过 lo 接口传送给 eth0 网卡然后向外发出。此时的源 IP 地址为 VIP，目标 IP 为 CIP，源 MAC 地址为 RS1 的 RMAC，目的 MAC 地址为下一跳路由器的 MAC 地址（CMAC），最终数据包通过 RS 相连的路由器转发给客户端。
    + 一个请求过来时，LVS 只需要将网络帧的 MAC 地址修改为某一台 RS 的 MAC，该包就会被转发到相应的 RS 处理，注意此时的源 IP 和目标 IP 都没变，LVS 只是做了一下移花接木。RS 收到 LVS 转发来的包时，链路层发现 MAC 是自己的，到上面的网络层，发现 IP 也是自己的，于是这个包被合法地接受，RS 感知不到前面有 LVS 的存在
    + 当 RS 返回响应时，只要直接向源 IP（即用户的 IP）返回即可，不再经过 LVS
    + 数据分发过程中不修改 IP 地址，只修改 mac 地址.由于实际处理请求的真实物理 IP 地址和数据请求目的 IP 地址一致，所以不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。因此，DR 模式具有较好的性能，也是目前大型网站使用最广泛的一种负载均衡手段。
    + 相较于LVS-NAT的最大优势在于LVS-DR不受调度器宽带的限制
    + 优点：
      - 响应数据不经过 LVS，性能高
      - 对数据包修改小，信息完整性好；
    + 缺点：
      - LVS 与 RS 必须在同一个物理网络；
      - RS 上必须配置 lo 和其他内核参数；
      - 不支持端口映射
  - LVS-TUN｜基于IP隧道的请求转发机制：将调度器收到的IP数据包封装在一个新IP数据包中，转交给实际服务器，然后实际服务器的响应数据包可以直接到达用户端
    + 与LVS-DR不同的是，实际服务器可以和调度器不在同一个WAN网段，调度器通过IP隧道技术来转发请求到实际服务器，所以实际服务器也必须拥有合法IP地址
    + 原理
      * 客户端发送数据包经过网络后到 LVS 网卡，数据包源 IP 为 CIP，目的 IP 为 VIP。
      * 进入 PREROUTING 链后，会根据目的 IP 去查找路由，确定是否为本机 IP，数据包将转发至 INPUT 链中，到 LVS，源 IP 和 目的 IP 不变。
      * 到 LVS 后，通过目的 IP 和目的 PORT 查找是否为 IPVS 服务，如是 IPVS 服务，将会选择一个 RS 后端服务器， 源 IP 为 DIP，目标 IP 为 RIP，数据包将会转发至 OUTPUT 链中。
      * 数据包根据路由信息到达 LVS 网卡，发送至路由器网关，最终到达后端服务器。
      * 后端服务器收到数据包后，会拆掉最外层的 IP 地址后，会发现还有一层 IP 首部，源 IP 为 CIP，目的 IP 为 VIP，TUNL0 上配置 VIP，查找路由后判断为本机 IP 地址，将会发给用户空间层的应用程序响应后 VIP 为源 IP，CIP 为目的 IP 数据包发送至网卡，最终返回至客户端用户。
    + 优点：
      * 单臂模式，LVS 负载压力小；
      * 数据包修改小，信息完整性高；
      * 可跨机房；
    + 缺点：
      * 不支持端口映射
      * 需在 RS 后端服务器安装模块及配置 VIP
      * 隧道头部 IP 地址固定，RS 后端服务器网卡可能会不均匀
      * 隧道头部的加入可能会导致分片，最终会影响服务器性能
    + 如对转发性要求较高且具有跨机房需求的，可选择 TUN 模式
  - LVS-DR和LVS-TUN都适合响应和请求不对称的Web服务器，如何从它们中做出选择，取决于你的网络部署需要，因为LVS-TUN可以将实际服务器根据需要部署在不同的地域，并且根据就近访问的原则来转移请求，所以有类似这种需求的，就应该选择LVS-TUN
* 优点
  - 抗负载能力强、是工作在传输层上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和 cpu 资源消耗比较低
  - 配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率
  - 工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如 LVS + Keepalived
  - 无流量，LVS 只分发请求，而流量并不从它本身出去，这点保证了均衡器 IO 的性能不会受到大流量的影响
  - 应用范围比较广，因为 LVS 工作在传输层，几乎可以对所有应用做负载均衡，包括 http、数据库、在线聊天室等等
* 缺点
  - LVS性能依赖Linux内核的网络性能，但Linux内核的网络路径过长导致了大量开销，使得LVS单机性能较低
  - 软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是 Nginx、HAProxy + Keepalived 的优势所在
  - 如果是网站应用比较庞大的话，LVS/DR + Keepalived 实施起来就比较复杂了，相对而言，Nginx / HAProxy + Keepalived 就简单多了
* LVS vs Nginx
  - LVS 比 Nginx 具有更强的抗负载能力，性能高，对内存和 CPU 资源消耗较低
  - LVS 工作在网络层，具体流量由操作系统内核进行处理，Nginx 工作在应用层，可针对 HTTP 应用实施一些分流策略
  - LVS 安装配置较复杂，网络依赖性大，稳定性高。Nginx 安装配置较简单，网络依赖性小
  - LVS 不支持正则匹配处理，无法实现动静分离效果
  - LVS 适用的协议范围广。Nginx 仅支持 HTTP、HTTPS、Email 协议，适用范围小
