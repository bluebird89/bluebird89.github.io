# Data Structure

* 数据结构决定了数据存储空间和时间效率问题，数据的写入和读取速度也决定了应该选择怎样的数据结构
* 根据对场景需求的不同，需要设计不同的数据结构
    - 一次写入，多次写出
    - 写得多，读的少
    - 读写都多
* 如何把现实问题转化为计算机语言的表示：设计出数据结构， 在施加以算法就行
* 内存是纳秒级的，而磁盘是毫秒级
* 存储方式
    - 数组（顺序存储）
        + 由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间
        + 因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)
        + 如果想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N)
    - 链表（链式存储）
        + 因为元素不连续，而是靠指针指向下一个元素的位置，所以不存在数组的扩容问题
        + 如果知道某一元素的前驱和后驱，操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)
        + 因为存储空间不连续，无法根据一个索引算出对应元素的地址，所以不能随机访问
        + 由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间
* 操作
    - 遍历 + 访问
        + 线性就是 for/while 迭代为代表
        + 非线性就是递归为代表

## 线性表:排成一条线的结构，只有前后两个方向,顺序存储

* 散列表（哈希表 hash table）:哈希-》散列
    - 根据 键 直接访问 在指定储存位置 数据的数据结构，让码值经过哈希函数转换映射到散列表对应位置上
    - 哈希算法：把任意值(key)通过哈希函数变换为固定长度的 key 地址
        + MD5消息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），MD5算法将数据（如一段文字）运算变为另一固定长度值，是散列算法的基础原理。由美国密码学家 Ronald Linn Rivest设计，于1992年公开并在 RFC 1321 中被加以规范。
        + 循环冗余校验（Cyclic Redundancy Check）是一种根据网络数据包或电脑文件等数据，产生简短固定位数校验码的一种散列函数，由 W. Wesley Peterson 于1961年发表。生成的数字在传输或者存储之前计算出来并且附加到数据后面，然后接收方进行检验确定数据是否发生变化。由于本函数易于用二进制的电脑硬件使用、容易进行数学分析并且尤其善于检测传输通道干扰引起的错误，因此获得广泛应用。
        + MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。由 Austin Appleby 在2008年发明，并出现了多个变种，与其它流行的哈希函数相比，对于规律性较强的键，MurmurHash的随机分布特征表现更良好
    - 数据碰撞：对不同的 key 会计算出同一个结果
        + 开放定址法
        + 链地址法：用链表把碰撞的数据接连起来
        + 再次哈希法
        + 建立公共溢出区
    - 布隆过滤器 Bloom Filter
        + 1970年由布隆提出的。实际上是一个很长的二进制向量和一系列随机映射函数，可以用于检索一个元素是否在一个集合中
        + 优点是空间效率和查询时间都远远超过一般的算法
        + 缺点是有一定的误识别率和删除困难
    - 访问或者修改一条数据的时间复杂度 O(1)
    - 范围查询或者排序性能会非常差，只能进行全表扫描并依次判断是否满足条件
* 链表(Singly-linked List):物理存储单元上非连续的、非顺序的存储结构，通过指针来联系起一个个结点
    - 单链表:每个结点包括数据和指针(存放下一结点的地址)
        + 第一个结点叫作头结点:用来记录链表的基地址,遍历得到整条链表
        + 最后一个结点叫作尾结点:指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点
        + 插入和删除节点的时间复杂度：需要获取其前驱节点，在单链表中获取前驱节点的时间复杂度是 O(n)
        + 查询节点的时间复杂度是 O(n)
        + 循环链表:在单链表的基础上,尾节点指向了头结点，从而首尾相连
    - 双向链表(Doubly-Linked List):每个结点中除了有一个指向下一个节点的指针外，还有一个用于指向上一个节点的指针，从而实现通过 O(1) 复杂度找到上一个节点
        + 插入、删除节点时比单链表更高效：时间复杂度才是真正的 O(1)
        + 查询效率也要高于单链表，不过更优的时间复杂度是靠更差的空间复杂度换取
        + 支持顺序查找和逆序查找
        + 不支持按某个值或区间的快速查找
        + 不支持数据的快速插入
    - 边界条件
        + 输入边界：用户输入参数
        + 特殊边界
    - 插入
        + 保存临时地址
        + 创建新结点，将新结点指针指向下一结点指针
        + 恢复临时指针指向新节点
    - 删除
        + 断开删除结点指针
        + 删除节点的前节点指针指向删除节点后节点
        + 另一种思路：删除节点指针 换掉 删除节点的前节点指针
    - 场景
        + 大内存空间分配：数组空间的连续性，如果要为数组分配 500M 的空间，这 500M 的空间必须是连续的，未使用的，所以在内存空间的分配上数组的要求会比较严格，如果内存碎片太多，分配连续的大空间很可能导致失败。而链表由于是非连续的
        + 元素频繁删除和插入
    - 如果数据以查为主，很少涉及到增和删，选择数组，如果数据涉及到频繁的插入和删除，或元素所需分配空间过大，倾向于选择链表
    - 以一个虚拟的节点作为头结点（哨兵）
* 跳跃表（skiplist)：在链表之上加上多层索引构成
    - 可以与平衡树媲美的层次化链表结构，查找、删除、添加等操作都可以在对数期望时间下完成
    - 受多层链表（通过对一个元素添加多个指针）启发：为每个节点随机出一个层数(level).新插入一个节点并不会影响到其他节点的层数，因此，插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整，这就降低了插入操作的复杂度
    - 在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的 2:1 的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点 （也包括新插入的节点） 重新进行调整，这会让时间复杂度重新蜕化成 O(n)。删除数据也有同样的问题
* Array
    - 用一组连续的内存空间，来存储一组具有相同类型的数据,很容易地找出数组中任意一个元素的位置
    - PHP 数组底层是通过散列表实现，功能异常强大
        + PHP 数组集成了 Java 的数组、List、Set、Map 于一身
        + 由于 PHP 不支持指针，所以不能实现真正的链表
    - 优点
        + 查找:通过下标值随机访问数组内的任何元素，算法复杂度是 O(1)，非常高效
    - 缺点
        + 删除/插入元素比较费劲,算法复杂度是 O(n)
        + 插入一个元素，需要把其余元素一个个往后移，以为新元素腾空间
        + 删除需要把被删除元素之后的元素一个个往前移
    - 数组的性能高于链表,程序局部性原理
    - 树状数组
    - 矩阵
* 队列 queue:一端插入，另一端删除,先入先出（FIFO）
    - 允许插入的一端叫队尾，允许删除的一端叫队头
    - 通过数组实现的叫顺序队列:随着队列元素的插入和删除，队尾指针和队头指针不断后移，而导致队尾指针指向末尾无法插入数据
        + 循环队列，即把队列头尾连起来
        + 断队列是否为空的条件还是 tail==head，但是判断队列是否满的条件就变成了 (tail+1) % maxsize == head
        + 浪费一个空间是为了避免混淆判断空队列的条件
    - 通过链表实现的叫链式队列
    - 需要两个指针，一个指向队头，一个指向队尾
    - 优先队列
    - 多级反馈队列
* 堆(heap)
    - 一种表示元素集合的结构，是一种二叉树
    - J. W. J. Williams在1964年发表的堆排序，当时他提出了二叉堆树作为此算法的数据结构，堆在戴克斯特拉算法和带优先级队列中亦为重要的关键
    - 满足以下特性，即可称为堆：给定堆中任意节点P和C，若P是C的母节点，那么P的值会小于等于C的值。若母节点的值恒小于等于子节点的值，此堆称为最小堆；反之称为最大堆
        + 元素顺序
            * 如果结点大于等于其所有子结点，也就是堆的根是所有元素中最大的，这种堆称为大根堆(大顶堆、最大堆)
            * 如果结点小于等于其所有子结点，也就是堆的根是所有元素中最小的，这种堆称为小根堆(小顶堆、最小堆)
            * 大根堆/小根堆只是约定了父结点和子结点的大小关系，但是并不约束子结点的相对大小和顺序
        + 树的形状：最多在两层具有叶子结点，并且最底层的叶子结点靠左分布，该树种不存在空闲位置，是个完全二叉树
    - 堆的数组表示
        + i<=n && i>=1 // 数组下标范围
        + root_index = 1 // 根结点下标为1
        + value(i) = array[i] // 层次遍历第i个结点的值等于数组第i个元素
        + left_child_index(i) = i*2 // 堆中第i个元素的左孩子下标i*2
        + right_child_index(i) = i*2+1 // 堆中第i个元素的右孩子下标i*2+1
        + parent(i) = i/2  // 堆中第i个元素的父结点下标i/2
    - 调整函数
        + siftup：以小根堆为例，之前a[1...n-1]满足堆的特性，在数组a[n]插入新元素之后，就产生了两种情况：
            * 如果a[n]大于父结点那么a[1...n]仍然满足堆的特性，不需要调整
            * 如果a[n]比它的父结点要小无法保证堆的特性，就需要进行调整
            * 循环过程：自底向上的调整过程就是新加入元素不断向上比较置换的过程
            * 停止条件：新结点的值大于其父结点，或者新结点成为根结点为止
        + siftdn：以小根堆为例，之前a[1...n]满足堆的特性，在数组a[1]更新元素之后，就产生了两种情况：
            * 如果a[1]小于等于子结点仍然满足堆的特性，不需要调整；
            * 如果a[1]大于子结点无法保证堆的特性，就需要进行调整；
            * 循环过程：自顶向下的调整过程就是新加入元素不断向下比较置换的过程
            * 停止条件：直到新结点的值小于等于其子结点，或者新结点成为叶结点为止
    - 堆排序
* 栈(stack):限定只能在一端进行插入和删除操作的线性表,满足后进先出（LIFO）特点
    - 栈顶:允许插入和删除的一端，另一个端叫做栈底
    - 支持通过数组/链表实现，通过数组实现的通常叫做顺序栈，通过链表实现的叫做链栈
* 并查集

```java
/**
* 链表中的结点，data代表节点的值，next是指向下一个节点的引用
 */
class Node {
    int data;// 结点的数组域，值
    Node next = null;// 节点的引用，指向下一个节点
    public Node(int data) {
        this.data = data;
    }
}

publicclass LinkedList {
    int length = 0; // 链表长度，非必须，可不加
    Node head = new Node(0); // 哨兵结点

    public void addNode(int val) {
        Node tmp = head;
        while (tmp.next != null) {
            tmp = tmp.next;
        }
        tmp.next = new Node(val);
        length++
    }
}

class Node{
    constructor(data){
        this.data = data;
        this.next = null;
    }
}

//定义链表
class LinkList{
    constructor(){
        //初始化头结点
        this.head = new Node('head');
    }

    //根据 value 查找结点
    findByValue = (value) =>{
        let currentNode = this.head;
        while(currentNode !== null && currentNode.data !== value){
            currentNode = currentNode.next;
        }
        //判断该结点是否找到
        console.log(currentNode)
        return currentNode === null ? -1 : currentNode;
    }

    //根据 index 查找结点
    findByIndex = (index) =>{
        let pos = 0;
        let currentNode = this.head;
        while(currentNode !== null && pos !== index){
            currentNode = currentNode.next;
            pos++;
        }
        //判断是否找到该索引
        console.log(currentNode)
        return currentNode === null ? -1 : currentNode;
    }

    //插入元素(指定元素向后插入)
    insert = (value,element) =>{
        //先查找该元素
        let currentNode = this.findByValue(element);
        //如果没有找到
        if(currentNode == -1){
            console.log("未找到插入位置!")
            return;
        }
        let newNode = new Node(value);
        newNode.next = currentNode.next;
        currentNode.next = newNode;
    }

    //根据值删除结点
    delete = (value) =>{
        let currentNode = this.head;
        let preNode = null;
        while(currentNode !== null && currentNode.data !== value){
            preNode = currentNode;
            currentNode = currentNode.next;
        }
        if(currentNode == null) return -1;
        preNode.next = currentNode.next;
    }

     //遍历所有结点
    print = () =>{
        let currentNode = this.head
        //如果结点不为空
        while(currentNode !== null){
            console.log(currentNode.data)
            currentNode = currentNode.next;
        }
    }
}

//测试
const list = new LinkList()
list.insert('xiao','head');
list.insert('lu','xiao');
list.insert('ni','head');
list.insert('hellow','head');
list.print()
console.log('-------------删除元素------------')
list.delete('ni')
list.delete('xiao')
list.print()
console.log('-------------按值查找------------')
list.findByValue('lu')
console.log('-------------按索引查找------------')
list.print()
```

## 非线性结构:链式存储

## 树

* 树状图是一种数据结构，是由 n（n>=1）个有限节点组成一个具有层次关系的集合
* 定义
    - 每个节点有零个或多个子节点
    - 每一个非根节点有且只有一个父节点
    - 除了根节点外，每个子节点可以分为多个不相交的子树（subtree）
* 概念
    - 度数：在树中，每个节点的子节点（子树）个数就称为该节点的度（degree）
    - 阶数（Order):一个节点的子节点数目的最大值
    - 根节点(root):没有父节点的节点
    - 叶节点或终端节点：度为零节点
    - 非终端节点或分支节点：度不为零的节点
    - 父(亲)节点：若一个节点含有子节点，则这个节点称为其子节点的父节点
    - (孩)子节点：一个节点含有的子树的根节点称为该节点的子节点
    - 兄弟节点：具有相同父节点的节点互称为兄弟节点
    - 堂兄弟节点：父节点在同一层的节点互为堂兄弟
    - 节点层次：从根开始定义起，根为第1层，根的子节点为第2层
    - 深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0
    - 高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0
    - 节点的祖先：从根到该节点所经分支上的所有节点
    - 子孙：以某节点为根的子树中任一节点
    - 森林：由m（m>=0）棵互不相交的树的集合
* 前缀树
* 线段树

## 二叉(查找)树 BST(Binary search tree)

* 一颗完全二叉树
* 最小堆:树中的某个节点的值总是不大于其左右子节点的值
* 最大堆:树中的某个节点的值总是不小于其左右子节点的值
* 最小(大)堆性质
    - 树根节点的值是所有堆节点值中最小(大)值。
    - 树中每个节点的子树也都是最小(大)堆。
* 最小(大)堆作用
    - 最小(大)堆能保证堆顶元素为最小，而如果使用数组无法达到该效果。数组如果要访问最小值则需要遍历查找最小值，时间复杂度至少O(n)。而最小堆访问最小值时间复杂度为O(1)，当然天底下没有免费的午餐，需要做额外的工作去维护最小(大)堆的结构，这也是需要复杂度花销的。维护的时间复杂度为O(logN)。而数组则无法做到如此，如果数组想要维护顺序性则需要的复杂度至少为O(N)
* 可以通过数组来表示完全二叉树,数组下标与完全二叉树节点存在映射关系
    - 父节点可以通过Math.floor((index-1)/2)来获取
    - 左子节点可以通过2index+1来获取
    - 右子节点可以通过2index+2来获取
* 每个节点最多有两个子树,有五种基本形态
    - 空集
    - 根可以有空的左子树或右子树
    - 左、右子树皆为空
* 性质（类比2进制）
    - 第 n 层上至多有 2^(n-1)个元素
    - 深度为k的树最多有2^k-1 个节点
    - 包含n个节点的二叉树高度为
        + 每层有最多节点：log2n+1（向下） 或者 log2(n+1)(向上)
        + 每层一个节点
    - 叶子节点个数为n0,度为2节点数为n2,n0=n2+1
    - 节点个数等于分支个数加1
* 满二叉树:除了叶结点外每一个结点 *都有左右子叶*（非叶结点的度数为 2） 且叶子结点都处在最底层的二叉树，深度为 h的结点数必为 2^h-1
* 完全二叉树:对于深度为K的，有n个结点的二叉树，当且仅当其每一个结点都与深度为K的满二叉树中编号从1至n的结点一一对应，除了最大的层次即成为一颗满二叉树且层次最大那层所有的结点均向左靠齐，即集中在左面的位置上，不能有空位置。设一个结点为 i 则其父节点为 i/2，2i 为左子节点，2i+1 为右子节点。
* 存储
    - 数组存储：第i层 左节点位置(索引)为 2i,右节点 为 2i+1
    - 为了表示节点之间的关系，引入链表结构，用左右两个指针分别指向左节点和右节点，可以串联整个二叉树
* 时间复杂度是 O(lgn)
* 大多数二叉排序树BST的操作（查找、最大值、最小值、插入、删除等等）都是Q(h)的时间复杂度，h 为树的高度
* 极端情况下会退化为线性链表，二分查找也会退化为遍历查找，时间复杂退化为 O（N），检索性能急剧下降
* 二叉查找树存在不平衡问题，因此提出通过树节点的自动旋转和调整，让二叉树始终保持基本平衡状态，就能保持二叉查找树的最佳查找性能了。基于这种思路的自调整平衡状态的二叉树有 AVL 树和红黑树。
* 使用二叉树作为底层实现结构，树会变得很高，从而增加了磁盘的IO次数，从而影响数据查询时间。因此为了降低其高度，让一个节点有多个子节点，B树就诞生了
* 插入
    - 依次插入生成最小树：4 7 2 5 6 1 0 3 8 =》 0 3 1 5 6 4 2 7 8。自上而下插入，遇见小值往上冒
* 删除：删除最小值，即最小堆树中的根节点。主要是将树中最后一个节点替换到被删除的根节点，然后自顶向下递归调整使之符合最小堆要求

### 红黑树（Red Black Tree）

* 一颗自平衡（self-balancing）的二叉排序树（BST）
    - 会自动调整树形态的树结构，比如当二叉树处于一个不平衡状态时，红黑树就会自动左旋右旋节点以及节点变色，调整树的形态，使其保持基本的平衡状态（时间复杂度为 O（logn）），也就保证了查找效率不会明显减低
* 树上的每一个结点都遵循下面的规则（提醒:这里的自平衡和平衡二叉树AVL的高度平衡有别） 三黑不同
    - 每一个结点都有一个颜色，要么为红色，要么为黑色；
    - 树的根结点为黑色；
    - 树中不存在两个相邻的红色结点（即红色结点的父结点和孩子结点均不能是红色）；
    - 从任意一个结点（包括根结点）到其任何后代 NULL 结点（默认是黑色的）的每条路径都具有相同数量的黑色结点。
* 红黑树的高度始终都维持在 lgn ，n 为树中的顶点数目
* 红黑树RBT与平衡二叉树AVL比较：
    * AVL 树比红黑树更加平衡，但AVL树在插入和删除的时候也会存在大量的旋转操作。所以当应用涉及到频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树；
    * 当然，如果应用中涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现
+ 如何保持平衡:通过左旋和右旋来调整由于插入和删除所造成的不平衡问题
    * 重新着色
    * 旋转
+ 红黑树的黑高（Black Height):从某个结点 x 出发（不包含该结点）到达一个叶结点的任意一条简单路径上包含的黑色结点的数目称为 黑高 ，记为 bh(x).bh >= h/2
    * 一棵有n个内部结点的红黑树的高度 h <= 2lg(n+1)
* 插入：具体取决于叔叔结点的颜色。如果叔叔结点是红色的，会重新着色。如果叔叔结点是黑色的,会旋转或者重新着色，或者两者都考虑。
    - 进行标准的 BST 插入并将新插入的结点 x 设置为红色。
    - 2 如果 x 是根结点，将 x 的颜色转化为黑色（整棵树的黑高增加 1）。
    - 3 如果 x 的父结点 p 不是黑色并且 x 不是根结点，则：
        + 如果 x 的叔叔结点 u 是红色
            * 将插入结点 x 的父结点（Parent ）p 和叔叔（uncle）结点 u 的颜色变为黑色
            * 将 x 的爷爷结点（Grand Parent）g 设置为红色
            * 将 x = x的爷爷结点 g ，对于新的 x 重复 2，3两步
        + 如果 x 的叔叔结点 u 是黑色，则对于 x、 x 的父结点 p 和 x 的爷爷结点 g有以下四种情况：
            * LL（p 是 g 的左孩子且 x 是 p 的左孩子）
            * LR （p 是 g 的左孩子且 x 是 p 的右孩子）
            * RR （p 是 g 的右孩子且 x 是 p 的右孩子）
            * RL（p 是 g 的右孩子且 x 是 p 的左孩子）
    - 如果父节点为黑色，直接插入不处理 
    - 如果父节点为红色，叔叔节点为红色，则父节点和叔叔节点变为黑色，祖先节点变为红色，将节点操作转换为祖先节点 
    - 如果当前节点为父亲节点的右节点，则以父亲结点为中心左旋操作 
    - 如果当前节点为父亲节点的左节点，则父亲节点变为黑色，祖先节点变为红色，以祖先节点为中心右旋操作 
* 删除： 
    - 先按照排序二叉树的方法，删除当前节点，如果需要转移即转移到下一个节点 
    - 当前节点，必定为这样的情况：没有左子树。 
    - 删除为红色节点，不需要处理，直接按照删除二叉树节点一样 
    - 如果兄弟节点为黑色，兄弟节点的两个子节点为黑色，则将兄弟节点变为红色，将着色转移到父亲节点 
    - 如果兄弟节点为红色，将兄弟节点设为黑色，父亲结点设为红色节点，对父亲结点进行左旋操作 
    - 如果兄弟节点为黑色，左孩子为红色，右孩子为黑色，对兄弟节点进行右旋操作 
    - 如果兄弟节点为黑色，右孩子为红色，则将父亲节点的颜色赋值给兄弟节点，将父亲节点设置为黑色，将兄弟节点的右孩子设为黑色，对父亲节点进行左旋 
* 缺点：并没有完全解决二叉查找树虽然这个“右倾”趋势远没有二叉查找树退化为线性链表那么夸张。自增操作对于查找性能而言也是巨大的消耗
* 应用呢？
    - 大多数自平衡BST(self-balancing BST) 库函数都是用红黑树实现的，比如C++中的map 和 set （或者 Java 中的 TreeSet 和 TreeMap）。
    - 红黑树也用于实现 Linux 操作系统的 CPU 调度。完全公平调度（Completely Fair Scheduler）使用的就是红黑树

## 平衡二叉树（Balanced Binary Tree）AVL树（有别于AVL算法）

- 特点
    + 若左子树不空，则左子树上所有节点的值均小于它的根节点的值
    + 若右子树不空，则右子树上所有节点的值均大于或等于它的根节点的值
    + 每个非叶子节点的左右子树的高度之差的绝对值（平衡因子）最多为1
    + 左右子树都是平衡二叉树
- 优点
    - 查找性能（O（logn）），不存在极端的低效查找的情况
    - 实现范围查找、数据排序
* 缺点
    + 数据处的（高）深度决定着IO操作次数，IO操作耗时大
    + 每一个磁盘块（节点/页）保存的数据量太小了
    + 没有很好的利用操作磁盘IO的数据交换特性
    + 也没有利用好磁盘IO的预读能力（空间局部性原理），从而带来频繁的IO操作
    + 数据库查询数据的瓶颈在于磁盘 IO，如果使用 AVL 树，每一个树节点只存储了一个数据，一次磁盘 IO 只能取出来一个节点上的数据加载到内存里
- 查找性能是比较高的（性能最好的是最优二叉树），查询性能越好，维护的成本就越大
    + 实际应用场景中可能需要旋转多次
- 查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如AVL、Treap、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1.，通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找
- 平衡调整：保证相对平衡，每次插入元素都会做相应的旋转
    + LL型调整（顺时针旋转）：左子树插入新元素，为满足平衡，左非根节点提升为根节点
    + RR型调整（逆时针旋转）：右子树插入新的节点
    + LR调整：左孩子的右子树上插入新节点
    + RL调整
* 遍历
    - 前序遍历(自上而下)：根节点->当前节点的左子树->当前节点的右子树(当前节点无左子树)
    - 中序遍历（由下向上）: 当前节点的左子树->根节点->当前节点的右子树
        + 一个有序序列。由于树的高度，区间查询需要中序遍历，都会导致查询效率很慢
    - 后序遍历（先水平后垂直）:从根节点出发，依次遍历各节点的左右子树，直到当前节点左右子树遍历完成后，才访问该节点元素 左子树->右子树->根结点
    - 层次遍历:从上往下一层一层遍历

* 哈夫曼树（Huffman Tree） 最优二叉树
    - 一种带权路径长度（树中所有的叶子节点的权值乘上其根节点的路径长度）最短的二叉树
    - 权值较大的结点离根较近

```
graph TD 3-->1 3-->5 1-->2 5-->4 5-->6

前序遍历结果： 3 1 2 5 4 6
中序遍历结果： 1 2 3 4 5 6
后序遍历结果： 2 1 4 6 5 3

# 二叉树 层序遍历
public List<List<Integer>> levelOrder(TreeNode root) {
    List<List<Integer>> res = new ArrayList<>();

    Queue<TreeNode> queue = new ArrayDeque<>();
    if (root != null) {
        queue.add(root);
    }
    while (!queue.isEmpty()) {
        int n = queue.size();
        List<Integer> level = new ArrayList<>();
        for (int i = 0; i < n; i++) {
            TreeNode node = queue.poll();
            level.add(node.val);
            if (node.left != null) {
                queue.add(node.left);
            }
            if (node.right != null) {
                queue.add(node.right);
            }
        }
        res.add(level);
    }

    return res;
}
```

## DFS（ Depth First Search 深度优先搜索）

* 从图中一个未访问的顶点 V 开始，沿着一条路一直走到底，然后从这条路尽头的节点回退到上一个节点，再从另一条路开始走到底...，不断递归重复此过程，直到所有的顶点都遍历完成，它的特点是不撞南墙不回头，先走完一条路，再换一条路继续走
* 递归实现,如果层级过深，很容易导致栈溢出
* 非递归实现
    - 对于每个节点来说，先遍历当前节点，然后把右节点压栈，再压左节点
    - 弹栈，拿到栈顶的节点，如果节点不为空，重复步骤 1， 如果为空，结束遍历
* leetcode 104，111: 给定一个二叉树，找出其最大/最小深度

## BFS（ Breath First Search 广度优先搜索）

* 从图的一个未遍历的节点出发，先遍历这个节点的相邻节点，再依次遍历每个相邻节点的相邻节点
* 要用队列来实现：
* LeetCode 102.Binary Tree Level Order Traversal:给你一个二叉树，请你返回其按层序遍历得到的节点值。（即逐层地，从左到右访问所有节点）
* LeetCode 1162. As Far from Land as Possible 离开陆地的最远距离（Medium）最短路径：结点之间最近路径

### B树(B-tree)

*  B 树，B+树的的设计原理：磁盘 IO 有个有个特点，就是从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的，根据这个思路，可以在一个树节点上尽可能多地存储数据，一次磁盘 IO 就多加载点数据到内存
* 即平衡查找树，一般理解为平衡多路查找树，也称为B-树、B_树。是一种自平衡树状数据结构，用来存储排序后的数据
* O(log n)的时间复杂度进行查找、插入和删除
* 减少定位记录时所经历的中间过程，从而加快存取速度。一般较多用在存储系统上，比如数据库或文件系统
* 每个结点中存储了关键字（key）和关键字对应的数据（data）,以及孩子结点的指针
* 一颗 B树需要指定它的阶数，阶数表示此树的结点最多有多少个孩子结点（子树），一般用字母 m 表示阶数.M阶 可理解为 M树，即内含（M-1）个关键字 和 M 个子树
* 实际应用中的B树的阶数m都非常大（通常大于100）所以即使存储大量的数据，B树的高度仍然比较小
* 也称 M 阶B树 为 ( ⌈M /2⌉ , M ) 树,定义了节点子树的上下限
    - Every node has at most m children 最多有 m-1 个关键字
    - The root has at least two children and 1个关键字
    - Every non-leaf node (except root) has at least k children contains k − 1 keys 非根结点至少有 ceil(M/2)-1 个关键字 至少 ceil(M/2) 个子树,k = [ceil(M/2),M]
    - 每个结点中关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它
    - All leaves appear in the same level. 所有的叶子结点都出现在同一层上，并且不带信息(可以看做是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空)
    - 根节点：子树范围为[2,m]，节点内项的个数范围为[1,m-1]
    - 非根节点：节点内的项个数范围为[ceil(m/2)-1,m-1]
* 假设中间节点的关键字为：Key[1], Key[2], …, Key[k-1]，且关键字按照升序排序，即 Key[i]<Key[i+1]
    -  k-1 个关键字相当于划分了 k 个范围，也就是对应着 k个指针，即为：P[1], P[2], …, P[k]
    -  其中 P[1] 指向关键字小于 Key[1] 的子树，P[i] 指向关键字属于 (Key[i-1], Key[i]) 的子树，P[k] 指向关键字大于 Key[k-1] 的子树
* 特点
    - B 树的查找性能等于 O（h*logn），其中 h 为树高，n 为每个节点关键词的个数；
    - 尽可能少的磁盘 IO，加快了检索速度
    - 可以支持范围查找
    - 超过节点容量，引起分裂操作，可能引起父节点需要继续分裂
    - 父节点的若干项作为分离项分成多个子树，左子树小于对应分离项，对应分离项小于右子树
* 插入
    - 根据要插入的key值，找到叶子结点并插入，只插入到叶子节点，如果不是叶子节点，继续往下
    - 判断当前结点key个数是否小于等于m-1，若满足则结束，否则继续
    - 以结点中间的key为中心分裂成左右两部分，然后将这个中间的key插入到父结点中，key的左子树指向分裂后的左半部分，key的右子支指向分裂后的右半部分，然后将当前结点指向父结点,继续上一步
        + 阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可
    - 代码中,结点中存储记录的数组长度定义为m而非m-1，这样方便底层的结点由于分裂向上层插入一个记录时，上层有多余的位置存储这个记录。同时，每个结点还可以存储它的父结点的引用
* 删除
    - 删除key位于非叶子结点上：用后继key（均指后继记录，首个子树）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。执行第2步
    - 结点key个数大于等于Math.ceil(m/2)-1，结束删除操作，否则执行第3步。
        + 借兄弟节点：兄弟结点key个数大于Math.ceil(m/2)-1，则父结点中的key下移到该结点，兄弟结点中的一个key上移，删除操作结束。
        + 合并节点：将父结点中的key下移与当前结点及它的兄弟结点中的key合并，形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，重复上第2步。有些结点它可能即有左兄弟，又有右兄弟，那么任意选择一个兄弟结点进行操作即可。
* B-树的结点所包含的键的数目和磁盘块大小一样，从数个到数千个不等。由于B-树的高度 h 可控（一般远小于  ），所以与 AVL 树和红黑树相比，B-树的磁盘访问时间将极大地降低
* 平衡m叉查找树是指每个关键字的左侧子树与右侧子树的高度差的绝对值不超过1的查找树，其结点结构与上面提到的B-树结点结构相同，由此可见，B-树是平衡m叉查找树，但限制更强，要求所有叶结点都在同一层
* 参考
    - [什么是B树](https://mp.weixin.qq.com/s?__biz=MzA4NDE4MzY2MA==&mid=2647522005&idx=1&sn=659962d777276bbd16a581ddc884c69d)

### B+树

* B树的变体，也是一种多路搜索树,其定义基本与B-树相同。尽可能在一次磁盘 IO 中多读一点数据到内存。这个直接反映到树的结构就是，每个节点能存储的 key 可以适当增加
* B+Tree与BTree区别：
    - B树中关键字集合分布在整棵树中，叶节点中不包含任何关键字信息，而B+树关键字集合分布在叶子结点中，非叶节点只是叶子结点中关键字的索引
    - B树中任何一个关键字只出现在一个结点中，而B+树中的关键字必须出现在叶节点中，也可能在非叶结点中重复出现
    - B+节点关键字搜索采用闭合区间（B-树是开区间）
    - B+非叶节点不保存数据，只保存关键字和子节点的引用，用于索引，所有数据都保存在叶子结点中
    - BTree中间结点存储 数据指针与键值，导致可以存储的结点树目极大地减少了，从而增加 B-树的层数，进而增加了记录的搜索时间
    - B+树的内部节点只存储了关键字，而没有存储关键字的数据的指针，所以内部节点比B树小。那么磁盘就能加载更多的关键字信息，那么磁盘io的次数就小，而io是影响检索效率的最大因素
    - B+树的磁盘读写代价更低。B+树的内部结点并没有指向关键字具体信息的指针，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素。
    - B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。
    - （数据库索引采用B+树的主要原因是，）B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）
    - b+树的中间节点只存储了关键字而没有存储数据的指针，而B树既存储了关键字又存储了数据的指针，所以B+树的中间节点占用的磁盘更小，那么每个节点的磁盘叶也就小，那么磁盘就能加载更多的磁盘叶，磁盘叶交换次数更低，那么磁盘IO 就会降低
    - B树的中间节点存储了数据，所以整个树的每一层都有可能查找到要查找的数据，查询性能不稳定，而B+树所有的data都存储在叶子节点，且叶子节点位于同一层，因此查询性能稳定。
    - B树如果想要进行范围查找，需要频繁的进行二叉树的中序遍历，进行范围查找比较复杂，B+树要查找的元素都位于叶子节点，且连接形成有序链表，便于范围查找。
    - 两者在查找、插入和删除等操作的时间复杂度的量级是一致的，均为
* 特点
    - 节点中子节点个数[N/2,N]（不然会造成页分裂或页合并）
    - 根节点子节点个数可以不超过 m/2，这是一个例外
    - 非叶子树只存储索引，并不真正存储数据，只有最后一行的叶子节点存储行数据
    - 通过链表将叶子节点串联在一起，每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接,方便按区间查找
* 树高和每个节点的子节点个数（即 N 叉树中的 N）有关
* 每个节点 16 byte
* 局部性原理
    - 索引文件大不可能全部放入内存中，而是需要时候换入内存，方式是磁盘页。一般来说树的一个节点就是一个磁盘页
    - 无论是内存还是磁盘，操作系统都是按页的大小进行读取的（页大小通常为 4 kb），磁盘每次读取都会预读，会提前将连续的数据读入内存中，这样就避免了多次 IO
    - 连续数据必须是操作系统页大小的整数倍，这个连续数据就是 MySQL 的页，默认值为 16 KB，也就是说对于 B+ 树的节点，最好设置成页的大小（16 KB），这样一个 B+ 树上的节点就只会有一次 IO 读
    - 页大小并不是越大越好，InnoDB 是通过内存中的缓存池（pool buffer）来管理从磁盘中读取的页数据的。页太大的话，很快就把这个缓存池撑满了，可能会造成页在内存与磁盘间频繁换入换出，影响性能
    - 尽量保证每个节点的大小等于一个页（16kb）的大小即可
* 利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入
    - 每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。
    - B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O（h）=O（logmN）。一般实际应用中，m是非常大的数字，通常超过100，因此h非常小（通常不超过3）
* B+ 树为了维护索引的有序性，每插入或更新一条记录的时候，会对索引进行更新，可能会引起页分裂
    - 主键的随机性会引起大量的随机结点中的插入，进而造成大量的页分裂，进而造成性能的急剧下降
    - 自增 id 作为主键 由于新插入的表中生成的 id 比索引中所有的值都大，所以要么合到已存在的节点（元素个数未满）中，要么放入新建的节点中
* 页合并：当删除表记录的时候，索引也要删除，此时就有可能发生页合并
    - 可以定个阈值，比如对于 N 叉树来说，当节点的个数小于 N/2 的时候就应该和附近的节点合并，不过需要注意的是合并后节点里的元素大小可能会超过 N，造成页分裂，需要再对父节点等进行调整以让它满足 N 叉树的条件
* 优点
    - 扫库、表能力更强
    - 磁盘读写能力更强
    - 排序能力更强
    - 查询效率更加稳定
* 查找、修改时间复杂度为 O(log n)
* B树包括B+树的设计思想都是尽可能的降低树的高度，以此降低磁盘IO的次数，因为一个索引节点就表示一个磁盘页，页的换入换出次数越多，表示磁盘IO次数越多，越低效。以块的形式从磁盘读取数据.B树算法减少定位数据所在的节点时所经历的磁盘IO次数，从而加快存取速度
* 聚簇索引：在叶节点存放一整行记录的索引 其他的就称为非聚簇索引
* 使用
    - B树主要用于文件系统，和部分数据库索引，如文档型数据库mongodb
    - B+树主要用于mysql数据库索引。
* 参考
    - [什么是 B+树](https://mp.weixin.qq.com/s/y3vDkEQfR5Pv1-rcWRZ7nQ)

## 哈夫曼树


### 图

### 字典
### LSM树

## 应用

*   学了顺序表和链表，在查询操作更多的程序中，你应该用顺序表
*   修改操作更多的程序中，使用链表
*   单向链表不方便怎么办，每次都从头到尾好麻烦啊你这时就会想到双向链表 or 循环链表
*   学了栈之后，你就知道，很多涉及后入先出的问题，例如函数递归就是个栈模型、Android 的屏幕跳转就用到栈，很多类似的东西，你就会第一时间想到：我会用这东西来去写算法实现这个功能。学了队列之后，你就知道，对于先入先出要排队的问题，你就要用到队列，例如多个网络下载任务，我该怎么去调度它们去获得网络资源呢？再例如操作系统的进程（or 线程）调度，我该怎么去分配资源（像 CPU）给多个任务呢？肯定不能全部一起拥有的，资源只有一个，那就要排队！那么怎么排队呢？用普通的队列？但是对于那些优先级高的线程怎么办？
*   这时，你就会想到了优先队列，优先队列怎么实现？用堆，然后你就有疑问了，堆是啥玩意？自己查吧，敲累了。总之好好学数据结构就对了。我觉得数据结构就相当于：我塞牙了，那么就要用到牙签这“数据结构”，当然你用指甲也行，只不过“性能”没那么好；我要拧螺母，肯定用扳手这个“数据结构”，当然你用钳子也行，只不过也没那么好用。学习数据结构，就是为了了解以后在 IT 行业里搬砖需要用到什么工具，这些工具有什么利弊，应用于什么场景。以后用的过程中，你会发现这些基础的“工具”也存在着一些缺陷，你不满足于此工具，此时，你就开始自己在这些数据结构的基础上加以改造，这就叫做自定义数据结构。而且，你以后还会造出很多其他应用于实际场景的数据结构。。你用这些数据结构去造轮子，不知不觉，你成了又一个轮子哥。
*   一个负载稍高一点的 Python 网站，你不懂数据结构，你都不知道 List 和 Dictionary 的性能曲线大概会怎么变，需要深度优化的时候怎么下手。

数据结构的作用，就是为了提高硬件利用率。比如操作系统需要查找用户应用程序"office"在硬盘的哪个位置，盲目的搜索一遍硬盘肯定是低效的，这时候搞个 b+树作为索引，搜索 office 这个单词就很快，然后就能很快的定位 office 这个应用程序的文件信息，再找到文件信息中对应的磁盘位置了。数据结构的东西找本《算法导论》，《数据结构与算法分析》之类的看吧。

的确很少有写业务代码的时候会直接用上二叉树。但是真的没有吗？XML/DOM 是什么？是不是一棵树？为什么 DOM 可以和 XML 一一对应？因为 XML 序列化就是树的遍历的结果。能和 XML 对应，也就能跟 JSON 对应，因为两者都可以对应到树（只是表示逻辑上有些区别）。一个业务系统里有任务（Task），任务有相应的执行计划（Plan），计划可以用子任务组成，子任务可以是基础任务，也可以通过 Plan 拆分成更多的子任务。这是什么？这不就是树吗？那么怎么存储？JSON 不就很好吗。怎么从 JSON 加载、再保存会 JSON？树的遍历。怎么计算任务总共需要多少个基础任务？树的遍历。怎么计算计划总共需要多少时间？树的遍历。一个社交系统里，用户可以加好友，好友还有别的好友，这是什么？无向图。如果是知乎这样的关注系统呢？有向图。一个用户点了个赞，扩散到另一个用户至少要经过几次转发？最短路径。我要画一个小圈子里的人之间的关系图，怎么做？最小生成树。我要整理信息路径，看这批用户里哪些生产内容，哪些阅读内容，按什么次序传播，怎么做？拓扑排序。

说明数据结构首先就是“数据的结构”，在内存上的存储方式，就是物理的存储结构，在程序使用人员的思想上它是逻辑的，比如：你们在 C/C++中学习到链表，那么链表是什么一个概念，你们使用指针制向下一个结点的首地址，让他们串联起来，形成一个接一个的结点，就像显示生活中的火车一样。而这只是对于程序员的概念，但是在内存中存储的方式是怎样的那？对于你程序员来说这是“透明”的，其内部分配空间在那里，都是随机的，而内存中也没有一个又一根的线将他们串联起来，所以，这是一个物理与逻辑的概念，对于我们程序员只需要知道这些就可以了，而我们主要要研究的是“逻辑结构”。我可以给你一个我自己总结的一个概念：所有的算法必须基于数据结构生存。也就是说，我们对于任何算法的编写，必须依赖一个已经存在的数据结构来对它进行操作，数据结构成为算法的操作对象，这也是为什么算法和数据结构两门分类不分家的概念，算法在没有数据结构的情况下，没有任何存在的意义；而数据结构没有算法就等于是一个尸体而没有灵魂。估计这个对于算法的初学者可能有点晕，我们在具体的说一些东西吧：我们在数据结构中最简单的是什么：我个人把书籍中线性表更加细化一层（这里是为了便于理解在这样说的）：单个元素，比如：int i;这个 i 就是一个数据结构，它是一个什么样的数据结构，就是一个类型为 int 的变量，我们可以对它进行加法/减法/乘法/除法/自加等等一系列操作，当然对于单个元素我们对它的数据结构和算法的研究没有什么意义，因为它本来就是原子的，某些具体运算上可能算法存在比较小的差异；而提升一个层次：就是我们的线性表（一般包含有：顺序表/链表）那么我们研究这样两种数据结构主要就是要研究它的什么东西那？一般我们主要研究他们以结构为单位（就是结点）的增加/删除/修改/检索（查询）四个操作（为什么有这样的操作，我在下面说到），我们一般把“增加/删除/修改”都把它称为更新，对于一个结点，若要进行更新一类的操作比如：删除，对于顺序表来说是使用下标访问方式，那么我们在删除了一个元素后需要将这个元素后的所有元素后的所有元素全部向前移动，这个时间是对于越长的顺序表，时间越长的，而对于链表，没有顺序的概念，其删除元素只需要将前一个结点的指针指向被删除点的下一个结点，将空间使用 free()函数进行释放，还原给操作系统。当执行检索操作的时候，由于顺序表直接使用下标进行随机访问，而链表需要从头开始访问一一匹配才可以得到使用的元素，这个时间也是和链表的结点个数成正比的。所以我们每一种数据结构对于不同的算法会产生不同的效果，各自没有绝对的好，也没有绝对的不好，他们都有自己的应用价值和方式；这样我们就可以在实际的项目开发中，对于内部的算法时间和空间以及项目所能提供的硬件能力进行综合评估，以让自己的算法能够更加好。（在这里只提到了基于数据结构的一个方面就是：速度，其实算法的要素还应该包括：稳定性、健壮性、正确性、有穷性、可理解性、有输入和输出等等）为什么要以结点方式进行这些乱七八糟的操作那？首先明确一个概念就是：对于过程化程序设计语言所提供的都是一些基础第一信息，比如一些关键字/保留字/运算符/分界符。而我们需要用程序解决现实生活中的问题，比如我们要程序记录某公司人员的情况变化，那么人员这个数据类型，在程序设计语言中是没有的，那么我们需要对人员的内部信息定义（不可能完全，只是我们需要那些就定义那些），比如：年龄/性别/姓名/出生日期/民族/工作单位/职称/职务/工资状态等，那么就可以用一些 C/C++语言描述了，如年龄我们就可以进行如下定义:
int age;/_age 变量，表示人员公司人员的年龄_/
同理进行其他的定义，我们用结构体或类把他们封装成自定义数据类型或类的形式，这样用他们定义的就是一个人的对象的了，它内部包含了很多的模板数据了。我就我个人的经历估计的代码量应该 10000 以内的（我个人的经理：只是建议，从你的第一行代码开始算，不论程序正确与否，不论那一门语言，作为一个标准程序员需要十万行的代码的功底（这个是我在大学二年级感觉有一定时候的大致数据，不一定适合其他人），而十万行代码功底一般需要四门基础远支撑，若老师没有教，可以自学一些语言）。

坚持刷 leetcode，因为找工作有用

AVL 树: 最早的平衡二叉树之一。应用相对其他数据结构比较少。windows 对进程地址空间的管理用到了 AVL 树。红黑树: 平衡二叉树，广泛用在 C++的 STL 中。如 map 和 set 都是用红黑树实现的。
epoll 在内核中的实现，用红黑树管理事件块
nginx 中，用红黑树管理 timer 等著名的 linux 进程调度,用红黑树管理进程控制块
B/B+树: 用在磁盘文件组织 数据索引和数据库索引。
Trie 树(字典树): 用在统计和排序大量字符串，如自动机。

AVL 是一种高度平衡的二叉树，所以通常的结果是，维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL 还是优于红黑的。

有一种数据结构是树（Tree），树里面有一种树叫二叉搜索树（Binary Search Tree），平均复杂度是 O(logN)，具有不错的查询性能。但是在这里，我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库的实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道——磁盘访问的成本大概是内存访问成本的十万倍左右，所以简单的搜索树，难以满足复杂的应用场景。

磁盘读取数据，考的是机械运动，每次读取数据花费的时间可以分成：寻道时间、旋转延迟、传输时间三个部分。寻道时间指的是磁臂移动到指定磁盘所需要的时间，主流的磁盘一般在 5ms 以下；旋转延迟指的是我们经常说的磁盘转速，比如一个磁盘 7200 转，表示的就是每分钟磁盘能转 7200 次，转换成秒也就是 120 次每秒，旋转延迟就是 1/120/2=4.17ms；传输时间指的是从磁盘读取出数据或将数据写入磁盘的时间，一般都在零点几毫秒，相对于前两个，可以忽略不计。那么访问一次磁盘的时间，即一次磁盘 I/O 的时间约等于 5+4.17=9.17ms，9ms 左右，听起来还是不错的哈，但要知道一台 500-MIPS 的机器每秒可以执行 5 亿条指令，因为指令依靠的是电的性质，换句话说，执行一次 I/O 的时间可以执行 40 万条指令，数据库动辄百万级甚至千万级的数据，每次 9ms 的时间，显然是一个灾难。

无序树：树中任意节点的子结点之间没有顺序关系,也称为自由树有序树：树中任意节点的子结点之间有顺序关系二叉树：每个节点最多含有两个子树的树称为二叉树完全二叉树满二叉树霍夫曼树：带权路径最短的二叉树称为哈夫曼树或最优二叉树

## 参考

* [grantjenks/python-sortedcontainers](https://github.com/grantjenks/python-sortedcontainers):Python Sorted Container Types: Sorted List, Sorted Dict, and Sorted Set
* [Data Structure Visualizations](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html)
* [elarity/data-structure-php](https://github.com/elarity/data-structure-php)

* [学好这13种数据结构，应对各种编程语言（C++版）](https://mp.weixin.qq.com/s/JxQjKWBe-Dg9aCyq-USPwA)
http://blog.csdn.net/mysteryhaohao/article/details/51719871
https://guptavikas.wordpress.com/2012/12/17/b-tree-index-in-mysql/
