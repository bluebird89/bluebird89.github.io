# OS

## 硬件

* MBR(Master Boot Record)：主引导记录（MBR）是任何硬盘或软盘的第一扇区中的信息，用于标识操作系统的放置方式和位置，以便可以将其加载到计算机的主存储器或随机存取存储器中。
* 块设备(block devices)：块设备是一个能存储固定大小块信息的设备，它支持以固定大小的块，扇区或群集读取和（可选）写入数据。每个块都有自己的物理地址。通常块的大小在 512 - 65536 之间。所有传输的信息都会以连续的块为单位。块设备的基本特征是每个块都较为对立，能够独立的进行读写。常见的块设备有 硬盘、蓝光光盘、USB 盘
* 字符设备(character devices)：另一类 I/O 设备是字符设备。字符设备以字符为单位发送或接收一个字符流，而不考虑任何块结构。字符设备是不可寻址的，也没有任何寻道操作。常见的字符设备有 打印机、网络设备、鼠标、以及大多数与磁盘不同的设备。
* 设备控制器(device controller)：设备控制器是处理 CPU 传入信号和传出信号的系统。设备通过插头和插座连接到计算机，并且插座连接到设备控制器。
* 显卡(Video card)，是个人电脑最基本组成部分之一，用途是将计算机系统所需要的显示信息进行转换驱动显示器，并向显示器提供逐行或隔行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要组件，是人机对话的重要设备之一。
* 挂载(mounting) ：挂载是指操作系统会让存储在硬盘、CD-ROM 等资源设备上的目录和文件，通过文件系统能够让用户访问的过程。
* RAID：全称是 Redundant Array of Inexpensive Disks ，廉价磁盘或驱动器的冗余阵列，它是一种数据存储虚拟化的技术，将多个物理磁盘驱动器组件组合成一个或多个逻辑单元，以实现数据冗余，改善性能。
* 可抢占资源(preemptable resource)：可以从拥有它的进程中抢占而并不会产生任何副作用。
* 不可抢占资源(nonpreemptable resource)：与可抢占资源相反，如果资源被抢占后，会导致进程或任务出错。
* 电阻式触摸屏(Resistive touchscreens)：电阻式触摸屏基于施加到屏幕上的压力来工作。电阻屏由许多层组成。当按下屏幕时，外部的后面板将被推到下一层，下一层会感觉到施加了压力并记录了输入。电阻式触摸屏用途广泛，可以用手指，指甲，手写笔或任何其他物体进行操作。
* 电容式触摸屏(capacitive touchscreen)：电容式触摸屏通过感应物体（通常是指尖上的皮肤）的导电特性来工作。手机或智能手机上的电容屏通常具有玻璃表面，并且不依赖压力。当涉及到手势（如滑动和捏合）时，它比电阻式屏幕更具响应性。电容式触摸屏只能用手指触摸，而不能用普通的手写笔，手套或大多数其他物体来响应。

* GDI (Graphics Device Interface)：图形接口，是微软视窗系统提供的应用程序接口，也是其用来表征图形对象、将图形对象传送给诸如显示器、打印机之类输出设备的核心组件。
* 设备上下文(device context)：设备上下文是 Windows 数据结构，其中包含有关设备（例如显示器或打印机）的图形属性的信息。所有绘图调用都是通过设备上下文对象进行的，该对象封装了用于绘制线条，形状和文本的 Windows API。设备上下文可用于绘制到屏幕，打印机或图元文件。
* 系统检查点(system checkpointed)：系统检查点是操作系统（OS）的可启动实例。检查点是计算机在特定时间点的快照。
* 沙盒(sandboxing)：沙盒是一种软件管理策略，可将应用程序与关键系统资源和其他程序隔离。它提供了一层额外的安全保护，可防止恶意软件或有害应用程序对你的系统造成负面影响。

## 内存

* 内存模型 :主要分为语言级别的内存模型和硬件级别的内存模型。
    - 语言级别的内存模型，C/C++属于weak memory model，简单的说就是编译器在进行编译优化的时候，可以对指令进行重排，只需要保证在单线程的环境下，优化前和优化后执行结果一致即可，执行中间过程不保证跟代码的语义顺序一致。所以在多线程的环境下，如果依赖代码中间过程的执行顺序，程序就会出现问题。
    - 硬件级别的内存模型，常用的cpu，也属于弱内存模型，即cpu在执行指令的时候，为了提升执行效率，也会对某些执行进行乱序执行（按照wiki提供的资料，在x86 64环境下，只会发生读写乱序，即读操作可能会被乱序到写操作之前），如果在编程的时候不做一些措施，同样容易造成错误。
* 内存屏障 :为了解决弱内存模型造成的问题，需要一种能控制指令重排或者乱序执行程序的手段，这种技术就叫做内存屏障，程序员只需要在代码中插入特定的函数，就能控制弱内存模型带来的负面影响，当然，由于影响了乱序和重排这类的优化，对代码的执行效率有一定的影响。具体实现上，内存屏障技术分三种，

* ECC(Error-Correcting Code)：指能够实现错误检查和纠正错误技术的内存。
* I/O port: 也被称为输入/输出端口，它是由软件用来与计算机上的硬件进行通信的内存地址。
* 内存映射I/O(memory mapped I/O，MMIO): 内存映射的 I/O 使用相同的地址空间来寻址内存和 I/O 设备，也就是说，内存映射I/O 设备共享同一内存地址。
* 端口映射I/O(Port-mapped I/O ,PMIO)：在 PMIO中，内存和I/O设备有各自的地址空间。端口映射I/O通常使用一种特殊的CPU指令，专门执行I/O操作。
* DMA (Direct Memory Access)：直接内存访问，它是计算机系统的一项功能，它允许某些硬件系统能够独立于 CPU 访问内存。如果没有 DMA，当 CPU 执行输入/输出指令时，它通常在读取或写入操作的整个过程中都被完全占用，因此无法执行其他工作。使用 DMA 后，CPU 首先启动传输信号，然后在进行传输时执行其他操作，最后在完成操作后从 DMA 控制器（DMAC）接收中断。完成执行。

## 存储

* 页是计算机管理存储器的逻辑块，将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）
* 主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行
* Page cache:针对文件系统的,是文件的缓存,在文件层面上的数据会缓存到page cache
    - 读：通过将磁盘中的数据缓存到内存中，从而减少磁盘I/O操作提高性能
        + 磁盘访问的速度比内存慢好几个数量级（毫秒和纳秒的差距）
        + 被访问过的数据，有很大概率会被再次访问
        + 内核发起一个读请求时（例如进程发起read()请求），首先会检查请求的数据是否缓存到了page cache中，如果有，那么直接从内存中读取，不需要访问磁盘，这被称为cache命中（cache hit）
        + 如果cache中没有请求的数据，即cache未命中（cache miss），就必须从磁盘中读取数据。然后内核将读取的数据缓存到cache中，这样后续的读请求就可以命中cache了
        + page可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来
    - page回写（page writeback）：在page cache中的数据更改时能够被同步到磁盘上
        + 当内核发起一个写请求时（例如进程发起write()请求），同样是直接往cache中写入，磁盘的内容不会直接更新
        + 内核会将被写入的page标记为dirty，并将其加入dirty list中。内核会周期性地将dirty list中的page写回到磁盘上，从而使磁盘上的数据和内存中缓存的数据一致
            * 用户进程调用sync() 和 fsync()系统调用
            * 空闲内存低于特定的阈值（threshold）
            * Dirty数据在内存中驻留的时间超过一个特定的阈值
    - 一个inode对应一个page cache对象，一个page cache对象包含多个物理page，其内容对应磁盘上的block
    - Cache回收：释放page，从而释放内存空间。cache回收的任务是选择合适的page释放，并且如果page是dirty的，需要将page写回到磁盘中再释放。理想的做法是释放距离下次访问时间最久的page，但是很明显不现实
        + LRU（least rencently used)算法是选择最近一次访问时间最靠前的page，即干掉最近没被光顾过的page。原始LRU算法存在的问题是，有些文件只会被访问一次，但是按照LRU的算法，即使这些文件以后再也不会被访问了，但是如果它们是刚刚被访问的，就不会被选中。
        + Two-List策略:维护了两个list，active list 和 inactive list
            + 在active list上的page被认为是hot的，不能释放。只有inactive list上的page可以被释放的。首次缓存的数据的page会被加入到inactive list中，已经在inactive list中的page如果再次被访问，就会移入active list中。两个链表都使用了伪LRU算法维护，新的page从尾部加入，移除时从头部移除，就像队列一样。如果active list中page的数量远大于inactive list，那么active list头部的页面会被移入inactive list中，从而位置两个表的平衡
        + 内核使用address_space结构来表示一个page cache https://www.linuxidc.com/Linux/2018-12/156117.htm
* Buffer cache:针对磁盘块的缓存,也就是在没有文件系统的情况下,直接对磁盘进行操作的数据会缓存到buffer cache中,例如,文件系统的元数据都会缓存到buffer cache中

```c
# address_space
struct address_space {
    struct inode            *host;              /* owning inode */
    struct radix_tree_root  page_tree;          /* radix tree of all pages */
    spinlock_t              tree_lock;          /* page_tree lock */
    unsigned int            i_mmap_writable;    /* VM_SHARED ma count */
    struct prio_tree_root   i_mmap;             /* list of all mappings */
    struct list_head        i_mmap_nonlinear;   /* VM_NONLINEAR ma list */
    spinlock_t              i_mmap_lock;        /* i_mmap lock */
    atomic_t                truncate_count;     /* truncate re count */
    unsigned long           nrpages;            /* total number of pages */
    pgoff_t                 writeback_index;    /* writeback start offset */
    struct address_space_operations *a_ops;     /* operations table */
    unsigned                long flags;         /* gfp_mask and error flags */
    struct backing_dev_info *backing_dev_info;  /* read-ahead information */
    spinlock_t              private_lock;       /* private lock */
    struct list_head        private_list;       /* private list */
    struct
```

## 网络编程

整个演变的过程，就是对CPU有效性能压榨的过程

* Socket
    - 套接字（socket）是通信的基石，是支持 TCP/IP 协议的网络通信的基本操作单元
    - 是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的 IP 地址，本地进程的协议端口，远地主机的 IP 地址，远地进程的协议端口。
    - 连接过程:建立 Socket 连接至少需要一对套接字，其中一个运行于客户端，称为 ClientSocket ，另一个运行于服务器端，称为 ServerSocket,套接字之间的连接过程可以分为三个步骤：服务器监听，客户端请求，连接确认。
        + 服务器监听：是服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。
        + 客户端请求：是指由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。
        + 连接确认：是指当服务器端套接字监听到或者说接收到客户端套接字的连接请求，它就响应客户端
    - 套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，连接就建立好了。而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。
* Fork进程
* 进程池/线程池
* epoll事件驱动(Nginx、node.js反人类回调)
    - 多线程+epoll的模式下,有效的压榨CPU性能
* 协程：协程需要上下文切换，但是不会产生 CPU上下文切换和进程/线程上下文的切换,因为这些切换都是在同一个线程中，即用户态中的切换，甚至可以简单的理解为，协程上下文之间的切换，就是移动了一下你程序里面的指针，CPU资源依旧属于当前线程
    - 没有IO阻塞操作,不会发生协程切换
    - 带IO阻塞操作:基于协程的php+ swoole服务比 Java + netty服务的QPS高了6倍
    - 在进程/线程切换的时候，会产生额外的CPU资源花销，特别是在用户态和内核态之间切换的时候！
* 多线程模型(IO 多路复用)
    - select/poll
        + Linux很早就提供了 select 系统调用，可以在一个进程内维持1024个连接
        + 后来加入了poll系统调用，poll做了一些改进，解决了 1024 限制的问题，可以维持任意数量的连接
        + 问题:需要循环检测连接是否有事件,如果服务器有100万个连接，在某一时间只有一个连接向服务器发送了数据，select/poll需要做循环100万次，其中只有1次是命中的，剩下的99万9999次都是无效的，白白浪费了CPU资源
    - epoll
        + Linux 2.6内核提供了新的epoll系统调用，可以维持无限数量的连接，而且无需轮询，这才真正解决了 C10K 问题
        + 各种高并发异步IO的服务器程序都是基于epoll实现的，比如Nginx、Node.js、Erlang、Golang。像 Node.js，Redis 这样单进程单线程的程序，都可以维持超过1百万TCP连接，全部归功于epoll技术
        + 基于 epoll 实现的 Reactor 模型.IO复用异步非阻塞程序使用经典的Reactor模型，它本身不处理任何数据收发。只是可以监视一个socket句柄的事件变化
            * 主进程/线程往epoll内核事件中注册socket上的读就绪亊件
            * 主进程/线程调用epoll_wait等待socket上有数据可读。
            * 当socket上有数据可读时，epoll_wait通知主进程/线程。主进程/线程则将socket可读事件放入请求队列。
            * 睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求， 然后往epoll内核事件表中注册该socket上的写就绪事件。
            * 主线程调用epoll_wait等待socket可写。
            * 当socket可写时，epoll_wait通知主进程/线程主进程/线程将socket可写事件放入请求队列。
            * 睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求
* 内核实现线程与线程之间的调度，通常一个线程是无法从头到尾占用着 cpu 的，尤其是进行 i/o 操作时，许多的系统调用都是阻塞的，此时内核保存该线程的上下文，然后挂起该线程
* 当然更多时候是由于该线程的本次运行时间耗尽，只得被挂起等待 cpu 的下一次临幸
* 关键
    - 线程的上下文切换造成的开销
        + 挂起一个进程，将这个进程在 CPU 中的状态（上下文）存储于内存中的某处
        + 在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复
        + 跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程
    - 线程之间对资源的竞争问题
* 进程上下文：进程是由内核来管理和调度的，进程的切换只能发生在内核态，因此虚拟内存、栈、全局变量等用户空间的资源，以及内核堆栈、寄存器等内核空间的状态
* 线程的上下文：线程会共享父进程的虚拟内存和全局变量等资源，父进程的资源加上线上自己的私有数据
    - 如果是同一进程的线程，因为有资源共享，所以会比多进程间的切换消耗更少的资源
* 进程和线程的切换，会产生CPU上下文切换和进程/线程上下文的切换。而这些上下文切换,都是会消耗额外的CPU的资源的
* 典型PHP-FPM的CGI模式，每一个HTTP请求会经历如下，决定了在高并发上的灾难性表现
    - 都会读取框架的数百个php文件
    - 都会重新建立/释放一遍MYSQL/REIDS/MQ连接
    - 都会重新动态解释编译执行PHP文件
    - 都会在不同的php-fpm进程直接不停的切换切换再切换
* 线程是操作系统调度的最小单位
* 进程是资源分配的最小单位

* execve函数接收3个参数
    - 第一个是可执行文件的路径pathname
    - 第二个是参数的指针数组argv 指向一个NULL结尾的指针数组，每个元素都是一个指向参数字符串的指针。按照约定，argv[0]是可执行文件的名称
    - 第三个是环境变量的指针数组envp  数据结构类似。唯一的区别是，环境变量数组元素指向的字符串都是名-值对形式的，比如"PWD=/usr/droh"
    - 加载:找到pathname对应的可执行文件后，execve会调用操作系统永驻内存的loader代码，把可执行文件的代码和数据从磁盘复制到内存。然后，跳到其第一个指令或“入口点”开始执行该程序

![reactor](../_satic/eventloop.png "Optional title")

```
int execve(const char *pathname, char *const argv[], char *const envp[]);
```

### 调度

* 周期窃取(cycle stealing)：许多总线能够以两种模式操作：每次一字模式和块模式。一些 DMA 控制器也能够使用这两种方式进行操作。在前一个模式中，DMA 控制器请求传送一个字并得到这个字。如果 CPU 想要使用总线，它必须进行等待。设备可能会偷偷进入并且从 CPU 偷走一个总线周期，从而轻微的延迟 CPU。它类似于直接内存访问（DMA），允许I / O控制器在无需 CPU 干预的情况下读取或写入RAM。
* 突发模式(burst mode)：指的是设备在不进行单独事务中重复传输每个数据所需的所有步骤的情况下，重复传输数据的情况。
* 中断向量表(interrupt vector table)：用来形成相应的中断服务程序的入口地址或存放中断服务程序的首地址称为中断向量。中断向量表是中断向量的集合，中断向量是中断处理程序的地址。
* 精确中断(precise interrupt)：精确中断是一种能够使机器处于良好状态下的中断，它具有如下特征
    - PC （程序计数器）保存在一个已知的地方
    - PC 所指向的指令之前所有的指令已经完全执行
    - PC 所指向的指令之后所有的指令都没有执行
    - PC 所指向的指令的执行状态是已知的
* 非精确中断(imprecise interrupt)：不满足以上要求的中断，指令的执行时序和完成度具有不确定性，而且恢复起来也非常麻烦。
* 设备独立性(device independence)：我们编写访问任何设备的应用程序，不用事先指定特定的设备。比如你编写了一个能够从设备读入文件的应用程序，那么这个应用程序可以从硬盘、DVD 或者 USB 进行读入，不必再为每个设备定制应用程序。这其实就体现了设备独立性的概念。
* UNC(Uniform Naming Convention) ：UNC 是统一命名约定或统一命名约定的缩写，是用于命名和访问网络资源（例如网络驱动器，打印机或服务器）的标准。例如，在 MS-DOS 和 Microsoft Windows 中，用户可以通过键入或映射到类似于以下示例的共享名来访问共享资源。 `\\computer\path` 然而，在 UNIX 和 Linux 中，你会像如下这么写 `//computer/path`

* 由于CPU是串行的,因此对于单核CPU来说,同一时刻一定是只有一个线程在占用CPU资源的。因此，Linux作为一个多任务(进程)系统，会频繁的发生进程/线程切换
* CPU上下文：在每个任务运行前，CPU都需要知道从哪里加载，从哪里运行，这些信息保存在CPU寄存器和操作系统的程序计数器里面
* 现代的cpu提供了对单一变量简单操作的原子指令，即这个变量的这些简单操作只需要一条cpu指令即可完成，这样就不用对这个操作加互斥锁了，在锁冲突不激烈的情况下，减少了用户态和内核态的切换，化悲观锁为乐观锁，从而提高了效率。此外，现在外面很火的所谓无锁编程（类似CAS操作），底层就是用了这些原子操作。gcc为了方便程序员使用这些cpu原子操作，提供了一系列__sync开头的函数，这些函数如果包含内存屏障语义，则同时禁止编译器指令重排和cpu乱序执行。
* 并发控制
    - 现代操作系统以及硬件基本都支持并发程序
    - 在并发程序设计中，各个进程或者线程需要对公共变量的访问加以制约
    - 不同的进程或者线程需要协同工作以完成特征的任务，这就需要一套完善的同步机制
        + 在Linux内核中有相应的技术实现，包括原子操作，信号量，互斥锁，自旋锁，读写锁等。
        + InnoDB考虑到效率和监控两方面的原因，实现了一套独有的同步机制
* 错误处理(Error handling)：错误处理是指对软件应用程序中存在的错误情况的响应和恢复过程。
* 同步阻塞(synchronous)：同步是阻塞式的，CPU 必须等待同步的处理结果。
* 异步响应(asynchronous)：异步是由中断驱动的，CPU 不用等待每个操作的处理结果继而执行其他操作
* 缓冲区(buffering)：缓冲区是内存的临时存储区域，它的出现是为了加快内存的访问速度而设计的。对于经常访问的数据和指令来说，CPU 应该访问的是缓冲区而非内存
* Programmed input–output,PIO：它指的是在 CPU 和外围设备（例如网络适配器或 ATA 存储设备）之间传输数据的一种方法。
* 轮询(polling)：轮询是指通过客户端程序主动通过对每个设备进行访问来获得同步状态的过程。
* 忙等(busy waiting)：当一个进程正处在某临界区内，任何试图进入其临界区的进程都必须等待，陷入忙等状态。连续测试一个变量直到某个值出现为止，称为忙等。
* 可重入(reentrant)：如果一段程序或者代码在任意时刻被中断后由操作系统调用其他程序或者代码，这段代码调用子程序并能够正确运行，这种现象就称为可重入。也就是说当该子程序正在运行时，执行线程可以再次进入并执行它，仍然获得符合设计时预期的结果。
* 主设备编号(major device number)、副设备编号(minor device number) ：所有设备都有一个主，副号码。主号码是更大，更通用的类别（例如硬盘，输入/输出设备等），而次号码则更具体（即告诉设备连接到哪条总线）。
* 多重缓冲区(double buffering)：它指的是使用多个缓冲区来保存数据块，每个缓冲区都保留数据块的一部分，读取的时候通过读取多个缓冲区的数据进而拼凑成一个完整的数据。
* 环形缓冲区(circular buffer)：它指的是首尾相连的缓冲区，常用来实现数据缓冲流。
* 假脱机(Spooling) ：假脱机是多程序的一种特殊形式，目的是在不同设备之间复制数据。 在现代系统中，通常用于计算机应用程序和慢速外围设备（例如打印机）之间的中介。
* 守护进程(Daemon)：在计算机中，守护程序是作为后台进程运行的计算机程序，而不是在交互式用户的直接控制下运行的程序。
* 逻辑块寻址(logical block addressing, LBA)：逻辑块寻址是一种通用方案，用于指定存储在计算机存储设备上的数据块的位置。
33. FCFS (First-Come, First-Served)：先进先出的调度算法，也就是说，首先到达  CPU 的进程首先进行服务。
34. SSF (Shortest Seek First) 最短路径优先算法，这是对先进先出算法的改进，这种算法因为减少了总的磁臂运动，从而缩短了平均响应时间。
35. 稳定存储(stable storage)：它是计算机存储技术的一种分类，该技术可确保任何给定的写操作都具有原子性。
36. 时钟(Clocks)：也被称为 timers。通常，时钟是指调节所有计算机功能的时序和速度的微芯片。芯片中是一个晶体，当通电时，晶体会以特定的频率振动。任何一台计算机能够执行的最短时间是一个时钟或时钟芯片的一次振动。

## 链接

* 动态库、静态库，指的是程序编译的链接阶段，链接成可执行文件的方式
* 静态库:在链接阶段将汇编生成的目标文件.o 与引用到的库一起链接打包到可执行文件中，因此对应的链接方式称为静态链接（static linking）
* 动态库:在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此对应的链接方式称为动态链接（dynamic linking）
    - 节省磁盘空间，不同的程序可以共享常见的库
    - 节省内存，共享的库只需从磁盘中加载到内存一次，然后在不同的程序之间共享
    - 更便于维护，库文件更新后，不需要重新编译使用该库的所有程
* 90 年代的程序大多使用的是静态链接，因为当时的程序大多数都运行在软盘或者盒式磁带上，而且当时根本不存在标准库。这样程序在运行时与函数库再无瓜葛，移植方便
* 对于 Linux 这样的分时系统，会在在同一块硬盘上并发运行多个程序，这些程序基本上都会用到标准的 C 库，这时使用动态链接的优点就体现出来了。使用动态链接时，可执行文件不包含标准库文件，只包含到这些库文件的索引
* 动态库与共享库（shared libraries）相结合才能达到节省内存的功效。Linux 中动态库的扩展名是 .so（ shared object），而 Windows 中动态库的扩展名是 .DLL（Dynamic-link library）
* 解决缺少标准库
    - `gcc -o hello hello.c -static`
    - 拷贝库文件到镜像中,用 ldd 工具
    - 使用 busybox:glibc 作为基础镜像

```sh
ldd hello
    linux-vdso.so.1 (0x00007ffdf8acb000)
    libc.so.6 => /usr/lib/libc.so.6 (0x00007ff897ef6000)
    /lib64/ld-linux-x86-64.so.2 => /usr/lib64/ld-linux-x86-64.so.2 (0x00007ff8980f7000)
```

## 系统

* 最外层客户机Ubuntu
* 两三个小分区出来，可以装多个linux发行版
* 公用/home分区
    - 每次装linux，/直接装在其中一个小分区上，/home挂载到第三个主分区去，那里存放文档和代码数据的，这样有什么新的linux就装，文档一直在，
    - 可以装新linux时起个不重复的用户名，也在home下，完全不影响老的文档和使用环境配置
* 安装第二个Linux发行版的时候，需要注意的是，EFI分区和交换分区swap已经有可用的了，安装程序可以自动检测得到，因此不需要再关系这2个分区，只需要在磁盘剩余的空闲分区中创建这个系统本身需要的根分区/和/home分区

```sh
sudo update-grub
```

* 内核参数优化
* JVM优化
* 网络参数优化
* 事务优化
* 数据库优化
* 池化
* 内存溢出排查
* 堆外内存排查
* 网络排查
* I/O排查
* 高负载排查
* 流量录制

## 锁

* 互斥锁 :互斥锁有两层语义，除了大家都知道的排他性（即只允许一个线程同时访问）外，还有一层内存屏障（full memory barrier）的语义，即保证临界区的操作不会被乱序到临界区外。Pthread库里面常用的mutex，conditional variable等操作都自带内存屏障这层语义。此外，使用pthread库，每次调用都需要应用程序从用户态陷入到内核态中查看当前环境，在锁冲突不是很严重的情况下，效率相对比较低。
* 自旋锁 :传统的互斥锁，只要一检测到锁被其他线程所占用了，就立刻放弃cpu时间片，把cpu留给其他线程，这就会产生一次上下文切换。当系统压力大的时候，频繁的上下文切换会导致sys值过高。自旋锁，在检测到锁不可用的时候，首先cpu忙等一小会儿，如果还是发现不可用，再放弃cpu，进行切换。互斥锁消耗cpu sys值，自旋锁消耗cpu usr值。
* 递归锁 :如果在同一个线程中，对同一个互斥锁连续加锁两次，即第一次加锁后，没有释放，继续进行对这个锁进行加锁，那么如果这个互斥锁不是递归锁，将导致死锁。可以把递归锁理解为一种特殊的互斥锁。
* 死锁 :构成死锁有四大条件，其中有一个就是加锁顺序不一致，如果能保证不同类型的锁按照某个特定的顺序加锁，就能大大降低死锁发生的概率，之所以不能完全消除，是因为同一种类型的锁依然可能发生死锁。另外，对同一个锁连续加锁两次，如果是非递归锁，也将导致死锁。
* 死锁(deadlock)：死锁常用于并发情况下，死锁 是一种状态，死锁中的每个成员都在等待另一个成员（包括其自身）采取行动。
* 活锁(Livelock)：活锁类似于死锁，不同之处在于，活锁中仅涉及进程的状态彼此之间不断变化，没有进展。举一个现实世界的例子，当两个人在狭窄的走廊里相遇时，就会发生活锁，每个人都试图通过移动到一边让对方通过而礼貌，但最终却没有任何进展就左右摇摆，因为他们总是同时移动相同的方式。
* 饥饿(starvation)：在死锁或者活锁的状态中，在任何时刻都可能请求资源，虽然一些调度策略能够决定一些进程在某一时刻获得资源，但是有一些进程永远无法获得资源。永远无法获得资源的进程很容易产生饥饿。

* 两阶段加锁(two-phase locking, 2PL)：经常用于数据库的并发控制，以保证可串行化 这种方法使用数据库锁在两个阶段：
    - 扩张阶段：不断上锁，没有锁被释放
    - 收缩阶段：锁被陆续释放，没有新的加锁

## 触摸板

* 选择项目：点击触摸板。
* 滚动：将两个手指放在触摸板上，然后以水平或垂直方向滑动。
* 放大或缩小：将两个手指放在触摸板上，然后收缩或拉伸。
* 显示更多命令（类似于右键单击）：使用两根手指点击触摸板，或按右下角。
* 查看所有打开的窗口：将三根手指放在触摸板上，然后朝外轻扫。
* 显示桌面：将三根手指放在触摸板上，然后朝里轻扫。
* 在打开的窗口之间切换：将三根手指放在触摸板上，然后向右或向左轻扫。
* 打开 Cortana：用三根手指点击触摸板。
* 打开操作中心：用四根手指点击触摸板。
* 切换虚拟桌面：将四根手指放在触摸板上，然后向右或向左轻扫。
* 三指
    - 上：多任务视图
    - 下：显示桌面
    - 左：切换应用
    - 右：切换应用
* 四指
    - 上：多任务视图
    - 下：显示桌面
    - 左：切换桌面
    - 右：切换桌面

## 中国操作系统往事

* 红旗Linux往事
    - 国产操作系统第一次对国际巨头发起挑战。从上世纪90年代开始，以中科院院士倪光南、中科院软件研究所副所长孙玉芳为首的一批科学家，在“中国必须拥有自主知识软件操作系统”的共识下，推出国产操作系统红旗Linux。2000年，在红旗Linux发布半年后，中科院软件所和上海联创以6:4的出资方式，共同成立了中科红旗。
    - 红旗Linux曾有过“辉煌时刻”，在成立仅1年后，红旗Linux成为北京市政府采购的中标平台。这次采购在行业内影响重大，当时，包括红旗、永中、金山等国产软件均中标，而微软却意外出局。此后不久，微软中国总裁高群耀辞职，据内部人士透露，此次为“被迫辞职”，原因与业绩不佳有关。
    - 在微软价格高企、盗版Windows猖獗的当时，在政府订单之外，为了降低成本，联想、戴尔、惠普等公司也曾预装红旗系统。上线一年多以后，时任中科红旗总裁的刘博表示，国内Linux 的使用量比去年增加3、4倍，已经达到100万套。
    - 正如倪光南所说，操作系统的成功与否，关键在于生态系统，需要能够搭建起完整的软件开发者、芯片企业、终端企业、运营商等产业链上的各个主体。出于这样的考虑，2002年，红旗宣布与国产办公软件永中合作，将红旗Linux和永中Office联合销售。
    - 正是软件，成为国产操作系统的致命伤。作为倪光南的助手，梁宁在2000年到2002年期间参与了Linux、永中office联合销售相关的工作。她回忆这段历史时，提到当时一个“要命的问题”：永中office、金山WPS等国产软件均基于Linux，这也意味着，他们与微软Office有兼容性问题。
    - 时任北京市科委主任的俞慈声带头启动“启航工程”，召集中、日、韩三国技术人员，一起研究如何破解微软的文档格式，以实现读写和存储的完美兼容，但效果并不理想。我们“没有搞定用户体验”，梁宁写到。
    - 2005年，中科红旗董事长、国产系统力主者孙玉芳突发脑溢血去世，此后，公司连续曝出合资各方意见不一、管理不善等问题。 两年以后，微软向国际标准化组织提交了自己的office标准OOXML；与此同时，金山、红旗、永中等国内办公软件企业联合提出的UOF被确立为中国国家标准。制定标准者能够决定市场走向，早已是业内共识，在国际标准争论中，倪光南四处奔走，希望中国投出反对票，在他看来，OOXML一旦通过，中国软件及操作系统将面临空前压力。
    - 最终，微软仍然以51票支持、18票反对获胜。 伴随着微软在全球包括中国市场压倒性优势的胜利，国产桌面操作系统日渐式微，其余国产操作系统中标麒麟、StartOS也鲜有用户。 2011年，永中科技宣告破产，2年后，中科红旗贴出清算公告，宣布团队解散。
* 运营商抢跑手机操作系统
    - 在iPhone问世的2007年底，Android（安卓）操作系统发布1.0版本，婴儿期的安卓系统优势并不明显。次年推出的HTC G1是世界上首个使用Android操作系统的智能手机产品，但因卡顿、死机问题显著，销量平平。彼时，在智能手机系统中，iOS、Android、微软、诺基亚“塞班”都在争夺着未来。
    - 在中国，首个宣布推出国产手机操作系统的是中国移动。2008年，这款名为OMS的系统上线，号称要与Android并驾齐驱，打破几大国外智能系统的垄断。 OMS基于Linux内核、采用Android源代码进行开发，去掉google搜索、邮件等服务，集合中国移动的飞信、139邮箱等，并首批搭载于联想的移动定制机OPhone上。依照中国移动的想法，这是一种软硬结合的发展方式，可以“掌控移动互联网平台的入口”。 单以时间看，OMS操作系统可以说是抢占了先机，然而，由于基于安卓开发，而当时的安卓成熟度较低、经移动修改后体验更差。OMS手机上市后，许多用户购买联想OPhone的第一件事是手动刷机，换成其它系统。
    - 由于反响惨淡，市场推广局面不利，几年之后，中国移动不再要求定制机搭载OMS系统，“首个国产智能手机系统”也逐渐悄无声息。 关于OMS的另一个争议是，这究竟是否是一个独立于安卓生存的操作系统？经过当时的许多技术人士分析，尽管OMS强调自己是自主系统，甚至在初期选择不兼容安卓应用，但事实上，OMS仍对安卓高度依赖，并需要跟随后者的升级而升级。 严格意义上，第一款“独立国产智能手机系统”的名号应该颁发给2年后发布的联通沃Phone系统。在发布当时，中国联通科技委主任刘韵洁即强调：“沃Phone与Android没有任何关系。沃Phone拥有完全自主知识产权。”正因如此，沃Phone系统也得到了国家级的多项支持，被列为国家核心核心电子器件、高端通用芯片及基础软件产品重大科技专项支持的课题成果。
    - 不过，作为运营商，联通推出沃Phone系统的目的主要是置入自有业务，而并非抢夺市场。甚至，因为当时联通正在依托苹果iPhone的销售追赶移动，在沃Phone推广上，也平衡了这一部分利益。种种原因之下，沃Phone具备多种“先天劣势”：系统仅用于1000元到2000元的低端机、不兼容安卓应用、对每家手机厂商收取30元/台手机授权费。 更糟糕的是 ，尽管沃Phone只比移动OMS系统晚了两年，但在2011年，手机系统市场格局已是天翻地覆：OMS上线时，安卓尚仅仅占据5%市场份额，然而；伴随着三星Galaxy S的大获成功，安卓系统飞速增长，至2011年，其已经拥有超过50%的市占率，自此后，更是对市场中的其它系统呈现碾压之势。沃Phone一路溃败，2014年，其研发团队——深圳全智达通信宣布公司被同洲电子以2983.31万元全资收购。
* 阿里云OS的倔强与短暂辉煌
    - 时任阿里巴巴CTO、阿里云总裁的王坚曾透露说，最早，阿里希望直接进入手机市场，甚至与富士康等企业进行过洽谈，并与中国电信谈好了话费分成，但却在最后拍板时，选择了停止。“几个高管一起决定的，”他说，“手机不是阿里能做的，售后、库存，都是互联网公司不曾遇到的，这不是阿里的核心竞争力”。
    - 退而求其次的阿里云选择了开发手机操作系统。摆在王坚面前的有两个选择，一是做安卓系统的再开发，二是研发对标安卓的自主系统。日后人们会知道，腾讯和百度、小米和华为等多家科技企业，均选择了前一种方案——毕竟，在已经势如破竹的安卓系统面前，坚持独立无异于自寻死路。
    - 在王坚的坚持下，阿里云OS成为第一款由互联网企业打造的自主操作系统。阿里云率先和天语、海尔合作推出手机。然而，当阿里云进一步与宏碁手机合作时，在2012年9月13日的发布会开始前一小时，由于受到谷歌施压，宏碁取消了这次合作。
    - “如果在新产品上搭载阿里云操作系统，谷歌公司将会解除与其安卓产品的合作和相关技术授权”。”根据一财报道，阿里云在当时的官方声明中这样写道。 之后不久，谷歌确认了这一消息，他们同时带来了一个坏消息——在声明中，谷歌将一贯宣称为自主操作系统的阿里“云OS”定义为“非兼容版安卓系统”，意味，虽然云OS不兼容安卓应用，但仍然是一个变形版的“安卓”。
    - 无论结论如何，这次纷争对于云OS是一次重大打击。谷歌能够要求宏碁停止与阿里合作，因为宏碁属于OHA（开放手机联盟），这是一个由谷歌发起的组织，成员可以提前获得新版安卓，在海外市场认可度极高。 彼时，国内华为、中兴、联想、OPPO，国外摩托罗拉、三星、LG、索爱等主流手机企业，均为OHA成员。阿里云与宏碁合作流产，昭示着与这些品牌合作的可能均付之东流。
    - 2012年9月20日，阿里宣布YunOS将独立于阿里云事业群运行，受阿里巴巴集团直接管理。此外，阿里宣称，YunOS成为阿里巴巴集团的战略级产品，将向其投入2亿美金。 2013年3月2日，YunOS网站上线，系统名称也从阿里云OS更名为阿里巴巴YunOS。

## 手机系统

* Aurora

## VM

* VMM (Virtual Machine Monitor)：也被称为 hypervisor，在同一个物理机器上创建出来多态虚拟机器的假象。
* 虚拟化技术(virtualization)：是一种资源管理技术，将计算机的各种实体资源（CPU、内存、磁盘空间、网络适配器等），进行抽象、转换后呈现出来并可供分割、组合为一个或多个电脑配置环境。
* 云(cloud)：云是目前虚拟机最重要、最时髦的玩法。
* 解释器(interpreter)：解释器是一种程序，能够把编程语言一行一行解释运行。每次运行程序时都要先转成另一种语言再运行，因此解释器的程序运行速度比较缓慢。它不会一次把整个程序翻译出来，而是每翻译一行程序叙述就立刻运行，然后再翻译下一行，再运行，如此不停地进行下去。
* 半虚拟化(paravirtualization)：半虚拟化的目的不是呈现出一个和底层硬件一摸一样的虚拟机，而是提供一个软件接口，软件接口与硬件接口相似但又不完全一样。
* 全虚拟化(full virtualization)：全虚拟化是硬件虚拟化的一种，允许未经修改的操作系统隔离运行。对于全虚拟化，硬件特征会被映射到虚拟机上，这些特征包括完整的指令集、I/O操作、中断和内存管理等。
* 客户操作系统(guest operating system) : 客户操作系统是安装在计算机上操作系统之后的操作系统，客户操作系统既可以是分区系统的一部分，也可以是虚拟机设置的一部分。客户操作系统为设备提供了备用操作系统。
* 主机操作系统(host operating system)：主机操作系统是计算机系统的硬盘驱动器上安装的主要操作系统。在大多数情况下，只有一个主机操作系统。

## 图书

* 《深入理解计算机系统》

## 参考

* [cfenollosa/os-tutorial](https://github.com/cfenollosa/os-tutorial):How to create an OS from scratch
* [30dayMakeOS](git@github.com:yourtion/30dayMakeOS.git)
