# OS

## 硬件

* MBR(Master Boot Record)：主引导记录（MBR）是任何硬盘或软盘的第一扇区中的信息，用于标识操作系统的放置方式和位置，以便可以将其加载到计算机的主存储器或随机存取存储器中。
* 块设备(block devices)：块设备是一个能存储固定大小块信息的设备，它支持以固定大小的块，扇区或群集读取和（可选）写入数据。每个块都有自己的物理地址。通常块的大小在 512 - 65536 之间。所有传输的信息都会以连续的块为单位。块设备的基本特征是每个块都较为对立，能够独立的进行读写。常见的块设备有 硬盘、蓝光光盘、USB 盘
* 字符设备(character devices)：另一类 I/O 设备是字符设备。字符设备以字符为单位发送或接收一个字符流，而不考虑任何块结构。字符设备是不可寻址的，也没有任何寻道操作。常见的字符设备有 打印机、网络设备、鼠标、以及大多数与磁盘不同的设备。
* 设备控制器(device controller)：设备控制器是处理 CPU 传入信号和传出信号的系统。设备通过插头和插座连接到计算机，并且插座连接到设备控制器。
* 显卡(Video card)，是个人电脑最基本组成部分之一，用途是将计算机系统所需要的显示信息进行转换驱动显示器，并向显示器提供逐行或隔行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要组件，是人机对话的重要设备之一。
* 挂载(mounting) ：挂载是指操作系统会让存储在硬盘、CD-ROM 等资源设备上的目录和文件，通过文件系统能够让用户访问的过程。
* RAID：全称是 Redundant Array of Inexpensive Disks ，廉价磁盘或驱动器的冗余阵列，它是一种数据存储虚拟化的技术，将多个物理磁盘驱动器组件组合成一个或多个逻辑单元，以实现数据冗余，改善性能。
* 可抢占资源(preemptable resource)：可以从拥有它的进程中抢占而并不会产生任何副作用。
* 不可抢占资源(nonpreemptable resource)：与可抢占资源相反，如果资源被抢占后，会导致进程或任务出错。
* 电阻式触摸屏(Resistive touchscreens)：电阻式触摸屏基于施加到屏幕上的压力来工作。电阻屏由许多层组成。当按下屏幕时，外部的后面板将被推到下一层，下一层会感觉到施加了压力并记录了输入。电阻式触摸屏用途广泛，可以用手指，指甲，手写笔或任何其他物体进行操作。
* 电容式触摸屏(capacitive touchscreen)：电容式触摸屏通过感应物体（通常是指尖上的皮肤）的导电特性来工作。手机或智能手机上的电容屏通常具有玻璃表面，并且不依赖压力。当涉及到手势（如滑动和捏合）时，它比电阻式屏幕更具响应性。电容式触摸屏只能用手指触摸，而不能用普通的手写笔，手套或大多数其他物体来响应。

* GDI (Graphics Device Interface)：图形接口，是微软视窗系统提供的应用程序接口，也是其用来表征图形对象、将图形对象传送给诸如显示器、打印机之类输出设备的核心组件。
* 设备上下文(device context)：设备上下文是 Windows 数据结构，其中包含有关设备（例如显示器或打印机）的图形属性的信息。所有绘图调用都是通过设备上下文对象进行的，该对象封装了用于绘制线条，形状和文本的 Windows API。设备上下文可用于绘制到屏幕，打印机或图元文件。
* 系统检查点(system checkpointed)：系统检查点是操作系统（OS）的可启动实例。检查点是计算机在特定时间点的快照。
* 沙盒(sandboxing)：沙盒是一种软件管理策略，可将应用程序与关键系统资源和其他程序隔离。它提供了一层额外的安全保护，可防止恶意软件或有害应用程序对你的系统造成负面影响。

## 内存

* 内存模型 :主要分为语言级别的内存模型和硬件级别的内存模型。
    - 语言级别的内存模型，C/C++属于weak memory model，简单的说就是编译器在进行编译优化的时候，可以对指令进行重排，只需要保证在单线程的环境下，优化前和优化后执行结果一致即可，执行中间过程不保证跟代码的语义顺序一致。所以在多线程的环境下，如果依赖代码中间过程的执行顺序，程序就会出现问题。
    - 硬件级别的内存模型，常用的cpu，也属于弱内存模型，即cpu在执行指令的时候，为了提升执行效率，也会对某些执行进行乱序执行（按照wiki提供的资料，在x86 64环境下，只会发生读写乱序，即读操作可能会被乱序到写操作之前），如果在编程的时候不做一些措施，同样容易造成错误。
* 内存屏障 :为了解决弱内存模型造成的问题，需要一种能控制指令重排或者乱序执行程序的手段，这种技术就叫做内存屏障，程序员只需要在代码中插入特定的函数，就能控制弱内存模型带来的负面影响，当然，由于影响了乱序和重排这类的优化，对代码的执行效率有一定的影响。具体实现上，内存屏障技术分三种，

* ECC(Error-Correcting Code)：指能够实现错误检查和纠正错误技术的内存。
* I/O port: 也被称为输入/输出端口，它是由软件用来与计算机上的硬件进行通信的内存地址。
* 内存映射I/O(memory mapped I/O，MMIO): 内存映射的 I/O 使用相同的地址空间来寻址内存和 I/O 设备，也就是说，内存映射I/O 设备共享同一内存地址。
* 端口映射I/O(Port-mapped I/O ,PMIO)：在 PMIO中，内存和I/O设备有各自的地址空间。端口映射I/O通常使用一种特殊的CPU指令，专门执行I/O操作。
* DMA (Direct Memory Access)：直接内存访问，它是计算机系统的一项功能，它允许某些硬件系统能够独立于 CPU 访问内存。如果没有 DMA，当 CPU 执行输入/输出指令时，它通常在读取或写入操作的整个过程中都被完全占用，因此无法执行其他工作。使用 DMA 后，CPU 首先启动传输信号，然后在进行传输时执行其他操作，最后在完成操作后从 DMA 控制器（DMAC）接收中断。完成执行。

## 进程与线程

* 进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。
* 线程(thread)，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。
* 区别
    - 地址空间和其它资源（如打开文件）：进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。
    - 通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。
    - 调度和切换：线程上下文切换比进程上下文切换要快得多。
    - 在多线程OS中，进程不是一个可执行的实体。

## cache vs buffer

* cache
    - cache 是为了弥补高速设备和低速设备的鸿沟而引入的中间层，最终起到**加快访问速度**的作用
    - Cache（缓存）则是系统两端处理速度不匹配时的一种折衷策略。因为CPU和memory之间的速度差异越来越大，所以人们充分利用数据的局部性（locality）特征，通过使用存储系统分级（memory hierarchy）的策略来减小这种差异带来的影响。3、假定以后存储器访问变得跟CPU做计算一样快，cache就可以消失，但是buffer依然存在。比如从网络上下载东西，瞬时速率可能会有较大变化，但从长期来看却是稳定的，这样就能通过引入一个buffer使得OS接收数据的速率更稳定，进一步减少对磁盘的伤害。4、TLB（Translation Lookaside Buffer，翻译后备缓冲器）名字起错了，其实它是一个cache.
* buffer
    - buffer 的主要目的进行流量整形，把突发的大数量较小规模的 I/O 整理成平稳的小数量较大规模的 I/O，以**减少响应次数**（比如从网上下电影，你不能下一点点数据就写一下硬盘，而是积攒一定量的数据以后一整块一起写，不然硬盘都要被你玩坏了
    - Buffer（缓冲区）是系统两端处理速度平衡（从长时间尺度上看）时使用的。它的引入是为了减小短期内突发I/O的影响，起到流量整形的作用。比如生产者——消费者问题，他们产生和消耗资源的速度大体接近，加一个buffer可以抵消掉资源刚产生/消耗时的突然变化。
    - Buffer的核心作用是用来缓冲，缓和冲击。比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，日子过得爽了。极大缓和了冲击。Cache的核心作用是加快取用的速度。比如你一个很复杂的计算做完了，下次还要用结果，就把结果放手边一个好拿的地方存着，下次不用再算了。加快了数据取用的速度。所以，如果你注意关心过存储系统的话，你会发现硬盘的读写缓冲/缓存名称是不一样的，叫write-buffer和read-cache。

## 存储

* 页是计算机管理存储器的逻辑块，将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）
* 主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行
* Page cache:针对文件系统的,是文件的缓存,在文件层面上的数据会缓存到page cache
    - 读：通过将磁盘中的数据缓存到内存中，从而减少磁盘I/O操作提高性能
        + 磁盘访问的速度比内存慢好几个数量级（毫秒和纳秒的差距）
        + 被访问过的数据，有很大概率会被再次访问
        + 内核发起一个读请求时（例如进程发起read()请求），首先会检查请求的数据是否缓存到了page cache中，如果有，那么直接从内存中读取，不需要访问磁盘，这被称为cache命中（cache hit）
        + 如果cache中没有请求的数据，即cache未命中（cache miss），就必须从磁盘中读取数据。然后内核将读取的数据缓存到cache中，这样后续的读请求就可以命中cache了
        + page可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来
    - page回写（page writeback）：在page cache中的数据更改时能够被同步到磁盘上
        + 当内核发起一个写请求时（例如进程发起write()请求），同样是直接往cache中写入，磁盘的内容不会直接更新
        + 内核会将被写入的page标记为dirty，并将其加入dirty list中。内核会周期性地将dirty list中的page写回到磁盘上，从而使磁盘上的数据和内存中缓存的数据一致
            * 用户进程调用sync() 和 fsync()系统调用
            * 空闲内存低于特定的阈值（threshold）
            * Dirty数据在内存中驻留的时间超过一个特定的阈值
    - 一个inode对应一个page cache对象，一个page cache对象包含多个物理page，其内容对应磁盘上的block
    - Cache回收：释放page，从而释放内存空间。cache回收的任务是选择合适的page释放，并且如果page是dirty的，需要将page写回到磁盘中再释放。理想的做法是释放距离下次访问时间最久的page，但是很明显不现实
        + LRU（least rencently used)算法是选择最近一次访问时间最靠前的page，即干掉最近没被光顾过的page。原始LRU算法存在的问题是，有些文件只会被访问一次，但是按照LRU的算法，即使这些文件以后再也不会被访问了，但是如果它们是刚刚被访问的，就不会被选中。
        + Two-List策略:维护了两个list，active list 和 inactive list
            + 在active list上的page被认为是hot的，不能释放。只有inactive list上的page可以被释放的。首次缓存的数据的page会被加入到inactive list中，已经在inactive list中的page如果再次被访问，就会移入active list中。两个链表都使用了伪LRU算法维护，新的page从尾部加入，移除时从头部移除，就像队列一样。如果active list中page的数量远大于inactive list，那么active list头部的页面会被移入inactive list中，从而位置两个表的平衡
        + 内核使用address_space结构来表示一个page cache https://www.linuxidc.com/Linux/2018-12/156117.htm
* Buffer cache:针对磁盘块的缓存,也就是在没有文件系统的情况下,直接对磁盘进行操作的数据会缓存到buffer cache中,例如,文件系统的元数据都会缓存到buffer cache中

```
# address_space
struct address_space {
    struct inode            *host;              /* owning inode */
    struct radix_tree_root  page_tree;          /* radix tree of all pages */
    spinlock_t              tree_lock;          /* page_tree lock */
    unsigned int            i_mmap_writable;    /* VM_SHARED ma count */
    struct prio_tree_root   i_mmap;             /* list of all mappings */
    struct list_head        i_mmap_nonlinear;   /* VM_NONLINEAR ma list */
    spinlock_t              i_mmap_lock;        /* i_mmap lock */
    atomic_t                truncate_count;     /* truncate re count */
    unsigned long           nrpages;            /* total number of pages */
    pgoff_t                 writeback_index;    /* writeback start offset */
    struct address_space_operations *a_ops;     /* operations table */
    unsigned                long flags;         /* gfp_mask and error flags */
    struct backing_dev_info *backing_dev_info;  /* read-ahead information */
    spinlock_t              private_lock;       /* private lock */
    struct list_head        private_list;       /* private list */
    struct
}
```

## 进程切换

* 进程切换（process switch）、任务切换（task switch）或上下文切换（content switch）：为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行
    - 尽管每个进程都有自己的地址空间，但所有进程必须共享CPU寄存器。因此，在恢复一个进程的执行之前，内核必须确保每个寄存器装载了挂起进程时所需要的值。
    - 进程恢复执行前必须装入寄存器的一组数据成为硬件上下文（hardware context）
        + 硬件上下文是进程可执行上下文的一个自己，因为可执行上下文包含进程执行时所需要的所有信息
        + 在Linux中，进程硬件上下文的一部分存放在TSS段，而剩余部分存放在内核态堆栈中
* 流程
    - 保存处理机上下文，包括程序计数器和其他寄存器。
    - 更新PCB信息。
    - 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
    - 选择另一个进程执行，并更新其PCB。
    - 更新内存管理的数据结构。
    - 恢复处理机上下文
* 阻塞
    - 正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。
    - 进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态
    - 当进程进入阻塞状态，是不占用CPU资源的
* 文件描述符fd：用于表述指向文件的引用的抽象化概念
    - 形式上是一个非负整数
    - 实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表
    - 当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符
* 缓存 I/O
    - 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O
    - 在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间
    - 缺点
        + 数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的
* IO模式
    - 一个read操作发生时，它会经历两个阶段：
        + 等待内核数据准备 (Waiting for the data to be ready)
        + 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)
* 网络模式
    - 阻塞 I/O（blocking IO）
        + 数据被拷贝到操作系统内核的缓冲区中是需要一个过程，进程这边，整个进程会被阻塞
        + 等到数据准备好了，就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来
        + 两阶段都阻塞
    - 非阻塞 I/O（nonblocking IO）
        + 如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error
        + 当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的
        + 特点是用户进程需要不断的主动询问kernel数据好了没有
    - I/O 多路复用（ IO multiplexing） event driven IO
        + 好处就在于单个process就可以同时处理多个网络连接的IO
        + 基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程
            * 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回
            * 这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。
            * 通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。
        + select/epoll的优势并不是对于单个连接能处理得更快(和blocking IO 对比，需要使用两个system call )，而是在于能处理更多的连接
        + select
            * 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds
            * 调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回
            * 当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符
            * 优点：几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点
            * 缺点
                - 单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低
                - 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
                - 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
                - select返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生了事件；
                - select的触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么之后每次select调用还是会将这些文件描述符通知进程。
        + poll
            * 使用一个 pollfd的指针(链表)实现
                - 要监视的event和发生的event，不再使用select“参数-值”传递的方式
            * 同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）
            * 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符
        + select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。
        + epoll:更加灵活，没有描述符限制
            * 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次.操作过程需要三个接口
            * int epoll_create(int size);
                - 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。
                - 当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。
            *  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； 函数是对指定描述符fd执行op操作。
                + epfd：是epoll_create()的返回值。
                + op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
                + fd：是需要监听的fd（文件描述符）
                + epoll_event：是告诉内核需要监听什么事
            - int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待epfd上的io事件，最多返回maxevents个事件。
                + 参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。
            - 工作模式
                + LT（level trigger）:当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
                + ET（edge trigger）:当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。
                    * 很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。
        * 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描
        * epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在)
    - 信号驱动 I/O（ signal driven IO）
    - 异步 I/O（asynchronous IO）
        + 用户进程发起read操作之后，立刻就可以开始去做其它的事
        + 而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block
        + 然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

```c
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);

int poll (struct pollfd *fds, unsigned int nfds, int timeout);
struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};

int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);

struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};

//events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
```

## 信号量（Semaphore）

* 保证多个线程不会互相冲突
* 在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了

## 阶段

* 原生php实现TCP Server -> 原生php实现http协议 -> 掌握tcpdump的使用 -> 深刻理解tcp连接过程
    - php解释器 能否处理tcp http,可以跳过之前的环节
    - client –(protocol:http)–> nginx –(protocol:fastcgi)–> php-fpm –(interface:sapi)–> php
* 原生php实现多进程webserver
    - 引入I/O多路复用
    - 引入php协程(yield)
    - 对比 I/O多路复用版本 和 协程版本的性能差异
* 实现简单的go web框架
* php c扩展实现简单的webserver

## 网状网络

多个无线路由器一起工作以广播单个超大型的无线网络。网状网络中的每个路由器都可与其他路由器智能地通信，以便为的数据提供最佳的“路径”

### 调度

* 周期窃取(cycle stealing)：许多总线能够以两种模式操作：每次一字模式和块模式。一些 DMA 控制器也能够使用这两种方式进行操作。在前一个模式中，DMA 控制器请求传送一个字并得到这个字。如果 CPU 想要使用总线，它必须进行等待。设备可能会偷偷进入并且从 CPU 偷走一个总线周期，从而轻微的延迟 CPU。它类似于直接内存访问（DMA），允许I / O控制器在无需 CPU 干预的情况下读取或写入RAM。
* 突发模式(burst mode)：指的是设备在不进行单独事务中重复传输每个数据所需的所有步骤的情况下，重复传输数据的情况。
* 中断向量表(interrupt vector table)：用来形成相应的中断服务程序的入口地址或存放中断服务程序的首地址称为中断向量。中断向量表是中断向量的集合，中断向量是中断处理程序的地址。
* 精确中断(precise interrupt)：精确中断是一种能够使机器处于良好状态下的中断，它具有如下特征
    - PC （程序计数器）保存在一个已知的地方
    - PC 所指向的指令之前所有的指令已经完全执行
    - PC 所指向的指令之后所有的指令都没有执行
    - PC 所指向的指令的执行状态是已知的
* 非精确中断(imprecise interrupt)：不满足以上要求的中断，指令的执行时序和完成度具有不确定性，而且恢复起来也非常麻烦。
* 设备独立性(device independence)：我们编写访问任何设备的应用程序，不用事先指定特定的设备。比如你编写了一个能够从设备读入文件的应用程序，那么这个应用程序可以从硬盘、DVD 或者 USB 进行读入，不必再为每个设备定制应用程序。这其实就体现了设备独立性的概念。
* UNC(Uniform Naming Convention) ：UNC 是统一命名约定或统一命名约定的缩写，是用于命名和访问网络资源（例如网络驱动器，打印机或服务器）的标准。例如，在 MS-DOS 和 Microsoft Windows 中，用户可以通过键入或映射到类似于以下示例的共享名来访问共享资源。 `\\computer\path` 然而，在 UNIX 和 Linux 中，你会像如下这么写 `//computer/path`
* 由于CPU是串行的,因此对于单核CPU来说,同一时刻一定是只有一个线程在占用CPU资源的。因此，Linux作为一个多任务(进程)系统，会频繁的发生进程/线程切换
* CPU上下文：在每个任务运行前，CPU都需要知道从哪里加载，从哪里运行，这些信息保存在CPU寄存器和操作系统的程序计数器里面
* 现代的cpu提供了对单一变量简单操作的原子指令，即这个变量的这些简单操作只需要一条cpu指令即可完成，这样就不用对这个操作加互斥锁了，在锁冲突不激烈的情况下，减少了用户态和内核态的切换，化悲观锁为乐观锁，从而提高了效率。此外，现在外面很火的所谓无锁编程（类似CAS操作），底层就是用了这些原子操作。gcc为了方便程序员使用这些cpu原子操作，提供了一系列__sync开头的函数，这些函数如果包含内存屏障语义，则同时禁止编译器指令重排和cpu乱序执行。
* 并发控制
    - 现代操作系统以及硬件基本都支持并发程序
    - 在并发程序设计中，各个进程或者线程需要对公共变量的访问加以制约
    - 不同的进程或者线程需要协同工作以完成特征的任务，这就需要一套完善的同步机制
        + 在Linux内核中有相应的技术实现，包括原子操作，信号量，互斥锁，自旋锁，读写锁等。
        + InnoDB考虑到效率和监控两方面的原因，实现了一套独有的同步机制
* 错误处理(Error handling)：错误处理是指对软件应用程序中存在的错误情况的响应和恢复过程。
* 同步阻塞(synchronous)：同步是阻塞式的，CPU 必须等待同步的处理结果。
* 异步响应(asynchronous)：异步是由中断驱动的，CPU 不用等待每个操作的处理结果继而执行其他操作
* 缓冲区(buffering)：缓冲区是内存的临时存储区域，它的出现是为了加快内存的访问速度而设计的。对于经常访问的数据和指令来说，CPU 应该访问的是缓冲区而非内存
* Programmed input–output,PIO：它指的是在 CPU 和外围设备（例如网络适配器或 ATA 存储设备）之间传输数据的一种方法。
* 轮询(polling)：轮询是指通过客户端程序主动通过对每个设备进行访问来获得同步状态的过程。
* 忙等(busy waiting)：当一个进程正处在某临界区内，任何试图进入其临界区的进程都必须等待，陷入忙等状态。连续测试一个变量直到某个值出现为止，称为忙等。
* 可重入(reentrant)：如果一段程序或者代码在任意时刻被中断后由操作系统调用其他程序或者代码，这段代码调用子程序并能够正确运行，这种现象就称为可重入。也就是说当该子程序正在运行时，执行线程可以再次进入并执行它，仍然获得符合设计时预期的结果。
* 主设备编号(major device number)、副设备编号(minor device number) ：所有设备都有一个主，副号码。主号码是更大，更通用的类别（例如硬盘，输入/输出设备等），而次号码则更具体（即告诉设备连接到哪条总线）。
* 多重缓冲区(double buffering)：它指的是使用多个缓冲区来保存数据块，每个缓冲区都保留数据块的一部分，读取的时候通过读取多个缓冲区的数据进而拼凑成一个完整的数据。
* 环形缓冲区(circular buffer)：它指的是首尾相连的缓冲区，常用来实现数据缓冲流。
* 假脱机(Spooling) ：假脱机是多程序的一种特殊形式，目的是在不同设备之间复制数据。 在现代系统中，通常用于计算机应用程序和慢速外围设备（例如打印机）之间的中介。
* 守护进程(Daemon)：在计算机中，守护程序是作为后台进程运行的计算机程序，而不是在交互式用户的直接控制下运行的程序。
* 逻辑块寻址(logical block addressing, LBA)：逻辑块寻址是一种通用方案，用于指定存储在计算机存储设备上的数据块的位置。
33. FCFS (First-Come, First-Served)：先进先出的调度算法，也就是说，首先到达  CPU 的进程首先进行服务。
34. SSF (Shortest Seek First) 最短路径优先算法，这是对先进先出算法的改进，这种算法因为减少了总的磁臂运动，从而缩短了平均响应时间。
35. 稳定存储(stable storage)：它是计算机存储技术的一种分类，该技术可确保任何给定的写操作都具有原子性。
36. 时钟(Clocks)：也被称为 timers。通常，时钟是指调节所有计算机功能的时序和速度的微芯片。芯片中是一个晶体，当通电时，晶体会以特定的频率振动。任何一台计算机能够执行的最短时间是一个时钟或时钟芯片的一次振动。

## I/O（Input/Output）

* 输入输出的数据传输行为
* 磁盘IO：磁盘的输入输出，比如磁盘和内存之间的数据传输
    - 数据库查询或者写入数据
* 网络IO：不同系统间跨网络的数据传输
    - 网卡拷贝 => 内核空间缓冲区 => 用户空间中的应用程序缓冲区
    - 系统间的远程接口调用
    - 页面请求到服务器
    - 应用程序访问数据库
* 和CPU关系
    - 早期:磁盘和内存的数据传输由CPU控制，从磁盘读取数据到内存中，是CPU存储和转发，期间CPU一直会被占用.磁盘的读写速度远远比不上CPU的运转速度。在传输数据时就会占用大量CPU资源，造成CPU资源严重浪费
    - DMA(Direct Memory Access) 直接内存访问:专门控制磁盘IO,磁盘和内存间的数据传输前，CPU会给DMA发送指令，让DMA负责数据传输操作，数据传输完DMA再通知CPU,大大提高了CPU利用率.现在的计算机基本都采用DMA模式进行数据传输
* top 中的 IO Wait（wa）：wa只代表磁盘IO Wait，不包括网络IO Wait

## 链接

* 动态库、静态库，指的是程序编译的链接阶段，链接成可执行文件的方式
* 静态库:在链接阶段将汇编生成的目标文件.o 与引用到的库一起链接打包到可执行文件中，因此对应的链接方式称为静态链接（static linking）
* 动态库:在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此对应的链接方式称为动态链接（dynamic linking）
    - 节省磁盘空间，不同的程序可以共享常见的库
    - 节省内存，共享的库只需从磁盘中加载到内存一次，然后在不同的程序之间共享
    - 更便于维护，库文件更新后，不需要重新编译使用该库的所有程
* 90 年代的程序大多使用的是静态链接，因为当时的程序大多数都运行在软盘或者盒式磁带上，而且当时根本不存在标准库。这样程序在运行时与函数库再无瓜葛，移植方便
* 对于 Linux 这样的分时系统，会在在同一块硬盘上并发运行多个程序，这些程序基本上都会用到标准的 C 库，这时使用动态链接的优点就体现出来了。使用动态链接时，可执行文件不包含标准库文件，只包含到这些库文件的索引
* 动态库与共享库（shared libraries）相结合才能达到节省内存的功效。Linux 中动态库的扩展名是 .so（ shared object），而 Windows 中动态库的扩展名是 .DLL（Dynamic-link library）
* 解决缺少标准库
    - `gcc -o hello hello.c -static`
    - 拷贝库文件到镜像中,用 ldd 工具
    - 使用 busybox:glibc 作为基础镜像

```sh
ldd hello
    linux-vdso.so.1 (0x00007ffdf8acb000)
    libc.so.6 => /usr/lib/libc.so.6 (0x00007ff897ef6000)
    /lib64/ld-linux-x86-64.so.2 => /usr/lib64/ld-linux-x86-64.so.2 (0x00007ff8980f7000)
```

## 提高服务器的并发处理能力

* 提高CPU并发计算能力
    - 减少进程切换: 当硬件上下文频繁装入和移出时，所消耗的时间是非常可观的。可用Nmon工具监视服务器每秒的上下文切换次数.为了尽量减少上下文切换次数，最简单的做法就是减少进程数，尽量使用线程并配合其它I/O模型来设计并发策略
    - 减少使用不必要的锁:服务器处理大量并发请求时，多个请求处理任务时存在一些资源抢占竞争，这时一般采用“锁”机制来控制资源的占用
    - 考虑进程优先级 进程调度器会动态调整运行队列中进程的优先级，通过top观察进程的PR值
    - 考虑系统负载: 可在任何时刻查看/proc/loadavg, top中的load average也可看出
    - 考虑CPU使用率: 除了用户空间和内核空间的CPU使用率以外，还要关注I/O wait,它是指CPU空闲并且等待I/O操作完成的时间比例（top中查看wa的值）
* 考虑减少内存分配和释放
  - 通过改善数据结构和算法复制度来适当减少中间临时变量的内存分配及数据复制时间，而服务器本身也使用了各自的策略来提高效率
    + Apache,在运行开始时一次申请大片的内存作为内存池，若随后需要时就在内存池中直接获取，不需要再次分配，避免了频繁的内存分配和释放引起的内存整理时间
    + Nginx使用多线程来处理请求，使得多个线程之间可以共享内存资源，从而令它的内存总体使用量大大减少
    + Nginx分阶段的内存分配策略，按需分配，及时释放，使得内存使用量保持在很小的数量范围
  - 共享内存:在多处理器的计算机系统中，可以被不同中央处理器（CPU）访问的大容量内存，也可以由不同进程共享，是非常快的进程通信方式
    + shell命令ipcs可用来显示系统下共享内存的状态
    + 函数shmget可以创建或打开一块共享内存区
    + 函数shmat将一个存在的共享内存段连接到本进程空间
    + 函数shmctl可以对共享内存段进行多种操作，函数shmdt函数分离该共享内存
* 考虑使用持久连接(长连接):在一次TCP连接中持续发送多分数据而不断开连接,短连接是建立连接后发送一份数据就断开，然后再次建立连接发送下一份数据.是否采用持久连接，完全取决于应用特点。
    - 从性能角度看，建立TCP连接的操作本身是一项不小的开销，在允许的情况下，连接次数越少，越有利于性能的提升;尤其对于密集型的图片或网页等小数据请求处理有明显的加速所用
    - 长连接的有效使用，还有关键一点在于长连接超时时间的设置，即长连接在什么时候关闭吗？ Apache的默认设置为5s, 若这个时间设置过长，则可能导致资源无效占有，维持大量空闲进程，影响服务器性能
* 改进I/O 模型:
    - 网络I/O和磁盘I/O:速度要慢很多，尽管使用RAID磁盘阵列可通过并行磁盘磁盘来加快磁盘I/O速度，购买大连独享网络带宽以及使用高带宽网络适配器可以提高网络I/O的速度. 但这些I/O操作需要内核系统调用来完成，这些需要CPU来调度，这使得CPU不得不浪费宝贵的时间来等待慢速I/O操作
    - 希望让CPU足够少的时间在i/O操作的调度上，如何让高速的CPU和慢速的I/O设备更好地协调工作，是现代计算机一直探讨的话题。各种I/O模型的本质区别在于CPU的参与方式
    - DMA技术: I/O设备和内存之间的数据传输方式由DMA控制器完成。在DMA模式下，CPU只需向DMA下达命令，让DMA控制器来处理数据的传送，这样可以大大节省系统资源。
    - 异步I/O指主动请求数据后便可以继续处理其它任务，随后等待I/O操作的通知，这样进程在数据读写时不发生阻塞.是非阻塞的，当函数返回时，真正的I/O传输已经完成，这让CPU处理和I/O操作达到很好的重叠。
    - I/O多路复用
        + epoll服务器同时处理大量的文件描述符是必不可少的，若采用同步非阻塞I/O模型，若同时接收TCP连接的数据，就必须轮流对每个socket调用接收数据的方法，不管这些socket有没有可接收的数据，都要询问一次。假如大部分socket并没有数据可以接收，那么进程便会浪费很多CPU时间用于检查这些socket有没有可以接收的数据。
        + 多路I/O就绪通知的出现，提供了对大量文件描述符就绪检查的高性能方案，它允许进程通过一种方法同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行数据访问
        + epoll可以同时支持水平触发和边缘触发，理论上边缘触发性能更高，但是代码实现复杂，因为任何意外的丢失事件都会造成请求处理错误。
        + epoll主要有2大改进：
          * epoll只告知就绪的文件描述符，而且当调用epoll_wait()获得文件描述符时，返回并不是实际的描述符，而是一个代表就绪描述符数量的值，然后只需去epoll指定的一个数组中依次取得相应数量的文件描述符即可。 这里使用了内存映射(mmap)技术，这样彻底省掉了这些文件描述符在系统调用时复制的开销。
          * epoll采用基于事件的就绪通知方式。其事先通过epoll_ctrl()注册每一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似callback的回调机制，当进程调用epoll_wait()时得到通知
    - Sendfile
        + 处理这些请求时，磁盘文件的数据先经过内核缓冲区，然后到用户内存空间，不需经过任何处理，其又被送到网卡对应的内核缓冲区，接着再被送入网卡进行发送.Linux提供sendfile()系统调用，可以讲磁盘文件的特定部分直接传送到代表客户端的socket描述符，加快了静态文件的请求速度，同时减少CPU和内存的开销
        + 适用场景：对于请求较小的静态文件，sendfile发挥的作用不那么明显，因发送数据的环节在整个过程中所占时间的比例相比于大文件请求时小很多
    - 内存映射
        + Linux内核提供一种访问磁盘文件的特殊方式，它可以将内存中某块地址空间和我们指定的磁盘文件相关联，从而对这块内存的访问转换为对磁盘文件的访问。这种技术称为内存映射。
        + 多数情况下，内存映射可以提高磁盘I/O的性能，无须使用read()或write()等系统调用来访问文件，而是通过mmap()系统调用来建立内存和磁盘文件的关联，然后像访问内存一样自由访问文件。
        + 缺点：在处理较大文件时，内存映射会导致较大的内存开销，得不偿失。
    - 直接I/O
        + 在linux 2.6中，内存映射和直接访问文件没有本质差异，因为数据需要经过2次复制，即在磁盘与内核缓冲区之间以及在内核缓冲区与用户态内存空间。
        + 引入内核缓冲区的目的在于提高磁盘文件的访问性能，然而对于一些复杂的应用，比如数据库服务器，它们为了进一步提高性能，希望绕过内核缓冲区，由自己在用户态空间实现并管理I/O缓冲区，比如数据库可根据更加合理的策略来提高查询缓存命中率。
        + 另一方面，绕过内核缓冲区也可以减少系统内存的开销，因内核缓冲区本身就在使用系统内存。
        + Linux在open()系统调用中增加参数选项O_DIRECT,即可绕过内核缓冲区直接访问文件,实现直接I/O。
        + 在Mysql中，对于Innodb存储引擎，自身进行数据和索引的缓存管理，可在my.cnf配置中分配raw分区跳过内核缓冲区，实现直接I/O
* 改进服务器并发策略:并发策略的目的，是让I/O操作和CPU计算尽量重叠进行，一方面让CPU在I/O等待时不要空闲，另一方面让CPU在I/O调度上尽量花最少的时间
    - 一个进程处理一个连接，非阻塞I/O:这样会存在多个并发请求同时到达时，服务器必然要准备多个进程来处理请求。其进程的开销限制了它的并发连接数。 但从稳定性和兼容性的角度，则其相对安全，任何一个子进程的崩溃不会影响服务器本身，父进程可以创建新的子进程；这种策略典型的例子就是Apache的fork和prefork模式。 对于并发数不高（如150以内）的站点同时依赖Apache其它功能时的应用选择Apache还是可以的。
    - 一个线程处理一个连接，非阻塞IO 这种方式允许在一个进程中通过多个线程来处理多个连接，一个线程处理一个连接。Apache的worker模式就是这种典型例子，使其可支持更多的并发连接。不过这种模式的总体性能还不如prefork，所以一般不选用worker模式。推荐阅读：14个Java并发容器。
    - 一个进程处理多个连接，异步I/O 一个线程同时处理多个连接，潜在的前提条件就是使用IO多路复用就绪通知。这种情况下，将处理多个连接的进程叫做worker进程或服务进程。worker的数量可以配置，如Nginx中的worker_processes 4。
    - 一个线程处理多个连接，异步IO 即使有高性能的IO多路复用就绪通知，但磁盘IO的等待还是无法避免的。更加高效的方法是对磁盘文件使用异步IO，目前很少有Web服务器真正意义上支持这种异步IO

## 系统

* 最外层客户机Ubuntu
* 两三个小分区出来，可以装多个linux发行版
* 公用/home分区
    - 每次装linux，/直接装在其中一个小分区上，/home挂载到第三个主分区去，那里存放文档和代码数据的，这样有什么新的linux就装，文档一直在，
    - 可以装新linux时起个不重复的用户名，也在home下，完全不影响老的文档和使用环境配置
* 安装第二个Linux发行版的时候，需要注意的是，EFI分区和交换分区swap已经有可用的了，安装程序可以自动检测得到，因此不需要再关系这2个分区，只需要在磁盘剩余的空闲分区中创建这个系统本身需要的根分区/和/home分区

```sh
sudo update-grub
```

* 内核参数优化
* JVM优化
* 网络参数优化
* 事务优化
* 数据库优化
* 池化
* 内存溢出排查
* 堆外内存排查
* 网络排查
* I/O排查
* 高负载排查
* 流量录制

## 锁

* 互斥锁 :互斥锁有两层语义，除了大家都知道的排他性（即只允许一个线程同时访问）外，还有一层内存屏障（full memory barrier）的语义，即保证临界区的操作不会被乱序到临界区外。Pthread库里面常用的mutex，conditional variable等操作都自带内存屏障这层语义。此外，使用pthread库，每次调用都需要应用程序从用户态陷入到内核态中查看当前环境，在锁冲突不是很严重的情况下，效率相对比较低。
* 自旋锁 :传统的互斥锁，只要一检测到锁被其他线程所占用了，就立刻放弃cpu时间片，把cpu留给其他线程，这就会产生一次上下文切换。当系统压力大的时候，频繁的上下文切换会导致sys值过高。自旋锁，在检测到锁不可用的时候，首先cpu忙等一小会儿，如果还是发现不可用，再放弃cpu，进行切换。互斥锁消耗cpu sys值，自旋锁消耗cpu usr值。
* 递归锁 :如果在同一个线程中，对同一个互斥锁连续加锁两次，即第一次加锁后，没有释放，继续进行对这个锁进行加锁，那么如果这个互斥锁不是递归锁，将导致死锁。可以把递归锁理解为一种特殊的互斥锁。
* 死锁 :构成死锁有四大条件，其中有一个就是加锁顺序不一致，如果能保证不同类型的锁按照某个特定的顺序加锁，就能大大降低死锁发生的概率，之所以不能完全消除，是因为同一种类型的锁依然可能发生死锁。另外，对同一个锁连续加锁两次，如果是非递归锁，也将导致死锁。
* 死锁(deadlock)：死锁常用于并发情况下，死锁 是一种状态，死锁中的每个成员都在等待另一个成员（包括其自身）采取行动。
* 活锁(Livelock)：活锁类似于死锁，不同之处在于，活锁中仅涉及进程的状态彼此之间不断变化，没有进展。举一个现实世界的例子，当两个人在狭窄的走廊里相遇时，就会发生活锁，每个人都试图通过移动到一边让对方通过而礼貌，但最终却没有任何进展就左右摇摆，因为他们总是同时移动相同的方式。
* 饥饿(starvation)：在死锁或者活锁的状态中，在任何时刻都可能请求资源，虽然一些调度策略能够决定一些进程在某一时刻获得资源，但是有一些进程永远无法获得资源。永远无法获得资源的进程很容易产生饥饿。
* 两阶段加锁(two-phase locking, 2PL)：经常用于数据库的并发控制，以保证可串行化 这种方法使用数据库锁在两个阶段：
    - 扩张阶段：不断上锁，没有锁被释放
    - 收缩阶段：锁被陆续释放，没有新的加锁
* 进程(Process) 本质就是操作系统执行的一个程序
    - 与每个进程相关的是地址空间(address space)，这是从某个最小值的存储位置(通常是零)到某个最大值的存储位置的列表。在这个地址空间中，进程可以进行读写操作
    - 地址空间中存放有可执行程序，程序所需要的数据和它的栈
    - 与每个进程相关的还有资源集，通常包括寄存器(registers)（寄存器一般包括程序计数器(program counter)和堆栈指针(stack pointer)）、打开文件的清单、突发的报警、有关的进程清单和其他需要执行程序的信息
    - 对进程建立一种直观感觉的方式是考虑建立一种多程序的系统。考虑下面这种情况： 用户启动一个视频编辑程序，指示它按照某种格式转换视频，然后再去浏览网页。同时，一个检查电子邮件的后台进程被唤醒并开始运行
    - 操作系统周期性的挂起一个进程然后启动运行另一个进程，这可能是由于过去一两秒钟程序用完了 CPU 分配的时间片，而 CPU 转而运行另外的程序。 像这样暂时中断进程后，下次应用程序在此启动时，必须要恢复到与中断时刻相同的状态，这在用户看起来是习以为常的事情，但是操作系统内部却做了巨大的事情
    - 挂起时该进程的所有信息都要被保存下来。例如，进程可能打开了多个文件进行读取。与每个文件相关联的是提供当前位置的指针（即下一个需要读取的字节或记录的编号）必须要保存这些指针，以便在重新启动进程后执行的 read调用将能够正确的读取数据
    - 与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为 进程表(process table)，进程表是数组或者链表结构，当前存在每个进程都要占据其中的一项
    - 一个挂起的进程包括：进程的地址空间（往往称作磁芯映像， core image，纪念过去的磁芯存储器），以及对应的进程表项（其中包括寄存器以及稍后启动该进程所需要的许多其他信息）
    - 与进程管理有关的最关键的系统调用往往是决定着进程的创建和终止的系统调用
    - 一个进程能够创建一个或多个进程（称为子进程），而且这些进程又可以创建子进程
    - 进程间通信(interprocess communication)：合作完成某些作业的相关进程经常需要彼此通信来完成作业
    - 系统管理器授权每个进程使用一个给定的 UID(User IDentification)。每个启动的进程都会有一个操作系统赋予的 UID，子进程拥有与父进程一样的 UID。用户可以是某个组的成员，每个组也有一个 GID(Group IDentification)
    - 在 UNIX 操作系统中，有一个 UID 是 超级用户(superuser)，或者 Windows 中的管理员(administrator)，它具有特殊的权利，可以违背一些保护规则
* 地址空间
* 虚拟内存

## 触摸板

* 选择项目：点击触摸板。
* 滚动：将两个手指放在触摸板上，然后以水平或垂直方向滑动。
* 放大或缩小：将两个手指放在触摸板上，然后收缩或拉伸。
* 显示更多命令（类似于右键单击）：使用两根手指点击触摸板，或按右下角。
* 查看所有打开的窗口：将三根手指放在触摸板上，然后朝外轻扫。
* 显示桌面：将三根手指放在触摸板上，然后朝里轻扫。
* 在打开的窗口之间切换：将三根手指放在触摸板上，然后向右或向左轻扫。
* 打开 Cortana：用三根手指点击触摸板。
* 打开操作中心：用四根手指点击触摸板。
* 切换虚拟桌面：将四根手指放在触摸板上，然后向右或向左轻扫。
* 三指
    - 上：多任务视图
    - 下：显示桌面
    - 左：切换应用
    - 右：切换应用
* 四指
    - 上：多任务视图
    - 下：显示桌面
    - 左：切换桌面
    - 右：切换桌面

## 中国操作系统往事

* 红旗Linux往事
    - 国产操作系统第一次对国际巨头发起挑战。从上世纪90年代开始，以中科院院士倪光南、中科院软件研究所副所长孙玉芳为首的一批科学家，在“中国必须拥有自主知识软件操作系统”的共识下，推出国产操作系统红旗Linux。2000年，在红旗Linux发布半年后，中科院软件所和上海联创以6:4的出资方式，共同成立了中科红旗。
    - 红旗Linux曾有过“辉煌时刻”，在成立仅1年后，红旗Linux成为北京市政府采购的中标平台。这次采购在行业内影响重大，当时，包括红旗、永中、金山等国产软件均中标，而微软却意外出局。此后不久，微软中国总裁高群耀辞职，据内部人士透露，此次为“被迫辞职”，原因与业绩不佳有关。
    - 在微软价格高企、盗版Windows猖獗的当时，在政府订单之外，为了降低成本，联想、戴尔、惠普等公司也曾预装红旗系统。上线一年多以后，时任中科红旗总裁的刘博表示，国内Linux 的使用量比去年增加3、4倍，已经达到100万套。
    - 正如倪光南所说，操作系统的成功与否，关键在于生态系统，需要能够搭建起完整的软件开发者、芯片企业、终端企业、运营商等产业链上的各个主体。出于这样的考虑，2002年，红旗宣布与国产办公软件永中合作，将红旗Linux和永中Office联合销售。
    - 正是软件，成为国产操作系统的致命伤。作为倪光南的助手，梁宁在2000年到2002年期间参与了Linux、永中office联合销售相关的工作。她回忆这段历史时，提到当时一个“要命的问题”：永中office、金山WPS等国产软件均基于Linux，这也意味着，他们与微软Office有兼容性问题。
    - 时任北京市科委主任的俞慈声带头启动“启航工程”，召集中、日、韩三国技术人员，一起研究如何破解微软的文档格式，以实现读写和存储的完美兼容，但效果并不理想。我们“没有搞定用户体验”，梁宁写到。
    - 2005年，中科红旗董事长、国产系统力主者孙玉芳突发脑溢血去世，此后，公司连续曝出合资各方意见不一、管理不善等问题。 两年以后，微软向国际标准化组织提交了自己的office标准OOXML；与此同时，金山、红旗、永中等国内办公软件企业联合提出的UOF被确立为中国国家标准。制定标准者能够决定市场走向，早已是业内共识，在国际标准争论中，倪光南四处奔走，希望中国投出反对票，在他看来，OOXML一旦通过，中国软件及操作系统将面临空前压力。
    - 最终，微软仍然以51票支持、18票反对获胜。 伴随着微软在全球包括中国市场压倒性优势的胜利，国产桌面操作系统日渐式微，其余国产操作系统中标麒麟、StartOS也鲜有用户。 2011年，永中科技宣告破产，2年后，中科红旗贴出清算公告，宣布团队解散。
* 运营商抢跑手机操作系统
    - 在iPhone问世的2007年底，Android（安卓）操作系统发布1.0版本，婴儿期的安卓系统优势并不明显。次年推出的HTC G1是世界上首个使用Android操作系统的智能手机产品，但因卡顿、死机问题显著，销量平平。彼时，在智能手机系统中，iOS、Android、微软、诺基亚“塞班”都在争夺着未来。
    - 在中国，首个宣布推出国产手机操作系统的是中国移动。2008年，这款名为OMS的系统上线，号称要与Android并驾齐驱，打破几大国外智能系统的垄断。 OMS基于Linux内核、采用Android源代码进行开发，去掉google搜索、邮件等服务，集合中国移动的飞信、139邮箱等，并首批搭载于联想的移动定制机OPhone上。依照中国移动的想法，这是一种软硬结合的发展方式，可以“掌控移动互联网平台的入口”。 单以时间看，OMS操作系统可以说是抢占了先机，然而，由于基于安卓开发，而当时的安卓成熟度较低、经移动修改后体验更差。OMS手机上市后，许多用户购买联想OPhone的第一件事是手动刷机，换成其它系统。
    - 由于反响惨淡，市场推广局面不利，几年之后，中国移动不再要求定制机搭载OMS系统，“首个国产智能手机系统”也逐渐悄无声息。 关于OMS的另一个争议是，这究竟是否是一个独立于安卓生存的操作系统？经过当时的许多技术人士分析，尽管OMS强调自己是自主系统，甚至在初期选择不兼容安卓应用，但事实上，OMS仍对安卓高度依赖，并需要跟随后者的升级而升级。 严格意义上，第一款“独立国产智能手机系统”的名号应该颁发给2年后发布的联通沃Phone系统。在发布当时，中国联通科技委主任刘韵洁即强调：“沃Phone与Android没有任何关系。沃Phone拥有完全自主知识产权。”正因如此，沃Phone系统也得到了国家级的多项支持，被列为国家核心核心电子器件、高端通用芯片及基础软件产品重大科技专项支持的课题成果。
    - 不过，作为运营商，联通推出沃Phone系统的目的主要是置入自有业务，而并非抢夺市场。甚至，因为当时联通正在依托苹果iPhone的销售追赶移动，在沃Phone推广上，也平衡了这一部分利益。种种原因之下，沃Phone具备多种“先天劣势”：系统仅用于1000元到2000元的低端机、不兼容安卓应用、对每家手机厂商收取30元/台手机授权费。 更糟糕的是 ，尽管沃Phone只比移动OMS系统晚了两年，但在2011年，手机系统市场格局已是天翻地覆：OMS上线时，安卓尚仅仅占据5%市场份额，然而；伴随着三星Galaxy S的大获成功，安卓系统飞速增长，至2011年，其已经拥有超过50%的市占率，自此后，更是对市场中的其它系统呈现碾压之势。沃Phone一路溃败，2014年，其研发团队——深圳全智达通信宣布公司被同洲电子以2983.31万元全资收购。
* 阿里云OS的倔强与短暂辉煌
    - 时任阿里巴巴CTO、阿里云总裁的王坚曾透露说，最早，阿里希望直接进入手机市场，甚至与富士康等企业进行过洽谈，并与中国电信谈好了话费分成，但却在最后拍板时，选择了停止。“几个高管一起决定的，”他说，“手机不是阿里能做的，售后、库存，都是互联网公司不曾遇到的，这不是阿里的核心竞争力”。
    - 退而求其次的阿里云选择了开发手机操作系统。摆在王坚面前的有两个选择，一是做安卓系统的再开发，二是研发对标安卓的自主系统。日后人们会知道，腾讯和百度、小米和华为等多家科技企业，均选择了前一种方案——毕竟，在已经势如破竹的安卓系统面前，坚持独立无异于自寻死路。
    - 在王坚的坚持下，阿里云OS成为第一款由互联网企业打造的自主操作系统。阿里云率先和天语、海尔合作推出手机。然而，当阿里云进一步与宏碁手机合作时，在2012年9月13日的发布会开始前一小时，由于受到谷歌施压，宏碁取消了这次合作。
    - “如果在新产品上搭载阿里云操作系统，谷歌公司将会解除与其安卓产品的合作和相关技术授权”。”根据一财报道，阿里云在当时的官方声明中这样写道。 之后不久，谷歌确认了这一消息，他们同时带来了一个坏消息——在声明中，谷歌将一贯宣称为自主操作系统的阿里“云OS”定义为“非兼容版安卓系统”，意味，虽然云OS不兼容安卓应用，但仍然是一个变形版的“安卓”。
    - 无论结论如何，这次纷争对于云OS是一次重大打击。谷歌能够要求宏碁停止与阿里合作，因为宏碁属于OHA（开放手机联盟），这是一个由谷歌发起的组织，成员可以提前获得新版安卓，在海外市场认可度极高。 彼时，国内华为、中兴、联想、OPPO，国外摩托罗拉、三星、LG、索爱等主流手机企业，均为OHA成员。阿里云与宏碁合作流产，昭示着与这些品牌合作的可能均付之东流。
    - 2012年9月20日，阿里宣布YunOS将独立于阿里云事业群运行，受阿里巴巴集团直接管理。此外，阿里宣称，YunOS成为阿里巴巴集团的战略级产品，将向其投入2亿美金。 2013年3月2日，YunOS网站上线，系统名称也从阿里云OS更名为阿里巴巴YunOS。

## 手机系统

* Aurora

## VM

* VMM (Virtual Machine Monitor)：也被称为 hypervisor，在同一个物理机器上创建出来多态虚拟机器的假象。
* 虚拟化技术(virtualization)：是一种资源管理技术，将计算机的各种实体资源（CPU、内存、磁盘空间、网络适配器等），进行抽象、转换后呈现出来并可供分割、组合为一个或多个电脑配置环境。
* 云(cloud)：云是目前虚拟机最重要、最时髦的玩法。
* 解释器(interpreter)：解释器是一种程序，能够把编程语言一行一行解释运行。每次运行程序时都要先转成另一种语言再运行，因此解释器的程序运行速度比较缓慢。它不会一次把整个程序翻译出来，而是每翻译一行程序叙述就立刻运行，然后再翻译下一行，再运行，如此不停地进行下去。
* 半虚拟化(paravirtualization)：半虚拟化的目的不是呈现出一个和底层硬件一摸一样的虚拟机，而是提供一个软件接口，软件接口与硬件接口相似但又不完全一样。
* 全虚拟化(full virtualization)：全虚拟化是硬件虚拟化的一种，允许未经修改的操作系统隔离运行。对于全虚拟化，硬件特征会被映射到虚拟机上，这些特征包括完整的指令集、I/O操作、中断和内存管理等。
* 客户操作系统(guest operating system) : 客户操作系统是安装在计算机上操作系统之后的操作系统，客户操作系统既可以是分区系统的一部分，也可以是虚拟机设置的一部分。客户操作系统为设备提供了备用操作系统。
* 主机操作系统(host operating system)：主机操作系统是计算机系统的硬盘驱动器上安装的主要操作系统。在大多数情况下，只有一个主机操作系统。

## 图书

* 《深入理解计算机系统》

## 参考

* [cfenollosa/os-tutorial](https://github.com/cfenollosa/os-tutorial):How to create an OS from scratch
* [30dayMakeOS](git@github.com:yourtion/30dayMakeOS.git)
