# Service Mesh 服务网格

* Service Mesh 本质上就是微服务的动态链接器（Dynamic Linker）。基础是一个网络代理，这个网络代理会接管微服务的网络流量，然后通过一个中央控制面板进行管理，将这些流量转发到该去的地方，并在这个代理的基础之上，扩展出一系列的流量监控、限流、熔断甚至是灰度发布、分布式跟踪等能力，而不需要应用本身做出任何修改，让开发者摆脱了 SDK 之苦，也避免了由于 SDK 使用不当造成的一系列问题。同时，这个代理工作是在网络层，一般情况下也不会成为性能瓶颈。
* 由开发 Linkerd 的 Buoyant 公司提出，并于 2016 年 9 月29 日第一次公开使用了这一术语。William Morgan，Buoyant CEO，对 Service Mesh 这一概念定义如下
  - A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application.
  - In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware
* 服务网格（ Service Mesh ）是解决微服务之间的网络问题和可观测性问题的(事实)标准，并且正在走向标准化
  - 应用程序间通讯中间层
  - 轻量级网络代理
  - 应用程序无感知
  - 解耦应用程序的重试/超时、监控、追踪和服务发现
* 特点
  - 本质：基础设施层；
  - 功能：请求分发；
  - 部署形式：网络代理；
  - 特点：透明；
* 功能
  - 流量控制: (路由,流量转移,超时重试, 熔断,故障注入,流量镜像)
  - 策略 (限流、黑白名单)
  - 网络安全 (授权与身份认证)
  - 可观察性 (指标、日志、追踪)
* 局限性。
  - 增加了复杂度。服务网格将 sidecar 代理和其它组件引入到已经很复杂的分布式环境中，会极大地增加整体链路和操作运维的复杂性。
  - 运维人员需要更专业。在容器编排器（如 Kubernetes）上添加 Istio 之类的服务网格，通常需要运维人员成为这两种技术的专家，以便充分使用二者的功能以及定位环境中遇到的问题。
  - 延迟。从链路层面来讲，服务网格是一种侵入性的、复杂的技术，可以为系统调用增加显著的延迟。这个延迟是毫秒级别的，但是在特殊业务场景下，这个延迟可能也是难以容忍的。
  - 平台的适配。服务网格的侵入性迫使开发人员和运维人员适应高度自治的平台并遵守平台的规

## 历程

* 原始的主机之间直接使用网线相连
* 网络层的出现
* 出现网络层（4层协议）控制的需求
* 控制逻辑下移到网络
* 出现新的应用层（7层协议）需求（服务发现、熔断、超时重试等）
* 封装成三方库（服务发现：Dubbo/HSF）
  - 原本在进程中互相调用那么简单的事情，都要变成一次在 7 层网络上的远程调用
  - 原本公共工具类做的事情，现在需要写成二方库 SDK 等，在每一个进程中使用，版本迭代成为了灾难
  - 原本是内部透明调用的不需要做任何防护，分离后却要额外增加安全防护和隔离的工作
  - 不再是代码即文档，需要维护大量的 API 定义和版本管理
* Sidecar模式：通过给应用服务加装一个“边车”来达到控制和逻辑的分离的目的

  - 服务网格技术中常用的(其中)一种设计架构，在 Kubernates 中，不同的容器允许被运行在同一个 Pod 中（即多个进程运行在同一个 cgroup 下），这在很大程度上给 Sidecar 模式提供了良好的土壤
  - 微服务之间的调用在架构图中是横向的，被称为东西流量。服务暴露到外部被公网可见的外部调用，被称为南北流量
  - Consumer 与 Provider 就是微服务互相调用的一种解决方案
  - Dubbo 架构：解决的正是东西流量的问题
    + 基于 SPI 机制以一种较为隔离的方式侵入到运行时的代码中
    + 只能限定 Java 这样被官方支持的语言来开发服务应用
  - 问题：流量管理（服务发现、负载均衡、路由、限流、熔断、容错等）、可观测性（监控、日志聚合、计量、跟踪）、安全（认证、授权），再甚至更高级的动态配置、故障注入、镜像流量等
  - Sidecar 的模式更为巧妙并更进一步。通过容器机制，在进程上是隔离的，基于 L7 代理进行通讯，允许微服务是由任何语言进行开发的

* 所有使用中间件的服务组成了一个大的服务网格。服务网格基于 Kubernates 这样的容器技术，将东西流量的问题解决得更加透明无感

* 通讯层的实现方式，有以下选择：

  - 用库的形式在微服务应用程序中导入使用:每个微服务应用程序包中都有实现Service Mesh功能的库。像Hystrix和Ribbon就是用库的方法
    + 调用方式是进程内的，没有安全隔离的包袱
    + 随着编程语言的发展，新的语言为特定的场景而生，而SDK库的方式限制了使用方必须用支持列表中的语言,用不同语言去重复实现多次，挑战在于实现的复杂性和一遍又一遍去实现同样概念的工作量
  - 节点代理或守护程序的形式为特定节点/计算机上的所有容器提供服务
    + 每个节点上都运行一个单独的代理（通常是用户进程），为异构的服务提供负载
    + 代理接口的调用路由规则，转发到特定的机器
    + 使用一个特定的服务专门代理微服务中的请求，是一个中间人的角色。但这个代理人的安全性要求非常高，因为需要处理来自不同微服务的请求，并鉴别它们各自的身份
    + 由于每个节点上都需要一个节点代理，因此需要与基础架构进行一些协作，如果没有协作的话此模型就无法工作
    + 强调工作资源共享，如果节点代理用一些内存来缓存微服务的数据，那么服务就可能会在几秒钟内转向并使用该缓存区提供的数据
  - 用Sidecar容器的形式运行，和应用容器一同运行:透明地劫持所有应用容器的出入流量：介于 SDK 库和节点代理中间的一种形式，相当于是给每个微服务都配上一个自己独有的代理，每个微服务自己的 Sidecar 就代表了自己特定的身份，有利于调用的安全审计

## Sidecar 模式

* 每个服务都额外部署这个代理组件，所有出站入站的流量都通过该组件进行处理和转发。这个组件被称为Sidecar,Sidecar会和微服务节点部署在同一台主机上并且共用相同的虚拟网卡。所以Sidecar和微服务节点的通信实际上都只是通过内存拷贝实现的
* Sidecar只负责网络通信。还需要有个组件来统一管理所有sidecar的配置。在Service Mesh中，负责网络通信的部分叫数据平面(data plane)，负责配置管理的部分叫控制平面(control plane)。数据平面和控制平面构成了Service Mesh的基本架构
* 允许为应用程序添加许多功能，而无需额外第三方组件的配置和代码的修改
* 概念
  - Sidecar 模式：容器应用模式之一，Service Mesh 架构的一种实现方式
  - Init 容器：Pod 中的一种专用的容器，在应用程序容器启动之前运行，用来包含一些应用镜像中不存在的实用工具或安装脚本
    + 使用 Linux Namespace，所以相对应用程序容器来说具有不同的文件系统视图
  - iptables：流量劫持是通过 iptables 转发实现的，含 5 张表：
    + raw 用于配置数据包，raw 中的数据包不会被系统跟踪
    + filter 是用于存放所有与防火墙相关操作的默认表
    + nat 用于 网络地址转换（例如：端口转发）
    + mangle 用于对特定数据包的修改（参考损坏数据包）
    + security 用于强制访问控制 网络规则
  - 东西向通讯：指服务间的相互访问，其通讯流量在服务间流转，流量都位于系统内部；
  - 南北向通讯：指服务对外部提供访问，通常是通过 API Gateway 提供的 API 对外部暴露，其通讯流量是从系统外部进入系统内部
* 步骤：
  - Kubernetes 需要了解待注入的 sidecar 所连接的 Istio 集群及其配置
  - Kubernetes 需要了解待注入的 sidecar 容器本身的配置，如镜像地址、启动参数等
  - Kubernetes 根据 sidecar 注入模板和以上配置填充 sidecar 的配置参数，将以上配置注入到应用容器的一侧
* Sidecar 模式解决微服务之间的网络通讯（远程调用）
* 与网关模式有类似之处，但是其粒度更细。其为每个服务都配备一个“边车”，这个“边车“可以理解为一个 agent ，这个服务所有的通信都是通过这个 agent 来完成的，这个 agent 同服务一起创建，一起销毁。像服务注册、服务发现、监控、流量控制、日志记录、服务限流和服务熔断等功能完全可以做成标准化的组件和模块，不需要在单独实现其功能来消耗业务开发的精力和时间来开发和调试这些功能，这样可以开发出真正高内聚低耦合的软件
* 优势
  - 通过抽象出与功能相关的共同基础设施到一个不同层降低了微服务代码的复杂度
  - 因为不再需要编写相同的第三方组件配置文件和代码，所以能够降低微服务架构中的代码重复度
  - 降低应用程序代码和底层平台的耦合度
* Istio CNI 插件设计目标是消除这个 privileged 权限的 init container，换成利用 Kubernetes CNI 机制来实现相同功能的替代方案

## 原理

* 服务网格中分为控制平面和数据平面，当前流行的两款开源的服务网格 Istio 和 Linkerd 实际上都是这种架构
* Istio 的划分更清晰，而且部署更零散，很多组件都被拆分，控制平面中包括 Mixer、Pilot、Citadel，数据平面默认是用 Envoy
* Linkerd 中只分为 Linkerd 做数据平面，namerd 作为控制平面
* 控制平面
  - 不直接解析数据包
  - 与数据平面中的代理通信，下发策略和配置
  - 负责网络行为的可视化
  - 通常提供 API 或者命令行工具可用于配置版本化管理，便于持续集成和部署
* 数据平面
  - 通常是按照无状态目标设计的，但实际上为了提高流量转发性能，需要缓存一些数据，因此无状态也是有争议的
  - 直接处理入站和出站数据包，转发、路由、健康检查、负载均衡、认证、鉴权、产生监控数据等
  - 对应用来说透明，即可以做到无感知部署

## 服务网格

* 从总体架构上来讲比较简单，不过是一堆紧挨着各项服务的用户代理，外加一组任务管理流程组成。代理在服务网格中被称为数据层或数据平面（data plane），管理流程被称为控制层或控制平面（control plane）。数据层截获不同服务之间的调用并对其进行“处理”；控制层协调代理的行为，并为运维人员提供 API，用来操控和测量整个网络
* 一个专用的基础设施层，旨在“在微服务架构中实现可靠、快速和安全的服务间调用”。它不是一个“服务”的网格，而是一个“代理”的网格，服务可以插入这个代理，从而使网络抽象化
* 典型的服务网格中，这些代理作为一个 sidecar（边车）被注入到每个服务部署中。服务不直接通过网络调用服务，而是调用它们本地的 sidecar 代理，而 sidecar 代理又代表服务管理请求，从而封装了服务间通信的复杂性。相互连接的 sidecar 代理集实现了所谓的数据平面，这与用于配置代理和收集指标的服务网格组件（控制平面）形成对比
* 控制平面
  - 特点：
    + 不直接解析数据包；
    + 与控制平面中的代理通信，下发策略和配置；
    + 负责网络行为的可视化；
    + 通常提供 API 或者命令行工具可用于配置版本化管理，便于持续集成和部署；
* 数据平面
  - 特点：
    + 通常是按照无状态目标设计的，但实际上为了提高流量转发性能，需要缓存一些数据，因此无状态也是有争议的；
    + 直接处理入站和出站数据包，转发、路由、健康检查、负载均衡、认证、鉴权、产生监控数据等；
    + 对应用来说透明，即可以做到无感知部署；
* 带来变革
  - 微服务治理与业务逻辑的解耦
  - 异构系统的统一治理

## 实现服务网格的方法

* 改进微服务的消息处理机制。服务网格确保你能监控到整个架构层，不仅可以跟踪到网络中的服务器地址，还可以跟踪到传达服务器地址信息的消息。例如，你可能想要跟踪“失败”消息，但这些消息在传统云架构中通常会丢失。服务网格的好处是既可以确保消息的传递，又会在消息未到达目的地时返回错误信息。
* 利用与传统应用程序相同的运维方式。对于企业级网络来说，可定制性和灵活性是最重要的。服务网格是为适应现代分布式应用程序而设计的。但是底层的技术如入口控制器，负载均衡器，以及代理都和传统单体应用的数据层面的技术相同。在实现服务网格的过程中，组织可以利用到与运营现代、基于软件的应用程序交付基础设施相同的技术与技能。
* 灵活使用多种云服务。服务网格解决了现代应用的云网络问题。支撑起服务网格的数据平面和控制平面的技术独立于任何特定架构，因此它们可以在无论是裸机，容器还是虚拟机的公有或私有的架构上运行。这种灵活特性甚至允许服务网格处理未来的应用程序架构，从而发挥其规模化、全球复制以及深层性能调节等优势。您的服务网格将成为运作模式化云架构场景下，一切潜在优势的实现保障。
* 提高对微服务的可见性。分布式系统的指标对于我们而言就像是一个黑盒子，而网格服务为我们提供了一种更深入观察分布式系统的指标的途径。它会随时间收集性能指标，为团队提供服务可用性的长期指标。这为操作员提供了一种观察服务可靠性和性能的方式，使他们能够逐步优化系统。
* 更高效的运维以及更有效的执行SLA（服务等级协议）。服务网格提供的追踪功能对调试和故障排除至关重要，与此同时，它也确保服务执行了服务等级协议（SLA）。服务网格执行了很多任务，包括执行策略以及追踪查看这些策略是否被满足。它为管理者提供了一个可以在网络层实施云应用管理和策略的场所。
* 简化微服务实现。服务网格的另一大优点是可以轻松部署它们。过去的解决方案要求开发人员将服务内功能编码到每个微服务中。这需要重写应用程序并在不同的编程语言中维护各种库。而服务网格帮开发人员抽象了这些事务。开发人员可以简单地调用必要的消息传递和服务发现功能就可以轻松的部署它们，而微服务的源码只用包含业务逻辑相关的代码。
* 加快新服务的上线时间。过去的库解决方案，如Finagle，Hystrix和Stubby，需要开发人员长时间的介入并且迫使开发人员将冗余功能编码到每一个服务中。另一个更简单的方法是在每个微服务中放置一个sidecar代理并将它们连接在一起，这正是服务网格所擅长的，因此未来将会有更多的云应用选择服务网格架构。简而言之，服务网格保证了开发者的生产力，使他们能够更快地将更多的服务推向市场。
* 保障服务间的通信安全。服务之间通信有可能跨云，跨数据中心，或者跨大陆，而服务网格保障了这些通信的安全，它封装了所有的通信，并且在控制器层面协调这些通信，通过管道内加密，联系人策略和服务权限解决了安全问题。

## Service Mesh vs API Gateway

* 功能定位和承担的职责：
  - 位于最底层的是拆分好的原子微服务，以服务的形式提供各种能力；
  - 在原子微服务上是（可选的）组合服务，某些场景下需要将若干微服务的能力组合起来形成新的服务；
  - 原子微服务和组合服务部署于 系统内部，在采用 Service Mesh 的情况下，由 Service Mesh 提供服务间通讯的能力；
  - API Gateway 用于将系统内部的这些服务暴露给 系统外部，以 API 的形式接受外部请求
* 部署：
  - Service Mesh 部署在系统内部：因为原子微服务和组合服务通常不会直接暴露给外部系统；
  - API Gateway 部署在系统的边缘：一方面暴露在系统之外，对外提供 API 供外部系统访问；一方面部署在系统内部，以访问内部的各种服务；
* 当 Service Mesh 产品和 API Gateway 产品开始出现相互渗透时，两者的关系就开始变得暧昧.在 Service Mesh 出现之后，如何为基于 Service Mesh 的服务选择合适的 API Gateway 方案，就慢慢开始提上日程，而其中选择重用 Service Mesh 的能力也自然成为一个探索的方向，并逐步出现新式 API Gateway 产品

## 标准

* UDPA
* SMI

## 工具

* [kubernetes-vagrant-centos-cluster](https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster):Setting up a distributed Kubernetes cluster along with Istio service mesh locally with Vagrant and VirtualBox, only PoC or Demo use. <https://jimmysong.io>
* linkerd
* [envoy](./envoy.md):数据平面
* [lstio](./lstio.md)：增加控制平面，收购enovy
* AWS：App Mesh

## 参考

* [ServicemeshCN/awesome-servicemesh](https://github.com/ServicemeshCN/awesome-servicemesh):A curated list for awesome service mesh architectures <https://servicemesh.gitbooks.io/aweso>…
* [geektime-geekbang / geektime-servicemesh](https://github.com/geektime-geekbang/geektime-servicemesh)
* Pattern:service Mesh
