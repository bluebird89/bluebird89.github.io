# Data Structure

* 数据结构决定数据存储空间和时间效率问题
* 数据的写入和读取速度决定了应该选择怎样的数据结构,根据对场景需求不同，需要设计不同数据结构
  - 一次写入，多次写出
  - 写得多，读的少
  - 读写都多
* 如何把现实问题转化为计算机语言的表示：设计出数据结构， 在施加以算法就行
* 为了提高硬件利用率：内存是纳秒级的，而磁盘是毫秒级
  - 磁盘读取数据：机械运动，每次读取数据花费的时间可以分成：寻道时间、旋转延迟、传输时间三个部分。
    + 寻道时间指的是磁臂移动到指定磁盘所需要的时间，主流的磁盘一般在 5ms 以下；
    + 旋转延迟指的是我们经常说的磁盘转速，比如一个磁盘 7200 转，表示的就是每分钟磁盘能转 7200 次，转换成秒也就是 120 次每秒，旋转延迟就是 1/120/2=4.17ms；
    + 传输时间指的是从磁盘读取出数据或将数据写入磁盘的时间，一般都在零点几毫秒，相对于前两个，可以忽略不计。
    + 访问一次磁盘的时间，即一次磁盘 I/O 的时间约等于 5+4.17=9.17ms，9ms 左右，听起来还是不错的哈，但要知道一台 500-MIPS 的机器每秒可以执行 5 亿条指令，因为指令依靠的是电的性质，换句话说，执行一次 I/O 的时间可以执行 40 万条指令，数据库动辄百万级甚至千万级的数据，每次 9ms 的时间，显然是一个灾难。
* 一个负载稍高一点网站，不懂数据结构，都不知道性能曲线大概会怎么变，需要深度优化的时候怎么下手。

## 数组（顺序存储）：随机访问

* 在内存中存储一系列元素，所有元素的类型都必须相同
* 由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间
* 因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)
* 在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N)
* 优势
  - 读取 1
* 劣势
  - 查找 N
  - 插入 N 次移动 一次插入
  - 删除 一次删除 N-1 次移动
* 用一组连续的内存空间，来存储一组具有相同类型的数据,很容易地找出数组中任意一个元素的位置
* PHP 数组底层是通过散列表实现，功能异常强大
  - PHP 数组集成了 Java 的数组、List、Set、Map 于一身
  - 由于 PHP 不支持指针，所以不能实现真正的链表
* 优点
  - 查找:通过下标值随机访问数组内的任何元素，算法复杂度是 O(1)，非常高效
* 缺点
  - 删除/插入元素比较费劲,算法复杂度是 O(n)
  - 插入一个元素，需要把其余元素一个个往后移，以为新元素腾空间
  - 删除需要把被删除元素之后的元素一个个往前移
* 数组的性能高于链表,程序局部性原理
* 树状数组
* 矩阵
* 数组查找性能高，但是插入、删除性能差

## 线性表:排成一条线结构，只有前后两个方向,顺序存储

* 链表(Singly-linked List):物理存储单元上非连续的、非顺序的存储结构，通过指针来联系起一个个结点
  - 存储空间不连续，每个元素都存储了下一个元素的地址，不存在数组的扩容问题。无法根据一个索引算出对应元素的地址，所以不能随机访问
  - 单链表:每个结点包括数据和指针(存放下一结点的地址)
    + 第一个结点叫作头结点:用来记录链表的基地址,遍历得到整条链表
    + 最后一个结点叫作尾结点:指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点
    + 插入和删除节点的时间复杂度：需要获取其前驱节点，在单链表中获取前驱节点的时间复杂度是 O(n)
    + 查询节点的时间复杂度是 O(n)
    + 循环链表:在单链表的基础上,尾节点指向了头结点，从而首尾相连
  - 双向链表(Doubly-Linked List):每个结点中除了有一个指向下一个节点的指针外，还有一个用于指向上一个节点的指针，从而实现通过 O(1) 复杂度找到上一个节点
    + 插入、删除节点时比单链表更高效：时间复杂度才是真正的 O(1)
    + 查询效率也要高于单链表，不过更优的时间复杂度是靠更差的空间复杂度换取
    + 支持顺序查找和逆序查找
    + 不支持按某个值或区间的快速查找
    + 不支持数据的快速插入
  - 边界条件
    + 输入边界：用户输入参数
    + 特殊边界
  - 插入
    + 保存临时地址
    + 创建新结点，将新结点指针指向下一结点指针
    + 恢复临时指针指向新节点
  - 删除
    + 断开删除结点指针
    + 删除节点的前节点指针指向删除节点后节点
    + 另一种思路：删除节点指针 换掉 删除节点的前节点指针
  - 场景
    + 大内存空间分配：数组空间的连续性，如果要为数组分配 500M 的空间，这 500M 的空间必须是连续的，未使用的，所以在内存空间的分配上数组的要求会比较严格，如果内存碎片太多，分配连续的大空间很可能导致失败。而链表由于是非连续的
    + 元素频繁删除和插入
  - 如果数据以查为主，很少涉及到增和删，选择数组，如果数据涉及到频繁的插入和删除，或元素所需分配空间过大，倾向于选择链表
  - 以一个虚拟的节点作为头结点（哨兵）
  - 链表插入、删除性能高，但查找性能差
  - 参考
    + [双指针×链表问题：快慢指针](https://mp.weixin.qq.com/s?__biz=MzA5ODk3ODA4OQ==&mid=2648167055&idx=1&sn=0eae5debd1c012c16d939982e7dc48aa&chksm=88aa22c9bfddabdf4fb584057b563f4c26c62d177701c0255816b657f9adfa5ea8bf1c726be8)
* 跳跃表（skiplist)：在链表之上加上多层索引构成
  - 在原始链表基础上，增加了一个索引链表。原始链表每两个结点，有一个结点也在索引链表当中
  - 多层索引每一层索引的结点数量都是低层索引的一半:可以进一步提升查询效率
  - 原始链表有n个结点，索的层级就是log(n)-1，在每一层的访问次数是常量，因此查找结点的平均时间复杂度是O（logn）
  - 优化之后的数据结构所占空间，是原来的2倍
  - 可以与平衡树媲美的层次化链表结构，查找、删除、添加等操作都可以在对数期望时间下完成
  - 受多层链表（通过对一个元素添加多个指针）启发：为每个节点随机出一个层数(level).新插入一个节点并不会影响到其他节点的层数，因此，插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整，这就降低了插入操作的复杂度
  - 让新插入的结点随机“晋升”，也就是成为索引结点
  - 删除：需要顺藤摸瓜，把索引当中的对应结点也一一删除
  - 问题
    + 新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的 2:1 的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点） 重新进行调整，这会让时间复杂度重新蜕化成 O(n)。删除数据也有同样的问题
  - 特点
    + 跳表采用的是双向链表，无论前后结点还是上下结点，都各有两个指针相互指向彼此。
    + 跳表的每一层首位各有一个空结点，左侧的空节点是负无穷大，右侧的空节点是正无穷大。
* 链表数组：数组包含的每个元素都指向一个链表
* 操作
  - 遍历 + 访问
    + 线性就是 for/while 迭代为代表
    + 非线性就是递归为代表

## 散列表｜哈希表 hash table:哈希-》散列

* 散列函数:每次对同一字符串调用该散列函数，返回的都应是同一数字串
* 以 键-值（key-value） 存储数据的结构，只要输入待查找的值 key，就可以找到对应的值即 value，基于数组实现
  - 把 key 放在数组里，用一个哈希函数把 key 转换成一个确定的位置
  - 把 value 放在数组的这个位置
  - 当多个 key 值经过哈希函数的换算会出现同一个值的情况,会拉出一个链表进行存储
  - 同样输入必须返回同样输出
* 哈希算法：把任意值(key)通过哈希函数变换为固定长度的 key 地址，将输入映射为内存地址
  - 直接定址法：即 f(key) = a*key + b，f 表示散列函数，a、b 是常量，key 是键值
  - 数字分析法：即对数字做左移、右移、反转等操作获取散列值
  - 除数留余法：即 f(key) = key % p，p 表示容器数量，这种方式通常用在将数据存放到指定容器中，如何决定哪个数据放到哪个容器，比如分表后插入数据如何处理（此时 p 表示拆分后数据表的数量），分布式 Redis 如何存放数据（此时 p 表示几台 Redis 服务器）
  - 随机数法：即 f(key) = random(key)，比如负载均衡的 random 机制
  - MD5消息摘要算法 MD5 Message-Digest Algorithm:一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），MD5算法将数据（如一段文字）运算变为另一固定长度值，是散列算法的基础原理。由美国密码学家 Ronald Linn Rivest设计，于1992年公开并在 RFC 1321 中被加以规范。
  - 循环冗余校验（Cyclic Redundancy Check）是一种根据网络数据包或电脑文件等数据，产生简短固定位数校验码的一种散列函数，由 W. Wesley Peterson 于1961年发表。生成的数字在传输或者存储之前计算出来并且附加到数据后面，然后接收方进行检验确定数据是否发生变化。由于本函数易于用二进制的电脑硬件使用、容易进行数学分析并且尤其善于检测传输通道干扰引起的错误，因此获得广泛应用。
  - MurmurHash 一种非加密型哈希函数，适用于一般的哈希检索操作。由 Austin Appleby 在2008年发明，并出现了多个变种，与其它流行的哈希函数相比，对于规律性较强的键，MurmurHash的随机分布特征表现更良好
* 数据碰撞｜散列冲突：不同 key 计算出同一个结果
  - 开放定址法
    + 线性寻址表示出现散列冲突之后，就去寻找下一个空的散列地址；线性寻址步长是1
    + 二次探测步长是线性寻址步长的2次方，其它逻辑一样
    + 随机探测每次步长随机。不管哪种探测方法，散列表中空闲位置不多的时候，散列冲突的概率就会提高，为了保证操作效率，我们会尽可能保证散列表中有一定比例的空闲槽位，用装载因子来表示空位的多少，装载因子=填入元素/散列表长度，装载因子越大，表明空闲位置越少，冲突越多，散列表性能降低。
  - 分离链接｜链地址法：当冲突发生时，不是将值放到格子里，而是放到该格子所关联的数组｜链表中
  - 再次哈希法：发生散列冲突后，换一个散列函数计算散列值
  - 建立公共溢出区
* 效率：既要避免冲突，又要节约空间
  - 填装因子｜负载因子：值与位置的比值，度量散列表中有多少位置是空的
  - 填装因子越低，发生冲突的可能性越小
  - 一旦填装因子大于0.7，就调整散列表的长度
* 扩容
  - 调整长度(resizing)：一旦填装因子开始增大，需要在散列表中添加位置
    + 首先创建一个更长的新数组:通常将数组增长一倍
    + 使用函数hash将所有的元素都插入到这个新的散列表中
* 应用
  - 安全加密
  - 唯一标识
  - 数据校验
  - 散列函数
  - 负载均衡
  - 分布式缓存
* 访问|修改时间复杂度 O(1)
* 范围查询或者排序性能会非常差，只能进行全表扫描并依次判断是否满足条件
* 在不考虑散列冲突的话，散列表的插入、删除、查找性能都很高，但是前提是没有散列冲突
* 存储的数据是无序的，扩容非常麻烦，涉及到散列冲突时，性能不稳定
* 散列表用起来爽，构造起来可不简单，要考虑散列函数的设计、哈希冲突的解决、扩容缩容等一系列问题

## 队列 queue

* 一端插入，另一端删除,先入先出（First In First Out，FIFO）
  - 只能在末尾插入数据
  - 只能读取开头的数据
  - 只能移除开头的数据
* 允许插入的一端叫队尾，允许删除的一端叫队头。需要两个指针，一个指向队头，一个指向队尾
  - 顺序队列：通过数组实现:随着队列元素的插入和删除，队尾指针和队头指针不断后移，而导致队尾指针指向末尾无法插入数据
    + 循环队列，即把队列头尾连起来
    + 断队列是否为空的条件还是 tail==head，但是判断队列是否满的条件就变成了 (tail+1) % maxsize == head
    + 浪费一个空间是为了避免混淆判断空队列的条件
  - 链式队列：通过链表实现
* 多级反馈队列
* 操作
  - 入队
  - 出队
* [优先队列](https://mp.weixin.qq.com/s/FSp95Ot3SIaCpJyVtE1P_A)
  - 每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务
  - 操作：
    + 插入带优先级的元素
    + 取出具有最高优先级的元素
    + 查看最高优先级的元素
  - 实现
    + 有序序列:有序序列中存储的数据都是有序的，在执行extractmin获取最小值时复杂度O(1)，但是在添加新元素时就存在大量的移动和查找正确的位置最大复杂度O(N)，因此在insert和extactmin同时执行N次时，最大复杂度为O(N^2)
    + 无序序列:无序序列中存储的元素是无序的，在执行insert操作复杂度为O(1)，但是在extractmin时每次都要进行一次遍历复杂度为O(N)，因此在insert和extractmin同时执行N次时，最大复杂度为O(N^2)。
    + 堆结构:堆的insert不如无序序列那么随意，extractmin也没有有序序列那么容易，每次都需要进行siftup和siftdn操作进行调整，但是同时执行insert和extractmin时，复杂度是O(nlogn)，优于O(N^2)。
  - 自定义优先级模板优先队列参数：
    + 容器元素的类型
    + 存储数据所用的容器
    + 比较函数 缺省情况是less
  - 应用:获取数组第K大元素
    + 默认的优先队列本质上是大顶堆，那么堆顶就不是第K大元素了，但是从堆顶开始依次pop出K-1个元素，堆顶也就是第K大元素了
    + 是贪心算法的重要组成部分，借助于优先队列贪心算法可以解决非常多的实际问题包括：
      * 旅行商TSP问题
      * 01背包问题
      * 霍夫曼编码问题
      * 最短路径Dijkstra算法
      * 最小生成树Prim算法

## 栈 stack

* 限定只能在一端进行插入和删除操作的线性表,满足后进先出（LIFO）特点
  - 压栈：只能在末尾插入数据
  - 出栈：只能读取末尾的数据
  - 只能移除末尾的数据
* 栈顶:允许插入和删除的一端，另一个端叫做栈底
* 通过数组/链表实现，通过数组实现的通常叫做顺序栈，通过链表实现的叫做链栈
* 场景
  - 函数调用过程
  - 最新调用在栈上面
* 代价:存储详尽的信息可能占用大量的内存
  - 使用循环编写代码
  - 尾递归

```java
/**
* 链表中的结点，data代表节点的值，next是指向下一个节点的引用
 */
class Node {
    int data;// 结点的数组域，值
    Node next = null;// 节点的引用，指向下一个节点
    public Node(int data) {
        this.data = data;
    }
}

publicclass LinkedList {
    int length = 0; // 链表长度，非必须，可不加
    Node head = new Node(0); // 哨兵结点

    public void addNode(int val) {
        Node tmp = head;
        while (tmp.next != null) {
            tmp = tmp.next;
        }
        tmp.next = new Node(val);
        length++
    }
}

class Node{
    constructor(data){
        this.data = data;
        this.next = null;
    }
}

//定义链表
class LinkList{
    constructor(){
        //初始化头结点
        this.head = new Node('head');
    }

    //根据 value 查找结点
    findByValue = (value) =>{
        let currentNode = this.head;
        while(currentNode !== null && currentNode.data !== value){
            currentNode = currentNode.next;
        }
        //判断该结点是否找到
        console.log(currentNode)
        return currentNode === null ? -1 : currentNode;
    }

    //根据 index 查找结点
    findByIndex = (index) =>{
        let pos = 0;
        let currentNode = this.head;
        while(currentNode !== null && pos !== index){
            currentNode = currentNode.next;
            pos++;
        }
        //判断是否找到该索引
        console.log(currentNode)
        return currentNode === null ? -1 : currentNode;
    }

    //插入元素(指定元素向后插入)
    insert = (value,element) =>{
        //先查找该元素
        let currentNode = this.findByValue(element);
        //如果没有找到
        if(currentNode == -1){
            console.log("未找到插入位置!")
            return;
        }
        let newNode = new Node(value);
        newNode.next = currentNode.next;
        currentNode.next = newNode;
    }

    //根据值删除结点
    delete = (value) =>{
        let currentNode = this.head;
        let preNode = null;
        while(currentNode !== null && currentNode.data !== value){
            preNode = currentNode;
            currentNode = currentNode.next;
        }
        if(currentNode == null) return -1;
        preNode.next = currentNode.next;
    }

     //遍历所有结点
    print = () =>{
        let currentNode = this.head
        //如果结点不为空
        while(currentNode !== null){
            console.log(currentNode.data)
            currentNode = currentNode.next;
        }
    }
}

//测试
const list = new LinkList()
list.insert('xiao','head');
list.insert('lu','xiao');
list.insert('ni','head');
list.insert('hellow','head');
list.print()
console.log('-------------删除元素------------')
list.delete('ni')
list.delete('xiao')
list.print()
console.log('-------------按值查找------------')
list.findByValue('lu')
console.log('-------------按索引查找------------')
list.print()

template<class T>
class priqueue {
    private:
        int n,maxsize;
        T *x;
        void swap(int i,int j)
        { T t = x[i]; x[i] = x[j]; x[j] = t; }
    public:
        //初始化
        priqueue(int m)
        {
            maxsize = m;
            x = new T[maxsize+1];
            n = 0;
        }
        //插入新数据
        void insert(T t)
        {
            int i,p;
            x[++n] = t;
            //末尾添加新数据 执行siftup操作
            for (i = n; i > 1 && x[p=i/2] > x[i]; i = p)
                swap(p,i);
        }
        //提取操作
        T extractmin()
       {
          int i,c;
          //提取堆顶元素
          T t = x[1];
          //将尾部元素放到堆顶
          x[1] = x[n--];
          //针对新堆顶进行siftdn操作
          for (i = 1; (c = 2*i) <= n; i = c) {
              if (c+1 <= n && x[c+1] < x[c])
                   c++;
              if (x[i] <= x[c])
                   break;
               swap(c,i);
          }
         return t;
      }
};
```

## 递归

* 定义：直接调用自己或通过一系列调用语句间接调用自己的函数
* 本质：把问题拆分成具有相同解决思路的子问题，直到最后被拆解的子问题再也不能拆分，解决了最小粒度可求解的子问题后，在「归」的过程中自然顺其自然地解决了最开始的问题
* 条件
  - 问题解可以分解为几个子问题的解
  - 问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
  - 存在递归终止条件
* 特点
  - 一个问题可以分解成具有相同解决思路的子问题，子子问题，换句话说这些问题都能调用同一个函数
  - 分为调用和回退阶段，回退顺序是调用顺序逆序
  - 经过层层分解的子问题最后一定是有一个不能再分解的固定值的（即终止条件）,如果没有的话,就无穷无尽地分解子问题了，问题显然是无解的
  - 程序结构更清晰、更简洁、更容易让人理解，从而减少读懂代码的时间
  - 在迫不得已的情况下才使用递归，因为递归本身的效率并不理想，但思想却值得留存在记忆之中
  - 大量的递归调用会建立函数的副本，会消耗大量的时间和内存，而迭代则不需要此种代价
* 分析：采用**自上而下**思维(最终问题往前推)，而解决问题有时候采用自下而上的方式能让算法性能得到极大提升,思路比结论重要
  - 「递」:将问题拆解成子问题来解决，子问题再拆解成子子问题，直到被拆解的子问题无需再拆分成更细的子问题（即可以求解）正向展开
  - 「归」:最小的子问题解决了，那么它上一层子问题也就解决了，上一层的子问题解决了，上上层子问题自然也就解决了,直到最开始的问题解决 逆向合并
* 流程
  - 找出基准情形（没有调用自身）。看该函数在基准情形下会做什么
  - 看该函数在到达基准情形的前一步会做什么
  - 就这样往前推，看每一步都在做什么
* 套路
  - 定义函数：明确函数功能，由于递归特点是问题和子问题都会调用函数自身，所以这个函数功能一旦确定了，之后只要找寻问题与子问题递归关系即可
  - 确定条件
    + 寻找问题与子问题间关系（即递推公式），由于问题与子问题具有相同解决思路，*子问题可以调用步骤 1 定义的函数*，符合递归的条件（函数里调用自身）所谓的关系最好能用一个公式表示出来，比如 f(n) = n * f(n-)这样，如果暂时无法得出明确的公式，也可以用伪代码表示
    + 终止条件:寻找最终不可再分解的子问题的解（临界条件），确保子问题不会无限分解下去
  - 将递推公式用代码表示出来补充到定义的函数中
  - 优化：根据问题与子问题关系，推导出时间复杂度,如果发现递归时间复杂度不可接受，则需转换思路对其进行改造，看下是否有更靠谱的解法
* 注意
  - 警惕堆栈溢出，为此要设定好终止条件和合理的递归层数
  - 防止重复计算，因此要经过认证求证，不能凭感觉
  - 递归代码更简洁,可读性不好
  - 切忌试图通过人脑去分解每个步骤，那样会把自己搞晕的
* 迭代和递归区别：迭代使用的是循环结构，递归使用的是选择结构。

```java
public int factorial(int n) {
    if (n < =1) {
        return 1;
    }

    return n * factorial(n - 1)
}
```

## divide and conquer，D&C

* 方法
  - 找出基线条件，这种条件必须尽可能简单。
    + 通常是数组为空或只包含一个元素
  - 不断将问题分解(或者说缩小规模)，直到符合基线条件。
* 适用于这小块地的最大方块，也是适用于整块地的最大方块

## 树

* 树状图是一种数据结构，是由 n（n>=1）个有限节点组成一个具有层次关系的集合
* 定义
  - 每个节点都只有有限个子节点或无子节点
  - 每一个非根节点有且只有一个父节点
  - 除了根节点外，每个子节点可以分为多个不相交的子树（subtree）
  - 树里面没有环路，意思就是从一个节点出发，除非往返，否则不能回到起点
* 概念
  - 节点：每个元素
  - 节点的度 degree：在树中，一个节点子节点（子树）个数
  - 树的度：树内各节点度的最大值
  - 阶数（Order):一个节点的子节点数目的最大值
  - 根节点(root):没有父节点的节点
  - 叶节点或终端节点：度为零节点，位于树的最底层，就是没有分叉的节点
  - 非终端节点或分支节点：度不为零的节点
  - 父(亲)节点：若一个节点含有子节点，则这个节点称为其子节点的父节点
  - (孩)子节点：一个节点含有的子树的根节点称为该节点的子节点
  - 兄弟节点：具有相同父节点的节点互称为兄弟节点
  - 堂兄弟节点：父节点在同一层的节点互为堂兄弟
  - 节点层次：从根开始定义起，根为第1层，根的子节点为第2层
  - 深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0
  - 高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0
  - 树高度:根节点高度
  - 节点的祖先：从根到该节点所经分支上的所有节点
  - 子孙：以某节点为根的子树中任一节点
  - 森林：由m（m>=0）棵互不相交的树的集合
* 线段树

## 二叉查找树 binary search tree BST

* 每个节点的度不大于 2 ，即它的每个节点最多只有两个分支，分别是左子节点和右子节点
  - 满二叉树
    + 除了叶结点外，每一个结点 *都有左右子叶*（非叶结点度数为2）
    + 叶子结点都处在最底层的二叉树
    + 深度为 h结点数必为 2^(h-1)
  - 完全二叉树
    + 深度为 k 有 n 个节点的二叉树，当且仅当其中的每一节点，都可以和同样深度 k 的满二叉树，序号为 1 到 n 的节点一对一对应
    + 除了最大的层次即成为一颗满二叉树且层次最大那层所有的结点均向左靠齐，即集中在左面的位置上，不能有空位置。设一个结点为 i 则其父节点为 i/2，2i 为左子节点，2i+1 为右子节点。
* 性质（类比2进制）
  - 第 n 层上至多有 2^(n-1)个元素
  - 深度为k的树最多有2^k-1 个节点
  - 包含n个节点的二叉树高度为
    + 每层有最多节点：log2n+1（向下） 或者 log2(n+1)(向上)
    + 每层一个节点
  - 叶子节点个数为n0,度为2节点数为n2,n0=n2+1
  - 节点个数等于分支个数加1
* 由于基础二叉树不利于数据的查找和插入，因此有必要对二叉树中的数据进行排序，所以就有了二叉查找树｜二叉排序树
  - 左子树上的节点都小于根节点，右子树上所有节点的值都大于根节点
* 插入和删除操作的速度要快得多

* 通过链表存储二叉树:链表结点上设置两个指针域，分别指向左右子节点,可以串联整个二叉树
* 每个节点最多有两个子树,有五种基本形态
  - 空集
  - 根可以有空的左子树或右子树
  - 左、右子树皆为空

* 大多数二叉排序树操作（查找、最大值、最小值、插入、删除等等）都是Q(h)的时间复杂度，h 为树的高度
* 极端情况下会退化为线性链表，二分查找也会退化为遍历查找，时间复杂退化为 O（N），检索性能急剧下降
* 二叉查找树存在不平衡问题，因此提出通过树节点的自动旋转和调整，让二叉树始终保持基本平衡状态，就能保持二叉查找树的最佳查找性能了。基于这种思路的自调整平衡状态的二叉树有 AVL 树和红黑树
* 使用二叉树作为底层实现结构，树会变得很高，从而增加了磁盘的IO次数，从而影响数据查询时间。因此为了降低其高度，让一个节点有多个子节点，B 树就诞生了
* 遍历
  - 前序遍历(上下左右):根节点->左子树->右子树
  - 中序遍历（左右上下）:左子树->根节点->右子树
  - 后序遍历（左右下上）:左子树->右子树->根节点
* 插入
  - 依次插入生成最小树：4 7 2 5 6 1 0 3 8 =》 0 3 1 5 6 4 2 7 8。自上而下插入，遇见小值往上冒
* 删除：删除最小值，即最小堆树中的根节点。主要是将树中最后一个节点替换到被删除的根节点，然后自顶向下递归调整使之符合最小堆要求

## 堆 heap

* 建堆复杂度，手算
* 一种表示元素集合的结构，是一种二叉树.J. W. J. Williams在1964年发表的堆排序，当时提出了二叉堆树作为此算法的数据结构，堆在戴克斯特拉算法和带优先级队列中亦为重要的关键
* 元素顺序
  - 大根堆(大顶堆、最大堆):母节点大于等于其所有子结点，也就是堆的根是所有元素中最大的
  - 小根堆(小顶堆、最小堆):母节点小于等于其所有子结点，也就是堆的根是所有元素中最小的
  - 大根堆/小根堆只是约定了父结点和子结点的大小关系，但是并不约束子结点的相对大小和顺序
* 树的形状：最多在两层具有叶子结点，并且最底层的叶子结点靠左分布，该树种不存在空闲位置，是个**完全二叉树**
* 堆的数组表示
  - i<=n && i>=1 // 数组下标范围
  - root_index = 1 // 根结点下标为1
  - value(i) = array[i] // 层次遍历第i个结点的值等于数组第i个元素
  - left_child_index(i) = i*2 // 堆中第i个元素的左孩子下标i*2
  - right_child_index(i) = i*2+1 // 堆中第i个元素的右孩子下标i*2+1
  - parent(i) = i/2  // 堆中第i个元素的父结点下标i/2
* 建堆过程：重点是初始化堆和调整堆两个过程，然而这两个过程都离不开siftup和siftdn两个函数
* 调整函数
  - siftup：以小根堆为例，之前a[1...n-1]满足堆的特性，在数组a[n]插入新元素之后，就产生了两种情况：
    + 如果a[n]大于父结点那么a[1...n]仍然满足堆的特性，不需要调整
    + 如果a[n]比它的父结点要小无法保证堆的特性，就需要进行调整
    + 循环过程：自底向上的调整过程就是新加入元素不断向上比较置换的过程
    + 停止条件：新结点的值大于其父结点，或者新结点成为根结点为止
  - siftdn：以小根堆为例，之前a[1...n]满足堆的特性，在数组a[1]更新元素之后，就产生了两种情况：
    + 如果a[1]小于等于子结点仍然满足堆的特性，不需要调整；
    + 如果a[1]大于子结点无法保证堆的特性，就需要进行调整；
    + 循环过程：自顶向下的调整过程就是新加入元素不断向下比较置换的过程
    + 停止条件：直到新结点的值小于等于其子结点，或者新结点成为叶结点为止
* 堆排序:堆的重要用途，假如有200w数据，要找最大的前10个数。
  - 假如有200w数据，要找最大的前10个数。
  - 建堆过程:可以自顶向下自底向上均可，以下采用自底向上思路分析。可以将数组的叶子节点，是单个结点满足二叉堆的定义，于是从底层叶子结点的父结点从左到右，逐个向上构建二叉堆，直到第一个节点时整个数组就是一个二叉堆，这个过程是siftup和siftdn的混合，宏观上来看是自底向上，微观上每个父结点是自顶向下
  - 渗透排序过程：完成堆化之后，开处理N之后的元素，从N+1~200w，遇到比当前堆顶大的则与堆顶元素交换，进入堆触发siftdn调整，直至生产新的小根堆

* 最小堆:树中某个节点值总是不大于其左右子节点的值
* 最大堆:树中某个节点值总是不小于其左右子节点的值
* 最小(大)堆性质
  - 树根节点值是所有堆节点值中最小(大)值。
  - 树中每个节点的子树也都是最小(大)堆。
* 最小(大)堆作用
  - 最小(大)堆能保证堆顶元素为最小，而如果使用数组无法达到该效果。数组如果要访问最小值则需要遍历查找最小值，时间复杂度至少O(n)。而最小堆访问最小值时间复杂度为O(1)，当然天底下没有免费的午餐，需要做额外的工作去维护最小(大)堆的结构，这也是需要复杂度花销的。维护的时间复杂度为O(logN)。而数组则无法做到如此，如果数组想要维护顺序性则需要的复杂度至少为O(N)
* 通过数组来表示完全二叉树,两种方法
  - 数组下标与完全二叉树节点存在映射关系
    + 父节点:Math.floor((index-1)/2)
    + 左子节点:2index+1
    + 右子节点:2index+2
  - 下标从 1 开始（根节点）
    + 其父节点为 i/2
    + 2i 为左子节点
    + 2i+1 为右子节点

### 红黑树 Red Black Tree

* 一颗自平衡（self-balancing）的二叉排序树（BST）
  - 会自动调整树形态的树结构，比如当二叉树处于一个不平衡状态时，红黑树就会自动左旋右旋节点以及节点变色，调整树的形态，使其保持基本的平衡状态（时间复杂度为 O（logn）），也就保证了查找效率不会明显减低
* 树上的每一个结点都遵循下面的规则（提醒:这里的自平衡和平衡二叉树AVL的高度平衡有别） 三黑不同
  - 节点是红色或黑色
  - 根结点为黑色
  - 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点）
  - 所有叶子都是黑色（叶子是NIL节点）
  - 从任意一个结点（包括根结点）到其任何后代 NULL 结点（默认是黑色的）的每条路径都具有相同数量的黑色结点
* 红黑树的高度始终都维持在 lgn ，n 为树中的顶点数目
* 一个 NULL 结点被认为是黑色的
* 红黑树RBT与平衡二叉树AVL比较：
  * AVL 树比红黑树更加平衡，但AVL树在插入和删除的时候也会存在大量的旋转操作。所以当应用涉及到频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树
  * 如果应用中涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现

+ 保持平衡:通过左旋和右旋来调整由于插入和删除所造成的不平衡
  * 重新着色（recoloring）
  * 旋转（rotation）
+ 黑高（Black Height):从某个结点 x 出发（不包含该结点）到达一个叶结点的任意一条简单路径上包含的黑色结点数目称为黑高 ，记为 bh(x)
  * 黑节点与子红节点有相同黑高
  * 一颗红黑树的黑高 bh >= h/2
  * 一棵有n个内部结点的红黑树高度 h <= 2lg(n+1)

* 插入：具体取决于叔叔结点颜色,容易出现两个连续的红色结点，违背红黑树中不存在两个相邻的红色结点
  - 标准的 BST 插入并将新插入的结点 x 设置为红色
  - 如果 x 是根结点，将 x 颜色转化为黑色（整棵树的黑高增加 1）
  - 如果叔叔结点u是红色
    + 将 p 和 u 的颜色设置为黑色
    + g 颜色设置为红色
    + 将 x = g，对 g 重复执行上面两步
  - 如果叔叔结点是黑色
    + LL(p 是 g 的左孩子且 x 是 p 的左孩子):右旋g,交换g和p颜色
    + LR(p 是 g 的左孩子且 x 是 p 的右孩子):左旋 p 转化为 LL 的情况,按照 LL 的情况处理
    + RR(p 是 g 的右孩子且 x 是 p 的右孩子):左旋g,交换g和p颜色
    + RL(p 是 g 的右孩子且 x 是 p 的左孩子):右旋 p 转化为 RR 的情况,按照 RR 的情况处理
  - 如果父节点为黑色，直接插入不处理
  - 如果父节点为红色，叔叔节点为红色，则父节点和叔叔节点变为黑色，祖先节点变为红色，将节点操作转换为祖先节点
  - 如果当前节点为父亲节点的右节点，则以父亲结点为中心左旋操作
  - 如果当前节点为父亲节点的左节点，则父亲节点变为黑色，祖先节点变为红色，以祖先节点为中心右旋操作
* [删除](https://mp.weixin.qq.com/s?__biz=MzA4NDE4MzY2MA==&mid=2647521911&idx=1&sn=2e0a8b636cff515c5471f9a1bb2c3022&chksm=87d24574b0a5cc62e19d1f78b429a78b855948c5a3c7a98f7aca8372a674d17419c47f34a6c8)：通过检查兄弟结点的颜色来决定恰当的平衡操作,容易造成子树黑高（Black Height）的变化（删除黑色结点可能导致根结点到叶结点黑色结点的数目减少，即黑高降低）
  - 当删除结点 v 是黑色结点，且其被其黑色子节点u替换时，其子结点就被标记为双黑,最主要的任务将**双黑结点转化为普通黑色结点**
  - 执行标准的 BST 的删除操作
  - 简单情况：u 或者 v 是红色
    + 将替换结点 v 的结点 u 标记为黑色结点（这样黑高就不会变化）
  - 复杂情况：u 和 v 都是黑色结点
    + 结点 u 是双黑结点:要删除结点 v  和孩子结点 u 都是黑色结点，删除结点 v ，导致结点 u 变为双黑结点。主要任务将变成将该双黑结点u变成普通的单黑结点。一定要特别注意，NULL结点为黑色结点 ，所以删除黑色的叶子结点就会产生一个双黑结点。
    + 当前结点 u 是双黑结点且不是根结点
      * u 的兄弟结点 s 是黑色且 s 的孩子结点至少有一个是红色:要对 u 的兄弟结点 s 进行旋转操作，将 s 的一个红色子结点用 r 表示，u 和 s 的父结点用 p 表示，那么结点 p 、s 和 r 的位置将出现以下四种情况
        - LL（s 是 p 的左孩子，r 是 s 的左孩子，或者 s 的两个孩子都是红色结点）:s 的左孩子 r 颜色设置为 s 的颜色，s 的颜色设置为父结点 p 的颜色,右旋结点p,将结点 p的颜色设置为黑色，双黑结点变为单黑结点
        - LR（s 是 p 的左孩子，r 是 s 的右孩子，或者 s 的两个孩子都是红色结点）:将结点 r 的颜色设置为 p 的颜色.左旋结点s,右旋结点p，p的颜色设置为黑色，双黑变单黑
        - RR（s 是 p 的右孩子，r 是 s 的右孩子，或者 s 的两个孩子都是红色结点）:r的颜色变为s的颜色，s的颜色变为p的颜色,左旋p，p的颜色设置为黑色，双黑变单黑
        - RL情况（s 是 p 的右孩子，r 是 s 的左孩子，或者 s 的两个孩子都是红色结点）:结点 r 的颜色变为 p 的颜色,右旋结点s,左旋结点p，p的颜色设置为黑色，双黑变单黑
      * u 的兄弟结点 s 是黑色且 s 的两个孩子结点都是黑色
      * u 的兄弟结点 s 是红色结点
        - u 的兄弟结点 s 是父结点 p 的左孩子 ,对结点 p 进行右旋操作
        - u 的兄弟结点 s 是父结点 p 的左孩子 ,对结点 p 进行左旋操作
    + 当前结点 u 是双黑结点且是根结点:当前结点 u 是双黑结点且是根结点时，直接将双黑结点变为单黑结点，整颗红黑树的黑高减 1
  - 先按照排序二叉树的方法，删除当前节点，如果需要转移即转移到下一个节点
  - 当前节点，必定为这样的情况：没有左子树。
  - 删除为红色节点，不需要处理，直接按照删除二叉树节点一样
  - 如果兄弟节点为黑色，兄弟节点的两个子节点为黑色，则将兄弟节点变为红色，将着色转移到父亲节点
  - 如果兄弟节点为红色，将兄弟节点设为黑色，父亲结点设为红色节点，对父亲结点进行左旋操作
  - 如果兄弟节点为黑色，左孩子为红色，右孩子为黑色，对兄弟节点进行右旋操作
  - 如果兄弟节点为黑色，右孩子为红色，则将父亲节点的颜色赋值给兄弟节点，将父亲节点设置为黑色，将兄弟节点的右孩子设为黑色，对父亲节点进行左旋
* 缺点：并没有完全解决二叉查找树虽然这个“右倾”趋势远没有二叉查找树退化为线性链表那么夸张。自增操作对于查找性能而言也是巨大的消耗
* 应用
  - 大多数自平衡BST(self-balancing BST) 库函数都是用红黑树实现的
  - 广泛用在 C++的 STL 中。如 map 和 set 都是用红黑树实现的
  - 实现 Linux 操作系统的 CPU 调度。完全公平调度（Completely Fair Scheduler）使用的就是红黑树
  - Linux的的进程调度，用红黑树管理进程控制块，进程的虚拟内存空间都存储在一颗红黑树上，每个虚拟内存空间都对应红黑树的一个结点，左指针指向相邻的虚拟内存空间，右指针指向相邻的高地址虚拟内存空间
  - IO多路复用的epoll采用红黑树组织管理sockfd，以支持快速的增删改查
  - Nginx中用红黑树管理定时器，因为红黑树是有序的，可以很快的得到距离当前最小的定时器
  - Java的 TreeMap 和 TreeSet 的实现
  - nginx 中，用红黑树管理 timer 等著名的 linux 进程调度,用红黑树管理进程控制块
  - B/B+树: 用在磁盘文件组织 数据索引和数据库索引。
  - Trie 树(字典树): 用在统计和排序大量字符串，如自动机。

* 参考
  - [红黑树？（中篇）](https://mp.weixin.qq.com/s?__biz=MzA4NDE4MzY2MA==&mid=2647521642&idx=1&sn=dda12824118e46c17374333062e37a6a&chksm=87d24669b0a5cf7f5bf8e2614deb224d15c10cd474d24c17e9354743b7a5eb72fc89469e6330)

## AVL树 平衡二叉树 Balanced Binary Tree

* 名字由来，是它的两个发明者G. M. Adelson-Velsky 和 Evgenii Landis 的缩写，AVL最初是他们两人在1962 年的论文「An algorithm for the organization of information」中提出来一种数据结构
* 定义：在二叉查找树中，任一节点对应的两棵子树的最大高度差为 1
* 平衡因子：左右子树的高度差
* 用平衡因子判断是否平衡并通过旋转来实现平衡，左右子树树高不超过1，和红黑树相比，AVL树是高度平衡的二叉树，平衡条件必须满足（所有结点的左右子树高度差不超过1）
* 不管执行插入还是删除操作，只要不满足上面的条件，就要通过旋转来保持平衡，由于旋转比较耗时，由此AVL树适合用于插入与删除次数比较少，但查找多的情况

- 特点
  + 若左子树不空，则左子树上所有节点的值均小于它的根节点的值
  + 若右子树不空，则右子树上所有节点的值均大于或等于它的根节点的值
  + 每个非叶子节点的左右子树的高度之差的绝对值（平衡因子）最多为1,当结点的左右子树的高度之差大于等于2时，需要进行平衡操作
  + 左右子树都是平衡二叉树
  + 对每一个结点，其左右子树的高度之差的绝对值小于 2
  + 严格平衡，查找速度更快
- 优点
  - 查找性能（O（logn）），不存在极端的低效查找的情况
  - 实现范围查找、数据排序

* 缺点
  + 数据处的（高）深度决定着IO操作次数，IO操作耗时大
  + 每一个磁盘块（节点/页）保存的数据量太小了
  + 没有很好的利用操作磁盘IO的数据交换特性
  + 也没有利用好磁盘IO的预读能力（空间局部性原理），从而带来频繁的IO操作
  + 数据库查询数据的瓶颈在于磁盘 IO，如果使用 AVL 树，每一个树节点只存储了一个数据，一次磁盘 IO 只能取出来一个节点上的数据加载到内存里

- 查找性能是比较高的（性能最好的是最优二叉树），查询性能越好，维护的成本就越大
  + 实际应用场景中可能需要旋转多次
  + 查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如AVL、Treap、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1.，通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找
- 平衡调整：保证相对平衡，每次插入元素都会做相应的旋转
  + LL型调整（顺时针旋转）：左子树插入新元素，为满足平衡，左非根节点提升为根节点
  + RR型调整（逆时针旋转）：右子树插入新的节点
  + LR调整：左孩子的右子树上插入新节点
  + RL调整
- 保持树平衡的目的是可以控制查找、插入和删除在平均和最坏情况下的时间复杂度都是O(log n)，相比普通二叉树最坏情况的时间复杂度是 O(n) ，AVL树把最坏情况的复杂度控制在可接受范围，非常合适对算法执行时间敏感类的应用

* 遍历
  - 前序遍历：根节点->当前节点的左子树->当前节点的右子树(当前节点无左子树)
  - 中序遍历: 当前节点的左子树->根节点->当前节点的右子树
    + 一个有序序列。由于树的高度，区间查询需要中序遍历，都会导致查询效率很慢
  - 后序遍历:从根节点出发，依次遍历各节点的左右子树，直到当前节点左右子树遍历完成后，才访问该节点元素 左子树->右子树->根结点
  - 层次遍历:从上往下一层一层遍历
  - 前序遍历的代码在进入某一个节点之前的那个时间点执行，后序遍历代码在离开某个节点之后的那个时间点执行
* 场景
  - Windows NT内核中广泛存在
  - 数据库查询查询操作较多的情况下

```
graph TD 3-->1 3-->5 1-->2 5-->4 5-->6

前序遍历结果： 3 1 2 5 4 6
中序遍历结果： 1 2 3 4 5 6
后序遍历结果： 2 1 4 6 5 3

## 前序遍历
void traverse(TreeNode root) {
    if (root == null) return;

    // 前序遍历的代码

    traverse(root.left);
    traverse(root.right);
}

## 后续遍历
void traverse(TreeNode root) {
    if (root == null) return;
    traverse(root.left);
    traverse(root.right);

    // 后序遍历的代码
}

## 中序遍历
void serialize(TreeNode root, StringBuilder sb) {
    if (root == null) {
        sb.append(NULL).append(SEP);
        return;
    }

    serialize(root.left, sb);
    /****** 中序遍历位置 ******/
    sb.append(root.val).append(SEP);
    /***********************/
    serialize(root.right, sb);
}

# 层序遍历
void traverse(TreeNode root) {
    if (root == null) return;
    // 初始化队列，将 root 加入队列
    Queue<TreeNode> q = new LinkedList<>();
    q.offer(root);

    while (!q.isEmpty()) {
        TreeNode cur = q.poll();

        /* 层级遍历代码位置 */
        System.out.println(root.val);
        /*****************/

        if (cur.left != null) {
            q.offer(cur.left);
        }

        if (cur.right != null) {
            q.offer(cur.right);
        }
    }
}
```

## 哈夫曼树 Huffman Tree 最优二叉树

* 一种带权路径长度（树中所有的叶子节点的权值乘上其根节点的路径长度）最短的二叉树
* 权值较大的结点离根较近

### B树 B-tree

* 鲁道夫·拜尔（Rudolf Bayer）1972年在波音研究实验室（Boeing Research Labs）工作时发明的
* 设计原理：磁盘 IO 有个特点，就是从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的，根据这个思路，可以在一个树节点上尽可能多地存储数据，一次磁盘 IO 就多加载点数据到内存
* 即平衡查找树，一般理解为平衡多路查找树，也称为B-树、B_树。用来存储排序后的数据
* O(log n)的时间复杂度进行查找、插入和删除
* 2-3树:2节点代表只能有两个内容，3节点只能有3个儿子.构造过程中是决不允许向下分裂的，只能向上融合
* 减少定位记录时所经历的中间过程，从而加快存取速度。一般较多用在存储系统上，比如数据库或文件系统
* 每个结点中存储了关键字（key）和关键字对应的数据（data）,以及孩子结点的指针
* 一颗 B树需要指定它的阶数，阶数表示此树的结点最多有多少个孩子结点（子树），一般用字母 m 表示阶数.M阶 可理解为 M树，即内含（M-1）个关键字 和 M 个子树
* 实际应用中的B树的阶数m都非常大（通常大于100）所以即使存储大量的数据，B树的高度仍然比较小
* 也称 M 阶B树 为 ( ⌈M /2⌉ , M ) 树,定义了节点子树的上下限
  - Every node has at most m children and 最多有 m-1 个关键字
  - The root has at least two children and 1个关键字
  - Every non-leaf node (except root) has at least k children contains k − 1 keys 非根结点至少有 ceil(M/2)-1 个关键字 至少 ceil(M/2) 个子树,k = [ceil(M/2),M]
  - 每个结点中关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它
  - 根节点：子树范围为[2,m]，节点内项的个数范围为[1,m-1]
  - 非根节点：节点内的项个数范围为[ceil(m/2)-1,m-1]
  - All leaves appear in the same level. 所有的叶子结点都出现在同一层上，不包含任何关键字(可以看做是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空)
* 假设中间节点的关键字为：Key[1], Key[2], …, Key[k-1]，且关键字按照升序排序，即 Key[i]<Key[i+1]
  - k-1 个关键字相当于划分了 k 个范围，也就是对应着 k个指针，即为：P[1], P[2], …, P[k]
  - 其中 P[1] 指向关键字小于 Key[1] 的子树，P[i] 指向关键字属于 (Key[i-1], Key[i]) 的子树，P[k] 指向关键字大于 Key[k-1] 的子树
* 特点
  - B 树的查找性能等于 O（h*logn），其中 h 为树高，n 为每个节点关键词的个数；
  - 尽可能少的磁盘 IO，加快了检索速度
  - 可以支持范围查找
  - 超过节点容量，引起分裂操作，可能引起父节点需要继续分裂
  - 父节点的若干项作为分离项分成多个子树，左子树小于对应分离项，对应分离项小于右子树
  - B树是所有节点的平衡因子均等于0的多路查找树（AVL树是平衡因子不大于 1 的二路查找树）。
  - B 树节点可以保存多个数据，使得 B 树可以不用像 AVL 树那样为了保持平衡频繁的旋转节点。
  - B树的多路的特性，降低了树的高度，所以B树相比于平衡二叉树显得矮胖很多。
  - B树非常适合保存在磁盘中的数据读取，因为每次读取都会有一次磁盘IO，高度降低减少了磁盘IO的次数
* 插入
  - 根据要插入的key值，找到叶子结点并插入，只插入到叶子节点，如果不是叶子节点，继续往下
  - 判断当前结点key个数是否小于等于m-1，若满足则结束，否则继续
  - 以结点中间的key为中心分裂成左右两部分，然后将这个中间的key插入到父结点中，key的左子树指向分裂后的左半部分，key的右子支指向分裂后的右半部分，然后将当前结点指向父结点,继续上一步
    + 阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可
  - 代码中,结点中存储记录的数组长度定义为m而非m-1，这样方便底层的结点由于分裂向上层插入一个记录时，上层有多余的位置存储这个记录。同时，每个结点还可以存储它的父结点的引用
* 删除
  - 删除key位于非叶子结点上：用后继key（均指后继记录，首个子树）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。执行第2步
  - 结点key个数大于等于Math.ceil(m/2)-1，结束删除操作，否则执行第3步。
    + 借兄弟节点：兄弟结点key个数大于Math.ceil(m/2)-1，则父结点中的key下移到该结点，兄弟结点中的一个key上移，删除操作结束。
    + 合并节点：将父结点中的key下移与当前结点及它的兄弟结点中的key合并，形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，重复上第2步。有些结点它可能即有左兄弟，又有右兄弟，那么任意选择一个兄弟结点进行操作即可。
* B-树的结点所包含的键的数目和磁盘块大小一样，从数个到数千个不等。由于B-树的高度 h 可控（一般远小于  ），所以与 AVL 树和红黑树相比，B-树的磁盘访问时间将极大地降低
* 平衡m叉查找树是指每个关键字的左侧子树与右侧子树的高度差的绝对值不超过1的查找树，其结点结构与上面提到的B-树结点结构相同，由此可见，B-树是平衡m叉查找树，但限制更强，要求所有叶结点都在同一层
* 参考
  - [什么是B树](https://mp.weixin.qq.com/s?__biz=MzA4NDE4MzY2MA==&mid=2647522005&idx=1&sn=659962d777276bbd16a581ddc884c69d)

### B+树 B+ Tree

* 在 B-Tree 基础上优化，使其更适合实现外存储索引结构，InnoDB引擎就是基于它实现索引结构
* 特点
  - 节点中子节点个数[N/2,N]（不然会造成页分裂或页合并）
  - 根节点子节点个数可以不超过 m/2，这是一个例外
  - 非叶子树只存储索引，并不真正存储数据，只有最后一行的叶子节点存储行数据
  - 通过链表将叶子节点串联在一起，每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接,方便按区间查找
* 树高和每个节点的子节点个数（即 N 叉树中的 N）有关
* 每个节点 16 byte
* 相对于 B-Tree 优势：
  + B+ 树的磁盘读取代价低：B+树所有的内部节点没有指向关键字具体信息的指针（只存储了关键字key的信息,而没有存储数据的指针），这样可以使内部节点相对更小。一个硬盘块中包含的节点信息越多，一次性读取内存中的关键字也就越多，相对来说就是 IO 读写次数的降低，也可以说是每次 IO 操作的可观看数据也就越多；
  + B+ 树便于执行扫库操作：B树在分支节点上都保存着数据，要找到具体的顺序数据，必须用中序遍历的方式按序扫库；由于B+树的数据都存储在叶子节点上，且连接形成有序链表,所有节点均为索引，所以 B+树直接从叶子节点挨个扫一遍就完了；B+树 支持范围查询（rang-query）非常方便，而B树不支持；
  + B+ 树查询效率更加稳定：由于 B+树的数据都存储在叶子节点上，分支节点均为索引，所以对于任意关键字的查找都必须从根节点走到分支节点，所有关键字查询路径长度相同，每个数据的查询效率差不多。对于 B树而言，分支节点也保存有数据，对于每一个数据的查询所走的路径长度也是不一样的，效率也就不一样；
* 与BTree区别：
  - B+树数据记录都保存在叶子结点中，所有叶子节点之间都有一个链指针.非叶节点只存储键值信息(关键字和子节点的引用)
  - BTree中间结点存储数据指针与键值，导致可以存储的结点树目极大地减少了，从而增加 B-树的层数，进而增加了记录的搜索时间
  - B树中任何一个关键字只出现在一个结点中，而B+树中的关键字出现在叶节点中，也可能在非叶结点中重复出现
  - B+节点关键字搜索采用闭合区间（B-树是开区间）
  - 两者在查找、插入和删除等操作的时间复杂度的量级是一致的
* 局部性原理
  - 索引文件大不可能全部放入内存中，而是需要时候换入内存，方式是磁盘页。一般来说树的一个节点就是一个磁盘页
  - 无论是内存还是磁盘，操作系统都是按页的大小进行读取的（页大小通常为 4 kb），磁盘每次读取都会预读，会提前将连续的数据读入内存中，这样就避免了多次 IO
  - 连续数据必须是操作系统页大小的整数倍，这个连续数据就是 MySQL 的页，默认值为 16 KB，也就是说对于 B+ 树的节点，最好设置成页的大小（16 KB），这样一个 B+ 树上的节点就只会有一次 IO 读
  - 页大小并不是越大越好，InnoDB 是通过内存中的缓存池（pool buffer）来管理从磁盘中读取的页数据的。页太大的话，很快就把这个缓存池撑满了，可能会造成页在内存与磁盘间频繁换入换出，影响性能
  - 尽量保证每个节点的大小等于一个页（16kb）的大小即可
* 利用磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入
  - 每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。
  - B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O（h）=O（logmN）。一般实际应用中，m是非常大的数字，通常超过100，因此h非常小（通常不超过3）
* 索引维护
  - 页分裂:为了维护索引的有序性，每插入或更新一条记录的时候，会对索引进行更新，可能会引起
  - 页合并：当相邻的两个页由于删除了数据，利用率很低之后，会将数据页做合并
    - 可以定个阈值，比如对于 N 叉树来说，当节点的个数小于 N/2 的时候就应该和附近的节点合并，不过需要注意的是合并后节点里的元素大小可能会超过 N，造成页分裂，需要再对父节点等进行调整以让它满足 N 叉树的条件
  - 主键的随机性会引起大量的随机结点中的插入，进而造成大量的页分裂，进而造成性能的急剧下降
  - 自增 id 作为主键由于新插入的表中生成的 id 比索引中所有的值都大，所以要么合到已存在的节点（元素个数未满）中，要么放入新建的节点中
* 索引重建：因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间
  - 过程不合理：
    + 不论是删除还是创建主键都会整个表重建
    + 连续执行两个语句，相当于第一个语句白做
    + 两个语句可以使用 alter table T engine=InnoDB 代替
* 查找、修改时间复杂度为 O(log n)
* B树包括B+树的设计思想都是尽可能的降低树的高度，以此降低磁盘IO的次数，因为一个索引节点就表示一个磁盘页，页的换入换出次数越多，表示磁盘IO次数越多，越低效。以块的形式从磁盘读取数据.B树算法减少定位数据所在的节点时所经历的磁盘IO次数，从而加快存取速度
* 聚簇索引（主键索引）：叶子节点中存储的是整行数据。限制：
  - 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的，否则会出现页分裂，严重影响性能。所以一般 InnoDB 表，都会定义一个自增的id作为主键。面试问题：为什么主键需要自增ID，或者为什么主键需要带有时间行关联。
  - 更新主键的代价很高，因为将会导致被更新的行移动。因此，InnoDB表一般主键不可更新。
  - MySQL默认情况下，主键是允许更新的。MongoDB主键是不允许更新的。
  - 二级索引访问需要回表。有种情况无需二次查找，就是索引覆盖。
  - 主键ID建议使用整型。因为，每个主键索引的 B+Tree 节点的键值可以存储更多主键ID，每个非主键索引的 B+Tree 节点的数据可以存储更多的主键ID。
* 非主键索引
  - 非主键索引的叶子节点存储的是主键的值，从物理存储的角度也叫 二级索引。
  - 二级索引存储主键，是为了减少出现行移动或数据页分裂时二级索引的维护工作，但会让二级索引占用更多的空间
* 适合使用业务字段直接做主键
  - 只有一个索引
  - 该索引必须有唯一索引
  - KV场景，由于没有其他索引，所以不用考虑其他索引的叶子节点大小的问题
  - 此时直接将这个索引设置为主键，可以避免回表
* 使用
  - B树主要用于文件系统，和部分数据库索引，如文档型数据库mongodb
  - B+树主要用于mysql数据库索引。
* 参考
  - [什么是 B+树](https://mp.weixin.qq.com/s/y3vDkEQfR5Pv1-rcWRZ7nQ)

## Trie树 前缀树或字典树

* 利用字符串前缀来查找指定的字符串，缩短查找时间提高查询效率，主要用于字符串的快速查找和匹配
* 性质：
  - 根节点不包含字符，除根节点外每一个节点都只包含一个字符
  - 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串
  - 每个节点的所有子节点包含的字符都不相同
* 建立和查询是可以同步进行的，可以在还没建立出完成的 Trie 树之前就找到目标数据，而如果用 Hash 表等结构存储是需要先建立完成表才能开始查询，这也是 Trie 树查询速度快的原因
* 应用
  - 用于搜索引擎的关键词提示功能
* 在海量数据查询上很有优势，因为不必为了找到目标数据遍历整个数据集合，只需按前缀遍历匹配的路径即可找到目标数据

### LSM树

## 图

* 权重(weight)
* 加权图(weighted graph):带权重的图
* 非加权图(unweighted graph):不带权重的图
* 有向图:边为箭头，箭头的方向指定了关系的方向，例如，rama→adit表示rama欠adit钱
* 无向图:边不带箭头，其中的关系是双向
* 环：从一个节点出发，走一圈后又回到这个节点

## 应用

* 在查询操作更多的程序中，应该用顺序表，修改操作更多的程序中，使用链表
* 单向链表不方便：双向链表 or 循环链表
* 学了栈之后，就知道，很多涉及后入先出的问题，例如函数递归就是个栈模型、Android 的屏幕跳转就用到栈，很多类似的东西，就会第一时间想到：我会用这东西来去写算法实现这个功能。学了队列之后，你就知道，对于先入先出要排队的问题，你就要用到队列，例如多个网络下载任务，我该怎么去调度它们去获得网络资源呢？再例如操作系统的进程（or 线程）调度，我该怎么去分配资源（像 CPU）给多个任务呢？肯定不能全部一起拥有的，资源只有一个，那就要排队！那么怎么排队呢？用普通的队列？但是对于那些优先级高的线程怎么办？
* 这时，就会想到了优先队列，优先队列怎么实现？用堆，然后你就有疑问了，堆是啥玩意？自己查吧，敲累了。总之好好学数据结构就对了。我觉得数据结构就相当于：我塞牙了，那么就要用到牙签这“数据结构”，当然你用指甲也行，只不过“性能”没那么好；我要拧螺母，肯定用扳手这个“数据结构”，当然你用钳子也行，只不过也没那么好用。学习数据结构，就是为了了解以后在 IT 行业里搬砖需要用到什么工具，这些工具有什么利弊，应用于什么场景。以后用的过程中，你会发现这些基础的“工具”也存在着一些缺陷，你不满足于此工具，此时，你就开始自己在这些数据结构的基础上加以改造，这就叫做自定义数据结构。而且，你以后还会造出很多其他应用于实际场景的数据结构。。你用这些数据结构去造轮子，不知不觉，你成了又一个轮子哥。


的确很少有写业务代码的时候会直接用上二叉树。但是真的没有吗？XML/DOM 是什么？是不是一棵树？为什么 DOM 可以和 XML 一一对应？因为 XML 序列化就是树的遍历的结果。能和 XML 对应，也就能跟 JSON 对应，因为两者都可以对应到树（只是表示逻辑上有些区别）。一个业务系统里有任务（Task），任务有相应的执行计划（Plan），计划可以用子任务组成，子任务可以是基础任务，也可以通过 Plan 拆分成更多的子任务。这是什么？这不就是树吗？那么怎么存储？JSON 不就很好吗。怎么从 JSON 加载、再保存会 JSON？树的遍历。怎么计算任务总共需要多少个基础任务？树的遍历。怎么计算计划总共需要多少时间？树的遍历。一个社交系统里，用户可以加好友，好友还有别的好友，这是什么？无向图。如果是知乎这样的关注系统呢？有向图。一个用户点了个赞，扩散到另一个用户至少要经过几次转发？最短路径。我要画一个小圈子里的人之间的关系图，怎么做？最小生成树。我要整理信息路径，看这批用户里哪些生产内容，哪些阅读内容，按什么次序传播，怎么做？拓扑排序。

说明数据结构首先就是“数据的结构”，在内存上的存储方式，就是物理的存储结构，在程序使用人员的思想上它是逻辑的，比如：你们在 C/C++中学习到链表，那么链表是什么一个概念，你们使用指针制向下一个结点的首地址，让他们串联起来，形成一个接一个的结点，就像显示生活中的火车一样。而这只是对于程序员的概念，但是在内存中存储的方式是怎样的那？对于你程序员来说这是“透明”的，其内部分配空间在那里，都是随机的，而内存中也没有一个又一根的线将他们串联起来，所以，这是一个物理与逻辑的概念，对于我们程序员只需要知道这些就可以了，而我们主要要研究的是“逻辑结构”。我可以给你一个我自己总结的一个概念：所有的算法必须基于数据结构生存。也就是说，我们对于任何算法的编写，必须依赖一个已经存在的数据结构来对它进行操作，数据结构成为算法的操作对象，这也是为什么算法和数据结构两门分类不分家的概念，算法在没有数据结构的情况下，没有任何存在的意义；而数据结构没有算法就等于是一个尸体而没有灵魂。估计这个对于算法的初学者可能有点晕，我们在具体的说一些东西吧：我们在数据结构中最简单的是什么：我个人把书籍中线性表更加细化一层（这里是为了便于理解在这样说的）：单个元素，比如：int i;这个 i 就是一个数据结构，它是一个什么样的数据结构，就是一个类型为 int 的变量，我们可以对它进行加法/减法/乘法/除法/自加等等一系列操作，当然对于单个元素我们对它的数据结构和算法的研究没有什么意义，因为它本来就是原子的，某些具体运算上可能算法存在比较小的差异；而提升一个层次：就是我们的线性表（一般包含有：顺序表/链表）那么我们研究这样两种数据结构主要就是要研究它的什么东西那？一般我们主要研究他们以结构为单位（就是结点）的增加/删除/修改/检索（查询）四个操作（为什么有这样的操作，我在下面说到），我们一般把“增加/删除/修改”都把它称为更新，对于一个结点，若要进行更新一类的操作比如：删除，对于顺序表来说是使用下标访问方式，那么我们在删除了一个元素后需要将这个元素后的所有元素后的所有元素全部向前移动，这个时间是对于越长的顺序表，时间越长的，而对于链表，没有顺序的概念，其删除元素只需要将前一个结点的指针指向被删除点的下一个结点，将空间使用 free()函数进行释放，还原给操作系统。当执行检索操作的时候，由于顺序表直接使用下标进行随机访问，而链表需要从头开始访问一一匹配才可以得到使用的元素，这个时间也是和链表的结点个数成正比的。所以我们每一种数据结构对于不同的算法会产生不同的效果，各自没有绝对的好，也没有绝对的不好，他们都有自己的应用价值和方式；这样我们就可以在实际的项目开发中，对于内部的算法时间和空间以及项目所能提供的硬件能力进行综合评估，以让自己的算法能够更加好。（在这里只提到了基于数据结构的一个方面就是：速度，其实算法的要素还应该包括：稳定性、健壮性、正确性、有穷性、可理解性、有输入和输出等等）为什么要以结点方式进行这些乱七八糟的操作那？首先明确一个概念就是：对于过程化程序设计语言所提供的都是一些基础第一信息，比如一些关键字/保留字/运算符/分界符。而我们需要用程序解决现实生活中的问题，比如我们要程序记录某公司人员的情况变化，那么人员这个数据类型，在程序设计语言中是没有的，那么我们需要对人员的内部信息定义（不可能完全，只是我们需要那些就定义那些），比如：年龄/性别/姓名/出生日期/民族/工作单位/职称/职务/工资状态等，那么就可以用一些 C/C++语言描述了，如年龄我们就可以进行如下定义:
int age;/_age 变量，表示人员公司人员的年龄_/
同理进行其他的定义，我们用结构体或类把他们封装成自定义数据类型或类的形式，这样用他们定义的就是一个人的对象的了，它内部包含了很多的模板数据了。我就我个人的经历估计的代码量应该 10000 以内的（我个人的经理：只是建议，从你的第一行代码开始算，不论程序正确与否，不论那一门语言，作为一个标准程序员需要十万行的代码的功底（这个是我在大学二年级感觉有一定时候的大致数据，不一定适合其他人），而十万行代码功底一般需要四门基础远支撑，若老师没有教，可以自学一些语言）。

坚持刷 leetcode，因为找工作有用

AVL 树: 最早的平衡二叉树之一。应用相对其他数据结构比较少。windows 对进程地址空间的管理用到了 AVL 树。
AVL 是一种高度平衡的二叉树，所以通常的结果是，维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL 还是优于红黑的。

有一种数据结构是树（Tree），树里面有一种树叫二叉搜索树（Binary Search Tree），平均复杂度是 O(logN)，具有不错的查询性能。但是在这里，我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库的实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道——磁盘访问的成本大概是内存访问成本的十万倍左右，所以简单的搜索树，难以满足复杂的应用场景。

无序树：树中任意节点的子结点之间没有顺序关系,也称为自由树有序树：树中任意节点的子结点之间有顺序关系二叉树：每个节点最多含有两个子树的树称为二叉树完全二叉树满二叉树霍夫曼树：带权路径最短的二叉树称为哈夫曼树或最优二叉树

## 课程

* [数据结构(上)(自主模式)](http://www.xuetangx.com/courses/course-v1:TsinghuaX+30240184+sp/about)
* [数据结构(下)](http://www.xuetangx.com/courses/course-v1:TsinghuaX+30240184_2X+sp)
* [CS 61B Data Structures](https://people.eecs.berkeley.edu/~jrs/61b/)

## 参考

* [python-sortedcontainers](https://github.com/grantjenks/python-sortedcontainers):Python Sorted Container Types: Sorted List, Sorted Dict, and Sorted Set
* [Data Structure Visualizations](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html)
* [data-structure-php](https://github.com/elarity/data-structure-php)
