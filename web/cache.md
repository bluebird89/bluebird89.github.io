# 缓存

* 已经处理过数据不需要重复处理
* 以快速的数据存储读写，代替较慢速的存储读写

## 性能指标

* 缓存空间使用率
* topN 命令执行次数
* 命中率：过低，失去缓存效果。一般对于热点数据而言，要保证命中率达到70%以上效果最佳
  - 包括业务场景、淘汰策略、清理策略、缓存容量等等
* 缓存接口平均RT，最大RT，最小RT
* 缓存QPS
* 网络出口流量
* 客户端连接数
* key个数统计

## 类型

* 浏览器缓存:当用户点击back按钮或是再次去访问某个页面的时候能够更快的响应
  - 返回码以下都可缓存 200 301 304 404 206
  - 对于缓存的处理是根据第一次请求资源时返回的响应头来确定的
    + 强缓存阶段:
      * `Cache-Control:max-age=2592000` HTTP/1.1定义的关于缓存的字段，它规定了缓存过期的一个相对时间
      * Expires是HTTP/1.0中的定义缓存的字段，它规定了缓存过期的一个绝对时间
      * 优先级:max-age > Expires
      * Firefox浏览器表现为一个灰色的200状态码。 Chrome浏览器状态码表现为 200  (from disk cache)或是200 OK (from memory cache)
        - Chrome会根据本地内存的使用率来决定缓存存放在哪，如果内存使用率很高，放在磁盘里面，内存的使用率很高会暂时放在内存里面
    + 协商缓存阶段
      * Last-Modified:文件最后一次修改的时间 `If-Moified-Since: Tue, 28 Nov 2017 05:14:02 GMT`
      * ETag是对文件的一个标记，具体生成方式HTTP并没有给出一个明确的方式，所以理论上只要不会重复生成方式无所谓，比如对资源内容使用抗碰撞散列函数，使用最近修改的时间戳的哈希值，甚至只是一个版本号。 `If-None-Match: W/"5a1cf09a-63c6"`
      * 发现缓存过期，于是会在本次请求的请求头里携带If-Moified-Since和If-None-Match这两个字段，服务器通过这两个字段来判断资源是否有修改，如果有修改则返回状态码200和新的内容，如果没有修改返回状态码304
    + 启发式缓存阶段:缓存过期时间的字段一个都没有,根据响应头中2个时间字段 Date 和 Last-Modified 之间的时间差值，取其值的10%作为缓存时间周期。
* 代理服务器缓存:存在于网络中，请求路由必须经过它们才会生效，所以实际上你可以去手动设置浏览器的代理，或是通过一个中间服务器来进行转发.一个共享缓存，不只为一个用户服务，经常为大量用户使用，因此在减少相应时间和带宽使用方面很有效：因为同一个缓存可能会被重用多次
* 网关缓存:也称为代理缓存或反向代理缓存，网关也是一个中间服务器，网关缓存一般是网站管理员自己部署，从让网站拥有更好的性能
* 客户端缓存：由于随机性比较强，请求分散，加上合理的缓存过期时间，给服务器的压力也很小
* 本地缓存：减少网络层交互，无论是本地内存还是磁盘，速度比较快。但对分布式系统来讲有一个缺点，当数据库更新时，没有一个简单有效的方法去更新本地缓存
  - 适用场景：
    + 对缓存内容时效性要求不高，能接受一定的延迟，可以设置较短过期时间，被动失效更新保持数据的新鲜度
    + 缓存的内容不会改变。比如订单号与uid的映射关系，一旦创建就不会发生改变
  - 注意
    + 内存Cache数据条目上限控制，避免内存占用过多导致应用瘫痪
    + 内存中的数据移出策略
    + 虽然实现简单，但潜在的坑比较多，最好选择一些成熟的开源框架
    + 容易让应用服务器带上“状态”，而且容易受内存大小的限制
* 分布式缓存：借助分布式的概念，集群化部署，独立运维，容量无上限，虽然会有网络传输的损耗，但这1~2ms的延迟相比其更多优势完成可以忽略
  - Memcached、Redis。对比关系型数据库和缓存存储，其在读和写性能上的差距可谓天壤之别，redis单节点已经可以做到8W+ QPS。设计方案时尽量把读写压力从数据库转移到缓存上，有效保护脆弱的关系型数据库
  - 不足：需要跨服务器走网络传输,网络传输带来的性能损耗

## 淘汰策略

* 针对变化的数据，清理掉保存的“脏”数据
*  LFU Least Frequently Used，即最不经常使用
*  LRU Least Recently Used，即最近最少使用
* 过期时间：热点数据都有过期时间，如果没有过期时间就造成了主存和缓存的数据不一致，因此过期时间一般都不会太长
  - 太短：造成频繁的从数据库中往缓存里写数据
  - 太长：内存浪费
* 被动失效
  - 通常会设置一个过期时间或者当数据库状态改变时，通过delete操作，使数据失效掉；当下次再去读取时，如果发现数据过期了或者不存在了，那么就重新去数据库读取，然后更新到缓存中
  - 风险：从缓存失效到数据再次被预热到cache这段时间，所有的读请求会直接打到DB上，对于一个高访问量的系统，很容易被击垮
* 主动更新
  - 数据库存储发生变化时，会直接同步更新到Cache，主要是为了解决cache空窗期引发的问题
  - 如果读多写多，同样会带来另一个问题，就是并发更新。多台应用服务器同时访问一份数据是很正常的，这样就会存在一台服务器读取并修改了缓存数据，但是还没来得及写入的情况下，另一台服务器也读取并修改旧的数据，这时候，后写入的将会覆盖前面的，从而导致数据丢失。解决的方式主要有三种
    + 锁控制：一般在客户端实现(在服务端加锁是另外一种情况)，其基本原理就是使用读写锁，即任何线程要调用写方法时，先要获取一个排他锁，阻塞住所有的其他访问，等自己完全修改完后才能释放。如果遇到其他线程也在修改或读取数据，那么则需要等待。 锁控制虽然是一种方案，但是很少有真的这样去做的，其缺点显而易见，其并发性只存在于读操作之间，只要有写操作存在，就只能串行
    + 单版本机制（乐观锁）：为每份数据保存一个版本号，当缓存数据写入时，需要回传这个版本号，然后服务端将传入的版本号和数据当前的版本号进行比对，如果等于当前版本号，则成功写入，否则失败。这样解决方式比较简单; 但是增加了高并发下客户端的写失败概率
    + 多版本机制：即存储系统为每个数据保存多份，每份都有自己的版本号，互不冲突，然后通过一定的策略来定期合并，再或者就是交由客户端自己去选择读取哪个版本的数据。

## 穿透/雪崩

* 缓存穿透 Cache Penetration
  - 缓存和数据库中都没有的数据，而用户不断发起请求.缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，导致这个不存在数据每次请求都要到存储层去查询
  - 小概率事件在高并发系统几乎要成为必然
  - 有效甄别是否存在这个key再决定是否读取很重要，常见做法：
    + 将不存在的key预先设定一个值。比如，”key” , “&&”， "null"，返回结果决定是否继续等待继续访问，还是放弃掉这次操作。如果继续等待访问，过一个时间轮询点后，再次请求这个key，如果取到的值不再是&&，则可以认为这时候key有值了
      - 局限性很大，缓存系统和数据库中存储大量无用key本身是无意义数据
    + 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
    + 时间复杂度 O (1)，二进制位存储，省空间，20 亿的数组约占 238M
    * 垃圾邮件识别、搜索蜘蛛爬虫url去重等，主要借助K个哈希函数和一个超大的bit数组来降低哈希冲突本身带来的误判，从而提高识别准确性
    * 由于 hash 碰撞，只能支持未命中的判断，如果布隆过滤器认为值不存在，那么值一定是不存在的，无需查询缓存也无需查询数据库，存在极小概率的误判断。不支持元素删除
* 缓存雪崩 Cache Avalanche：缓存系统故障或者设置缓存时采用了相同过期时间，大量请求无法从缓存完成数据请求，全量汹涌冲向磁盘数据库系统，导致数据库被打死，整个系统彻底崩溃
  - 一般不会瞬间造成系统不可用，缓慢过程，报警，监控命中率
    + 提高缓存系统的稳定性和可用性十分必要，对于使用Redis作为缓存的系统而言需要使用Sentinel哨兵机制、集群化、持久化等来提高缓存系统的HA
  - 风控层面做干预，识别非法来源
  - 用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上
  - 缓存失效时间分散开：在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，设置100ms的基础值，在此基础上正负浮动10ms，从而降低相同时刻出现CacheMiss的key的数量 `setRedis（Key，value，time + Math.random() * 10000）；`
  - 提前将数据预热到 cache
  - 灰度，逐步开放给新用户，做好流量阶梯缓冲
  - 计算好缓存过期时间
  - 服务本身需要支持降级：使用奈飞的Hystrix来实现服务的熔断、降级、限流来降低出现雪崩时的故障程度。做资源的隔离保护主线程池
* 缓存击穿 Hotspot Invalid：一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库
  - 和缓存雪崩区别在于这里针对某一key缓存，后者则是很多key
  - 多线程加锁
    + 第一个线程发现CacheMiss之后进行加锁，再从数据库获取内容之后写到缓存中
    + 其他线程获取锁失败则阻塞数ms之后再进行缓存读取
    + 可以降低访问数据数据库的线程数，需要注意在单机和集群需要使用不同的锁，集群环境使用分布式锁来实现，但是锁的存在也会影响并发效率
  - 使用互斥锁(mutex key)
    + 在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key
    + 当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法
  - "提前"使用互斥锁(mutex key)
    + 在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。 当从cache读取到timeout1发现已经过期时，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。
  - 在业务层对使用的热点数据查看是否即将过期，如果即将过期则去数据库获取最新数据进行更新并延长该热点key在缓存系统中的时间，从而避免后面的过期CacheMiss，相当于把事情提前解决
  - 缓存副本设计有一个细节需要注意，就是不同的缓存副本不要设置统一的过期时间，设定一个过期时间范围，不同的缓存副本的过期时间是指定范围内的随机值
  - 在设置热点数据过期时间时尽量分散，基础值上正负浮动
* 并发更新：一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况
  - 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁
  - 其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询

## 不同读写模式保证一致性

* 原因
  - 缓存服务器挂了或者网络问题引起没有及时更新
  - 通过重试机制：启动一个异步任务定时去检测缓存服务器是否连接成功，一旦连接成功则从数据库中按顺序取出修改数据，依次进行缓存最新值的修改
* 缓存与数据库 必须保持一致性:读请求和写请求串行化，串到一个内存队列里去
  - 可以保证一定不会出现不一致的情况，但是也会导致系统吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上请求
* Cache Aside 旁路缓存策略,控制逻辑都实现在应用程序中的模式,缓存不和数据库直接进行交互，而是由应用程序来同时和缓存以及数据库打交道,Cache在应用的一旁(aside)
  - 读
    + 程序需要判断缓存中是否已经存在数据
    + 当缓存中已经存在数据(也就是缓存命中，cache hit)，则直接从缓存中返回数据
    + 当缓存中不存在数据(也就是缓存未命中，cache miss)，则先从数据库里读取数据，并且存入缓存，然后返回数据
  - 写：先把数据存到数据库中，成功删除缓存
    + 策略1:变更数据库-》变更缓存：变更数据库和变更缓存是两个独立操作，会因为写入顺序的不同造成数据的不一致:线程A先于线程B更新了数据库,但是后于线程B更新缓存，A用旧数据更新缓存：数据库与缓存不一致，引起脏数据
    * 更新缓存代价有时候是很高
      - 缓存值需要关联与计算，删除缓存就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，需要被使用的时候再重新计算
      - 怕两个并发的写操作导致脏数据
    + 策略2：更新数据库-》删除缓存中对应数据
      * A读数据，由于未命中那么从数据库中取数据
      * B写数据库，删除缓存
      * A由于网络延迟比较慢，将脏数据写入缓存
      * 这个case理论上会出现，不过实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大
      - 问题
        + 删除缓存失败导致数据库中是新数据，缓存中是旧数据：先删除缓存，再修改数据库
        + 删除了缓存，还没来得及修改数据库，一个请求过来，去读缓存，发现缓存空了后去查询数据库，查到了修改前的旧数据，放到了缓存中
      - 缺点
        + 当发生缓存未命中的情况时，则会比较慢，因为要经过三个步骤：查询缓存，从数据库读取，写入缓存
        + 复杂的逻辑都在应用程序中，如果实现微服务，多个微服务中会有重复的逻辑代码
        + 应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）
    * 策略3:先删除缓存，然后再更新数据库
      - 两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库
* Read/Write Through
  - 应用认为后端就是一个单一的存储，而存储自己维护自己的Cache
  - Read Through:查询操作中更新缓存,当缓存失效时候（过期或LRU换出）用缓存服务自己来加载，从而对应用方是透明的
    + 本地缓存，大量使用这种策略，如：Guava  Cache 中的 Loading Cache，预留扩展接口，只需要实现 CacheLoader 接口，如果缓冲没有该数据 kv 对，则自动调用接口方法从数据库获取
  - Write Through:当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）
  - 用于写入之后经常被读取的应用
  - 优点
    + 缓存不存在脏数据
    + 相比较Cache-Aside懒加载模式，读取速度更高，因为较少因为缓存未命中而从数据库中查找
    + 应用程序的逻辑相对简单
  - 缺点
    + 对于总是写入却很少被读取的应用，那么Write-Through会非常浪费性能，因为数据可能更改了很多次，却没有被读取，白白的每次都写入缓存造成写入延迟
    + 强依赖缓存了，对缓存服务的稳定性有较大要求
    + 增加新缓存节点时会有初始状态空数据问题
    + 写数据库是同步的，对于性能有比较大的开销
* Write Behind｜back
  - Read/Write Through 一个变种。和Write-Through写入的时机不同，Write-Back将缓存作为可靠的数据源，每次都只写入缓存，而写入数据库则采用异步的方式
  - 让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write back还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的，适用于读写密集的应用
    + 操作系统层面的 page cache 就是采用这种思想。就是操作系统在内存中给磁盘上的文件建立的缓存。在调用系统的 API 读写文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的都是 PageCache，也就是文件在内存中缓存的副本
  - 优点
    + 写入和读取数据都非常的快，因为都是从缓存中直接读取和写入
    + 对于数据库不可用的情况有一定的容忍度，即使数据库暂时不可用，系统也整体可用，当数据库之后恢复的时候，再将数据写入数据库
  - 缺点
    + 数据不是强一致性的，而且可能会丢
    + 逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来 lazy write
    + 有数据丢失的风险，如果缓存挂掉而数据没有及时写到数据库中，那么缓存中的有些数据将永久的丢失了
* Write-Around
  - 更新的时候只写入数据库，不写入缓存，结合Read-Through或者Cache-Aside使用，只在缓存未命中的情况下写缓存
  - 适合于只写入一次而很少被读取的应用
  - 优点
    + 相比较Write-Through写入的时候的效率较高，如果数据写入后很少被读取，缓存也不会被没用到的数据占满
  - 缺点
    + 如果数据会写入多次，那么可能存在缓存和数据库不一致
* 参考
  - [缓存更新套路](https://coolshell.cn/articles/17416.html)

## 序列化

分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一

* 要缓存的数据，并不是完全无需处理直接读写的，而是需要读入内存后，以某种语言的结构体或者对象来处理的，这就需要涉及到“序列化”和“反序列化”的问题
  - 如果采用直接拷贝内存的方式来缓存数据，当这些数据需要跨进程、甚至跨语言访问的时候，会出现那些指针、ID、句柄数据的失效。因为在另外一个进程空间里，这些“标记型”的数据都是不存在的。
  - 因此需要更深入的对数据缓存的方法，可能会使用所谓深拷贝的方案，也就是跟着那些指针去找出目标内存的数据，一并拷贝。
  - 一些更现代的做法，则是使用所谓序列化方案来解决这个问题，也就是用一些明确定义了的“拷贝方法”来定义一个结构体，然后用户就能明确的知道这个数据会被拷贝，直接取消了指针之类的内存地址数据的存在。比如著名的Protocol Buffer就能很方便的进行内存、磁盘、网络位置的缓存；
  - 现在常见的JSON，也被一些系统用来作为缓存的数据格式。
* 缓存的数据和程序真正要操作的数据，往往是需要进行一些拷贝和运算的，这就是序列化和反序列化的过程，这个过程很快，也有可能很慢。
  - 在选择数据缓存结构的时候，必须要注意其转换时间，否则缓存的效果可能被这些数据拷贝、转换消耗去很多，严重的甚至比不缓存更差。
  - 一般来说，缓存数据越解决使用时的内存结构，其转换速度就越快，在这点上，Protocol Buffer采用TLV编码，就比不上直接memcpy的一个C结构体，但是比编码成纯文本的XML或者JSON要来的更快。因为编解码的过程往往要进行复杂的查表映射，列表结构等操作
* 序列化速度
* 对象压缩比例
* 支持的序列化数据类型范围
* 反序列化的速度
* 框架接入易用性
* 框架：
  - Java源生序列化
  - Hessian
  - Protobuf
  - Kryo

## 命中率较低

* 过期时间太短， 这种场景可以根据实际情况适当增大过期时间
* 存在不合理缓存删除逻辑， 导致有效的缓存频繁被删除
* 不合理的key规则设计， 每次缓存访问的key都在变化， 导致无法命中缓存和频繁的新缓存创建
* key确实不存在，但是应用还是在频繁的访问， 这种应该从业务逻辑上杜绝

## 注意

* 评估当前业务使用的空间大小,提前考虑扩容问题。避免空间不足，导致热数据被置换出去，影响缓存命中率
* 不要把缓存当DB使用，因为会丢失
* 最好设置过期时间，可以自己回收
* key定义遵循一定规则，相同业务采用同一前缀
* 缓存对象粒度。高内聚低耦合，考虑尽可能复用，不要一个小字段修改导整个大对象全部失效
* 缓存对象大小要控制，不要过大，占用过多带宽
* 根据业务需求，选择合适缓存框架
* 是否要引入多级缓存，本地内存--》非持久化缓存（如memcache）---》持久化缓存---》DB，要注意数据一致性问题
  - 客户端浏览器缓存：减少对网站的访问
  - Web服务器缓存：减少应用服务器请求 模版缓存：动静分离
  - 数据库缓存：减少数据库的查询、减少文件系统I/O
  - 操作系统缓存：减少磁盘机械操作

## 技巧

* 创建
  - 主动创建缓存:系统定时创建
  - 请求的时候设置标志位。第一个请求到达，标识这个 url 正在创建缓存，其他请求进入等待队列
* 失效
  - 主动失效：用 API 调用方式实现。比如删除 key,或者调用 CDN 接口进行删除操作
  - 自动失效：设置失效时间

## 模板语法

* Mustache
* jade
* hbs

## Guava Cache

## Caffeine

## 图书

* 深入分布式缓存：从原理到实践
