# 秒杀

* 目的：吸引流量
* 过程
  - 秒杀开始前几分钟，大量用户开始进入秒杀商品详情页面，很多人开始频繁刷新秒杀商品详情页，这时秒杀商品详情页访问量会猛增
  - 秒杀开始，大量用户开始抢购，这时创建订单，扣库存压力会显著增大
* 特点
  - 瞬间高并发,疯狂的点鼠标
  - 库存少
  - 用户规模
    + 几百或者上千人的活动单体架构足以可以应付，简单的加锁、进程内队列可以轻松搞定
    + 一旦上升到百万、千万级别的规模就要考虑分布式集群来应对瞬时高并发
  - 读写冲突，锁非常严重，并发高响应慢

## 优化

* 方案
    - 将请求尽量拦截在系统上游（不要让锁冲突落到数据库上去）
    - 充分利用缓存（缓存抗读压力），典型的读多些少的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求
* 浏览器层（限速）
  - 客户端：产品层面，用户点击"查询"或者"购票"后，按钮置灰，禁止用户重复提交请求
  - JS层面：限制用户在x秒之内只能提交一次请求
  - 页面静态化：把秒杀商品详情页做成静态页面，把商品详情、商品价格等参数、评论评价等信息全部放在这个静态页面里，然后把这个静态页面上传到CDN上预热，用CDN扛流量，这样大量的商品详情页的访问请求就不用访问自己的网站（源站）。既可以提高访问速度，也没有给网站增加压力，同时也减少了网站带宽压力
* 站点层（按照uid做限速，做页面缓存）
  - 防止程序员写for循环调用:对uid进行请求计数和去重,5s只透过一个请求
  - 其余的请求怎么办？缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）
* 服务层
  - 写请求：请求队列，每次只透有限的写请求去数据层（下订单，支付这样的写业务）
  - 读请求：cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题
  - 分时分段售票：流量摊匀
  - 数据粒度的优化：去购票，对于余票查询票剩了58张还是26张关注么，只关心有票和无票？流量大的时候，做一个粗粒度的"有票""无票"缓存即可
  - 一些业务逻辑的异步：例如下单业务与 支付业务的分离
* 分流
  - SLB对多台云服务器进行流量分发，扩展应用系统对外的服务能力，消除单点故障提升应用系统的可用性
  - Nginx做限流分发，来保障后端服务的正常运行
* 限流: 当访问频率或者并发请求超过其承受范围的时候，考虑限流来保证接口的可用性，以防止非预期的请求对系统压力过大而引起的系统瘫痪
  - 网关可以做成集群，多节点分摊访问压力
  - 网关（zuul，nginx）层：对下单等接口按userID限流，几秒钟只能访问一次
  - 策略：拒绝多余的访问按秒杀失败处理或者让多余的访问排队等待服务
  - 算法
    + 令牌桶算法：网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送
    + 漏桶：控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。无论流入速率多大都按照既定的速率去处理，如果桶满则拒绝服务
  - 开源工具包guava提供的限流工具类RateLimiter进行API限流
  - OpenResty限流
    + 限制接口总并发数/请求数:resty.limit.count
    + 限制接口时间窗请求数:resty.limit.conn
    + 平滑限制接口请求数:resty.limit.req
* 缓存:尽量不要让大量请求穿透到DB层，活动开始前商品信息可以推送至分布式缓存。提升系统访问速度和增强系统的处理能力
* 异步:分析并识别出可以异步处理的逻辑，比如日志，缩短系统响应时间
* 主备
* 分布式锁解决了集群下数据的安全一致性问题
  - 基于 Redis 或者 Zookeeper 分布式锁，Kafka 或者 Redis 做消息队列，DRDS数据库中间件实现数据的读写分离
* 分层优化
  - 应用服务优化：Nginx最佳配置、Tomcat连接池优化、数据库配置优化、数据库连接池优化
* 分段放行：为了尽量避免库存被机器人和自动脚本抢走，200个请求不能在秒杀开始瞬间同时放行，可以分段放行，比如秒杀开始后随机选取100ms内的5个请求放行（这100ms内的其他请求直接拒掉，按秒杀失败处理），之后每隔100ms放行5个请求，4秒钟可以放行完200个请求。分段放行，除了限制了机器人和自动脚本，把请求分散在各个时间段，还进一步缓解了后端服务的压力
  - 分段放行总时间不能太长，假如每100ms放行1个请求，放行完所有200个请求需要20秒时间，这样用户就会明显感知到下单早的人没秒杀成功，下单晚的人反而秒杀成功了，用户体验会变差
* 放行的下单请求就有几万个：压力就在数据库了，扣减库存压力，创建订单压力
  - 库存可以放到Reids缓存中，来提高扣减库存吞吐能力。对于热点商品的库存可以利用Redis分片存储
  - 创建订单可以走异步消息队列。后端服务接到下单请求，直接放进消息队列，监听服务取出消息后，先将订单信息写入Redis，每隔100ms或者积攒100条订单，批量写入数据库一次。前端页面下单后定时向后端拉取订单信息，获取到订单信息后跳转到支付页面。用这种批量异步写入数据库的方式大幅减少了数据库写入频次，从而明显降低了订单数据库写入压力
* 网络
  - 秒杀前要和网络运营商、CDN服务商提前申请带宽
  - 全国用户，最好是BGP多线机房，减少网络延迟
* 避免超卖
  - 如果在redis中扣减库存，可以利用decr命令扣减库存，decr是原子操作，在分布式环境下也不会有并发问题，decr扣减库存后，判断返回值，如果返回值小于0，扣减库存失败，秒杀也就失败了
  - 如果在数据库中扣减库存可以在where后面加上库存大于0的条件，来避免库存被减成负值。这样就可以避免超卖情况发生了
* 接口防刷
  - 在网关层对下单等接口按userID限流
  - 网关层除了对userID做限流外，还要做整体限流。在实际访问量超过预估访问量时，整体限流可以起到保护作用，避免系统被压垮
* 防止重复下单，按userID限流已经起到了防止重复下单的作用。假如限制同一个用户10分钟能下一次单，一般情况下10分钟内，商品早已经被抢光了，用户也就没有再次下单的机会了
* 结合风控系统，在网关层把羊毛党等有问题的用户请求直接拒掉
* 在网关层上面再加一层防火墙或者高防服务（高防IP），来防御DDos等分布式网络攻击

* 如何防止恶意调用秒杀接口？
* 如果用户秒杀成功，一直不支付该怎么办？
* 消息队列处理完成后，如果异步通知给用户秒杀成功？
* 如何保障 Redis、Zookeeper 、Kafka 服务的正常运行(高可用)
* 高并发下秒杀业务如何做到不影响其他业务(隔离性)
  - 业务隔离：从业务上把秒杀和日常的售卖区分开来，把秒杀做为营销活动，要参与秒杀的商品需要提前报名参加活动，这样就能提前知道哪些商家哪些商品要参与秒杀，可以根据提报的商品提前生成静态页面并上传到CDN预热，提报的商品库存也需要提前预热，可以将商品库存在活动开始前预热到Redis，避免秒杀开始后大量的缓存穿透
  - 部署隔离：秒杀相关服务和日常服务要分组部署，不能因为秒杀出问题影响日常售卖业务。可以申请单独的秒杀域名，从网络入口层就开始分流。网关也单独部署，秒杀走自己单独的网关，从而避免日常网关受到影响。秒杀可以复用订单，库存，支付等日常服务，只是需要一些小的改造（比如下单流程走消息队列，批量写入订单库，以及在Redis中扣减库存）
  - 数据隔离：为了避免秒杀活动影响到日常售卖业务，Redis缓存需要单独部署，甚至数据库也需要单独部署！数据隔离后，秒杀剩余的库存怎么办？秒杀活动结束后，剩余库存可以归还到日常库存继续做为普通商品售卖。数据隔离后，秒杀订单和日常订单不在相同的数据库，之后的订单查询怎么展示？可以在创建秒杀订单后发消息到消息队列，日常订单服务采取拉的方式消费消息，这时日常订单服务是主动方，可以采用线程池的方式，根据机器的性能来增加或缩小线程池的大小，控制拉取消息的速度，来控制订单数据库的写入压力
* 下单减库存的方案，下单时扣减库存，然后再进行支付

![秒杀架构](../_static/seckill.webp "秒杀架构")

![令牌桶算法](../_static/tokenbottle.png "令牌桶算法")

```
#统一在http域中进行配置
#限制请求
limit_req_zone $binary_remote_addr $uri zone=api_read:20m rate=50r/s;
#按ip配置一个连接 zone
limit_conn_zone $binary_remote_addr zone=perip_conn:10m;
#按server配置一个连接 zone
limit_conn_zone $server_name zone=perserver_conn:100m;
server {
        listen       80;
        server_name  seckill.52itstyle.com;
        index index.jsp;

        location / {
              #请求限流排队通过 burst默认是0
              limit_req zone=api_read burst=5;
              #连接数限制,每个IP并发请求为2
              limit_conn perip_conn 2;
              #服务所限制的连接数(即限制了该server并发连接数量)
              limit_conn perserver_conn 1000;
              #连接限速
              limit_rate 100k;
              proxy_pass      http://seckill;
        }
}

upstream seckill {
        fair;
        server  172.16.1.120:8080 weight=1  max_fails=2 fail_timeout=30s;
        server  172.16.1.130:8080 weight=1  max_fails=2 fail_timeout=30s;
}
```

## 全链路压测

压测优化过程就是一个不断优化不断改进的过程，事先通过测试不断发现问题，优化系统，避免问题，指定应急方案

* 分析需压测业务场景涉及系统
* 协调各个压测系统资源并搭建压测环境
* 压测数据隔离以及监控(响应时间、吞吐量、错误率等数据以图表形式实时显示)
* 压测结果统计(平均响应时间、平均吞吐量等数据以图表形式在测试结束后显示)
* 优化单个系统性能、关联流程以及整个业务流程

```sh
yum -y install httpd-tools
ab -v
ab --help

ab -n 1000 -c 100 http://127.0.0.1/
```

## 参考

* [小柒2012 / spring-boot-seckill](https://gitee.com/52itstyle/spring-boot-seckill):从0到1构建分布式秒杀系统 https://blog.52itstyle.com/archives/2853/
* [分布式秒杀系统构建中的多种限流实现](https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&mid=2650768375&idx=1&sn=0b1de5c41ac15db0fc53f279fcfa58b6&chksm=f3f93662c48ebf7481bd7ce8ca74a3f2ad66fd80e7f50e313d8ebd1152a094045d75113a832d)
* [openresty/lua-resty-limit-traffic](https://github.com/openresty/lua-resty-limit-traffic):Lua library for limiting and controlling traffic in OpenResty/ngx_lua
