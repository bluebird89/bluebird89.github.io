# 秒杀

* 过程
  - 秒杀开始前几分钟，大量用户开始进入秒杀商品详情页面，很多人开始频繁刷新秒杀商品详情页，这时秒杀商品详情页访问量会猛增
  - 秒杀开始，大量用户开始抢购，这时创建订单，扣库存压力会显著增大
* 特点
  - 瞬间高并发,疯狂的点鼠标
  - 库存少
  - 用户规模
    + 几百或者上千人的活动单体架构足以可以应付，简单的加锁、进程内队列可以轻松搞定
    + 一旦上升到百万、千万级别的规模就要考虑分布式集群来应对瞬时高并发
  - 读写冲突，锁非常严重，并发高响应慢
* 解决两个核心问题，一是并发读，一是并发写


流量控制：展示层流量 > 应用层流量 > 服务层流量 > DB 层流量

让 DB 可以象应用层和服务层一样随时分布式扩展，可实际上 DB 做不到，DB 是最大的瓶颈，所以才有了 排队系统 和 预约系统。

缓存是一定要用到的，但秒杀往往是瞬间的事，缓存的时效性导致缓存系统在这样的大流量对 DB 的瞬间冲击时几乎没有帮助。

库存更新使得大量的 udpate sql 直接到了 DB，DB 压力非常大。我们尝试了在 mysql 下先 select，有库存时再 update，

排队系统是目前大多秒杀场景最常用的，本质是 异步处理放缓流量、削平瞬间峰值，降低对后续服务层和 DB 层的流量冲击。

预约系统的作用在于 提前预知流量，虽然预约量本身不可控，但秒杀前可以针对已知流量提前做好预案，让 系统处于可控状态。


- DB 层不能任意或随时扩展，是最大的瓶颈和最后的底线，是绝对不能破的，一是 DB 并发连接不能超过最大连接数，二是 DB 压力不能太大，所以流量必须在前端控制。
- 服务层虽然可以分布式扩展，但受限于 DB 连接，并不意味着可以无限扩展。如果是公共服务层不区分秒杀业务和普通业务，是不好做流量过滤的，因为会影响到普通业务的正常流量，这种情况下只能从应用层想办法。如果是单独为秒杀流程服务，或者说流量来源能区分出秒杀业务或其他业务的，那还是有思路的，办法总比困难多，如：

  - 随机数过滤：将一定百分比的用户请求直接过滤返回给应用层包装，以友好的方式返回提示给用户。
  - 预设阀值限流：设定单机在单位时间的处理最大阀值，如单机的实际处理能力 TPS 最大是 10000/ 秒，设定阀值为 20，当单机单位时间内（秒）的并发请求达到阀值时，后续请求直接返回给应用层，以友好的方式返回提示给用户。此时系统并不处理业务逻辑和进行 DB 操作，只是简单地判断和响应返回，所以单机的处理能力 20+X 是远大于 10000/ 秒的。
  - 注：上述两种方法 并不是 串行或有依赖的，两者都是一种可选的方法（每层都可以使用），它们的本质都是 流量过滤 和 提升单机处理能力 保护系统以免被冲垮。在保证一定用户体验（单机处理能力）的情况下将流量过滤最大化。

- 应用层

  - 通过 Tomcat 最大连接数控制，超过最大连接数的请求 直接拒绝服务，但用户体验很不好，系统假死崩溃的感觉，尽量通过加分布式服务器的方式解决。（服务层一定要通过应用层控制不能超过最大连接数，展示层和应用层直接取决于用户量，很难控制，可以使用预约系统让流量可控）

- 展示层：随机数过滤，将一定百分比的流量请求直接以友好的方式提示给用户。 正常讲展示层是 不应该过滤 的，请求都没有到服务器，但从业务角度看，抢购秒杀本身就是一个概率事件，并不是完全取决于先后顺序 (有时后来的反而能抢到，这取决于分布式服务器处理、网络、排队系统的异步处理等)。 虽然对技术人来说欺骗用户的感觉很不耻，但关键时刻偶尔抱一下佛脚也是一种办法，总比系统被冲垮了好。


## 优化

* 性能优化需要一个基准值，所以系统还需要做好应用基线，比如性能基线（何时性能突然下降）、成本基线（去年大促用了多少机器）、链路基线（核心流程发生了哪些变化），通过基线持续关注系统性能，促使系统在代码层面持续提升编码质量、业务层面及时下掉不合理调用、架构层面不断优化改进
* 方案
    - 将请求尽量拦截在系统上游（不要让锁冲突落到数据库上去）
    - 充分利用缓存（缓存抗读压力），典型的读多些少的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求
* 分层优化
  - 浏览器层（限速）
    + 客户端：产品层面，用户点击"查询"或者"购票"后，按钮置灰，禁止用户重复提交请求
    + JS层面：限制用户在x秒之内只能提交一次请求
    + 页面静态化：把秒杀商品详情页做成静态页面，把商品详情、商品价格等参数、评论评价等信息全部放在这个静态页面里，然后把这个静态页面上传到CDN上预热，用CDN扛流量，这样大量的商品详情页的访问请求就不用访问自己的网站（源站）。既可以提高访问速度，也没有给网站增加压力，同时也减少了网站带宽压力
  - 站点层（按照uid做限速，做页面缓存）
    + 防止程序员写for循环调用:对uid进行请求计数和去重,5s只透过一个请求
    + 其余的请求怎么办？缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）
  - 应用层：Nginx最佳配置、Tomcat连接池优化、数据库配置优化、数据库连接池优化
  - 服务层
    + 写请求：请求队列，每次只透有限的写请求去数据层（下订单，支付这样的写业务）
    + 读请求：cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题
    + 分时分段售票：流量摊匀
    + 数据粒度的优化：去购票，对于余票查询票剩了58张还是26张关注么，只关心有票和无票？流量大的时候，做一个粗粒度的"有票""无票"缓存即可
    + 一些业务逻辑的异步：例如下单业务与 支付业务的分离
* 分流
  - SLB对多台云服务器进行流量分发，扩展应用系统对外的服务能力，消除单点故障提升应用系统的可用性
  - Nginx做限流分发，来保障后端服务的正常运行
* 限流: 当访问频率或者并发请求超过其承受范围的时候，考虑限流来保证接口的可用性，以防止非预期的请求对系统压力过大而引起的系统瘫痪
  - 网关可以做成集群，多节点分摊访问压力
  - 网关（zuul，nginx）层：对下单等接口按userID限流，几秒钟只能访问一次
  - 策略：拒绝多余的访问按秒杀失败处理或者让多余的访问排队等待服务
  - 算法
    + 令牌桶算法：网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送
    + 漏桶：控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。无论流入速率多大都按照既定的速率去处理，如果桶满则拒绝服务
  - 开源工具包guava提供的限流工具类RateLimiter进行API限流
  - OpenResty限流
    + 限制接口总并发数/请求数:resty.limit.count
    + 限制接口时间窗请求数:resty.limit.conn
    + 平滑限制接口请求数:resty.limit.req
* 缓存:尽量不要让大量请求穿透到DB层，活动开始前商品信息可以推送至分布式缓存。提升系统访问速度和增强系统的处理能力
* 异步:分析并识别出可以异步处理的逻辑，比如日志，缩短系统响应时间
* 主备
* 分布式锁解决了集群下数据的安全一致性问题
  - 基于 Redis 或者 Zookeeper 分布式锁，Kafka 或者 Redis 做消息队列，DRDS数据库中间件实现数据的读写分离
* 分段放行：为了尽量避免库存被机器人和自动脚本抢走，200个请求不能在秒杀开始瞬间同时放行，可以分段放行，比如秒杀开始后随机选取100ms内的5个请求放行（这100ms内的其他请求直接拒掉，按秒杀失败处理），之后每隔100ms放行5个请求，4秒钟可以放行完200个请求。分段放行，除了限制了机器人和自动脚本，把请求分散在各个时间段，还进一步缓解了后端服务的压力
  - 分段放行总时间不能太长，假如每100ms放行1个请求，放行完所有200个请求需要20秒时间，这样用户就会明显感知到下单早的人没秒杀成功，下单晚的人反而秒杀成功了，用户体验会变差
* 放行的下单请求就有几万个：压力就在数据库了，扣减库存压力，创建订单压力
  - 库存可以放到Reids缓存中，来提高扣减库存吞吐能力。对于热点商品的库存可以利用Redis分片存储
  - 创建订单可以走异步消息队列。后端服务接到下单请求，直接放进消息队列，监听服务取出消息后，先将订单信息写入Redis，每隔100ms或者积攒100条订单，批量写入数据库一次。前端页面下单后定时向后端拉取订单信息，获取到订单信息后跳转到支付页面。用这种批量异步写入数据库的方式大幅减少了数据库写入频次，从而明显降低了订单数据库写入压力
* 网络
  - 秒杀前要和网络运营商、CDN服务商提前申请带宽
  - 全国用户，最好是BGP多线机房，减少网络延迟
* 避免超卖
  - 如果在redis中扣减库存，可以利用decr命令扣减库存，decr是原子操作，在分布式环境下也不会有并发问题，decr扣减库存后，判断返回值，如果返回值小于0，扣减库存失败，秒杀也就失败了
  - 如果在数据库中扣减库存可以在where后面加上库存大于0的条件，来避免库存被减成负值。这样就可以避免超卖情况发生了
* 接口防刷
  - 在网关层对下单等接口按userID限流
  - 网关层除了对userID做限流外，还要做整体限流。在实际访问量超过预估访问量时，整体限流可以起到保护作用，避免系统被压垮
* 防止重复下单，按userID限流已经起到了防止重复下单的作用。假如限制同一个用户10分钟能下一次单，一般情况下10分钟内，商品早已经被抢光了，用户也就没有再次下单的机会了
* 结合风控系统，在网关层把羊毛党等有问题的用户请求直接拒掉
* 在网关层上面再加一层防火墙或者高防服务（高防IP），来防御DDos等分布式网络攻击

* 如何防止恶意调用秒杀接口？
* 如果用户秒杀成功，一直不支付该怎么办？
* 消息队列处理完成后，如果异步通知给用户秒杀成功？
* 如何保障 Redis、Zookeeper 、Kafka 服务的正常运行(高可用)
* 高并发下秒杀业务如何做到不影响其他业务(隔离性)
  - 业务隔离：从业务上把秒杀和日常的售卖区分开来，把秒杀做为营销活动，要参与秒杀的商品需要提前报名参加活动，这样就能提前知道哪些商家哪些商品要参与秒杀，可以根据提报的商品提前生成静态页面并上传到CDN预热，提报的商品库存也需要提前预热，可以将商品库存在活动开始前预热到Redis，避免秒杀开始后大量的缓存穿透
  - 部署隔离：秒杀相关服务和日常服务要分组部署，不能因为秒杀出问题影响日常售卖业务。可以申请单独的秒杀域名，从网络入口层就开始分流。网关也单独部署，秒杀走自己单独的网关，从而避免日常网关受到影响。秒杀可以复用订单，库存，支付等日常服务，只是需要一些小的改造（比如下单流程走消息队列，批量写入订单库，以及在Redis中扣减库存）
  - 数据隔离：为了避免秒杀活动影响到日常售卖业务，Redis缓存需要单独部署，甚至数据库也需要单独部署！数据隔离后，秒杀剩余的库存怎么办？秒杀活动结束后，剩余库存可以归还到日常库存继续做为普通商品售卖。数据隔离后，秒杀订单和日常订单不在相同的数据库，之后的订单查询怎么展示？可以在创建秒杀订单后发消息到消息队列，日常订单服务采取拉的方式消费消息，这时日常订单服务是主动方，可以采用线程池的方式，根据机器的性能来增加或缩小线程池的大小，控制拉取消息的速度，来控制订单数据库的写入压力
* 下单减库存的方案，下单时扣减库存，然后再进行支付

![秒杀架构](../_static/seckill.webp "秒杀架构")

![令牌桶算法](../_static/tokenbottle.png "令牌桶算法")

```
#统一在http域中进行配置
#限制请求
limit_req_zone $binary_remote_addr $uri zone=api_read:20m rate=50r/s;
#按ip配置一个连接 zone
limit_conn_zone $binary_remote_addr zone=perip_conn:10m;
#按server配置一个连接 zone
limit_conn_zone $server_name zone=perserver_conn:100m;
server {
        listen       80;
        server_name  seckill.52itstyle.com;
        index index.jsp;

        location / {
              #请求限流排队通过 burst默认是0
              limit_req zone=api_read burst=5;
              #连接数限制,每个IP并发请求为2
              limit_conn perip_conn 2;
              #服务所限制的连接数(即限制了该server并发连接数量)
              limit_conn perserver_conn 1000;
              #连接限速
              limit_rate 100k;
              proxy_pass      http://seckill;
        }
}

upstream seckill {
        fair;
        server  172.16.1.120:8080 weight=1  max_fails=2 fail_timeout=30s;
        server  172.16.1.130:8080 weight=1  max_fails=2 fail_timeout=30s;
}
```

## 高性能

* 高读就尽量"少读"或"读少"，高写就数据拆分
* 动静分离：将动态页面改造成适合缓存的静态页面
  - 思路
    + 数据要尽量少，以便减少没必要的请求
    + 路径要尽量短，以便提高单次请求的效率
  - 数据拆分：分离出动态数据
    + 用户：用户身份信息包括登录状态以及登录画像等，相关要素可以单独拆分出来，通过动态请求进行获取；与之相关的广平推荐，如用户偏好、地域偏好等，同样可以通过异步方式进行加载
    + 时间：秒杀时间是由服务端统一管控的，可以通过动态请求进行获取
  - 静态缓存
    + 直接缓存整个 HTTP 连接而不是仅仅缓存静态数据，Web 代理服务器根据请求 URL，可以直接取出对应的响应体然后直接返回，响应过程无需重组 HTTP 协议，也无需解析 HTTP 请求头
    + 作为缓存键，URL唯一化是必不可少的，只是对于商品系统，URL 天然是可以基于商品 ID 来进行唯一标识的，比如淘宝的https://item.taobao.com/item.htm?id=xxxx
    + 缓存位置
      * 浏览器：第一选择但不可控，主要体现在如果用户不主动刷新，系统很难主动地把消息推送给用户，会导致用户端在很长一段时间内看到的信息都是错误的。对于秒杀系统，保证缓存可以在秒级时间内失效是不可或缺的
      * CDN:本身更擅长处理大并发的静态文件请求，既可以做到主动失效，又离用户尽可能近
        - 失效问题。任何一个缓存都应该是有时效的，尤其对于一个秒杀场景。所以，系统需要保证全国各地的 CDN 在秒级时间内失效掉缓存信息，这实际对 CDN 的失效系统要求是很高的
        - 命中率问题。高命中是缓存系统最为核心的性能要求，不然缓存就失去了意义。如果将数据放到全国各地的 CDN ，势必会导致请求命中同一个缓存的可能性降低，那么命中率就成为一个问题
        - 节点的选取
          + 临近访问量集中的地区
          + 距离主站较远的地区
          + 节点与主站间网络质量良好的地区
        - 选择 CDN 的二级缓存比较合适:cdn 中回源动态数据，数量偏少，容量也更大，访问量相对集中
      * 服务端:主要进行动态逻辑计算及加载，本身并不擅长处理大量连接，每个连接消耗内存较多，同时 Servlet 容器解析 HTTP 较慢，容易侵占逻辑计算资源；另外，静态数据下沉至此也会拉长请求路径
  - 数据整合：前端如何组织数据页，动态数据的加载处理
    + ESI 方案：Web 代理服务器上请求动态数据，并将动态数据插入到静态页面中，用户看到页面时已经是一个完整的页面。这种方式对服务端性能要求高，但用户体验较好
    + CSI 方案：Web 代理服务器上只返回静态页面，前端单独发起一个异步 JS 请求动态数据。这种方式对服务端性能友好，但用户体验稍差
* 热点优化：基于二八原则对数据进行了纵向拆分，以便进行针对性地处理
  - 热点操作：零点刷新、零点下单、零点添加购物车等，是用户的行为，不好改变，但可以做一些限制保护，比如用户频繁刷新页面时进行提示阻断
  - 热点数据
    + 类型
      * 静态热点：能够提前预测的热点数据。大促前夕，可以根据大促的行业特点、活动商家等纬度信息分析出热点商品，或者通过卖家报名的方式提前筛选；另外，还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，即可视为热点商品
      * 动态热点：无法提前预测的热点数据。冷热数据往往是随实际业务场景发生交替变化的，尤其是如今直播卖货模式的兴起——带货商临时做一个广告，就有可能导致一件商品在短时间内被大量购买。由于此类商品日常访问较少，即使在缓存系统中一段时间后也会被逐出或过期掉，甚至在db中也是冷数据。瞬时流量的涌入，往往导致缓存被击穿，请求直接到达DB，引发DB压力过大
    + 热点识别
      * 动态发现能力，一个常见实现思路是：
        - 异步采集交易链路各个环节的热点 Key 信息，如 Nginx采集访问URL或 Agent 采集热点日志（一些中间件本身已具备热点发现能力），提前识别潜在的热点数据
        - 聚合分析热点数据，达到一定规则的热点数据，通过订阅分发推送到链路系统，各系统根据自身需求决定如何处理热点数据，或限流或缓存，从而实现热点保护
      * 热点数据采集最好采用异步方式，一方面不会影响业务的核心交易链路，一方面可以保证采集方式的通用性
      * 热点发现最好做到秒级实时，这样动态发现才有意义，实际上也是对核心节点的数据采集和分析能力提出了较高的要求
    + 热点隔离：不要让 1% 影响到另外的 99%
      * 业务隔离。秒杀作为一种营销活动，卖家需要单独报名，从技术上来说，系统可以提前对已知热点做缓存预热
      * 系统隔离。系统隔离是运行时隔离，通过分组部署和另外 99% 进行分离，另外秒杀也可以申请单独的域名，入口层就让请求落到不同的集群中
      * 数据隔离。秒杀数据作为热点数据，可以启用单独的缓存集群或者DB服务组，从而更好的实现横向或纵向能力扩展
    + 热点优化
      * 缓存：热点缓存是最为有效的办法。如果热点数据做了动静分离，那么可以长期缓存静态数据
      * 限流：流量限制更多是一种保护机制。需要注意的是，各服务要时刻关注请求是否触发限流并及时进行review
* 系统优化
  - 减少序列化：减少 Java 中的序列化操作可以很好的提升系统性能。序列化大部分是在 RPC 阶段发生，因此应该尽量减少 RPC 调用，一种可行的方案是将多个关联性较强的应用进行 “合并部署”，从而减少不同应用之间的 RPC 调用（微服务设计规范）
  - 直接输出流数据：只要涉及字符串的I/O操作，无论是磁盘 I/O 还是网络 I/O，都比较耗费 CPU 资源，因为字符需要转换成字节，而这个转换又必须查表编码。所以对于常用数据，比如静态字符串，推荐提前编码成字节并缓存，具体到代码层面就是通过 OutputStream() 类函数从而减少数据的编码转换；另外，热点方法toString()不要直接调用ReflectionToString实现，推荐直接硬编码，并且只打印DO的基础要素和核心要素
  - 裁剪日志异常堆栈：无论是外部系统异常还是应用本身异常，都会有堆栈打出，超大流量下，频繁的输出完整堆栈，只会加剧系统当前负载。可以通过日志配置文件控制异常堆栈输出的深度
  - 去组件框架：极致优化要求下，可以去掉一些组件框架，比如去掉传统的 MVC 框架，直接使用 Servlet 处理请求。这样可以绕过一大堆复杂且用处不大的处理逻辑，节省毫秒级的时间，当然，需要合理评估对框架的依赖程度

## 一致性

* 减库存：在用户体验和商业诉求两方面，其本质原因在于购物过程存在两步甚至多步操作，在不同阶段减库存，容易存在被恶意利用的漏洞
  - 下单减库存。买家下单后，扣减商品库存。最简单且控制最为精确的一种
    + 优势：用户体验最好。下单减库存是最简单的减库存方式，也是控制最精确的一种。下单时可以直接通过数据库事务机制控制商品库存，所以一定不会出现已下单却付不了款的情况。
    + 劣势：可能卖不出去。正常情况下，买家下单后付款概率很高，所以不会有太大问题。但有一种场景例外，就是当卖家参加某个促销活动时，竞争对手通过恶意下单的方式将该商品全部下单，导致库存清零，那么这就不能正常售卖了——要知道，恶意下单的人是不会真正付款的，这正是 “下单减库存” 的不足之处。
  - 付款减库存。买家下单后，并不立即扣减库存，而是等到付款后才真正扣减库存。但因为付款时才减库存，如果并发比较高，可能出现买家下单后付不了款的情况，因为商品已经被其他人买走了
    + 优势：一定实际售卖。“下单减库存” 可能导致恶意下单，从而影响卖家的商品销售， “付款减库存” 由于需要付出真金白银，可以有效避免。
    + 劣势：用户体验较差。用户下单后，不一定会实际付款，假设有 100 件商品，就可能出现 200 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在大促的热门商品上。如此一来就会导致很多买家下单成功后却付不了款，购物体验自然是比较差的。
  - 预扣库存。相对复杂一些，买家下单后，库存为其保留一定的时间（如 15 分钟），超过这段时间，库存自动释放，释放后其他买家可以购买
    + 优势：缓解了以上两种方式的问题。预扣库存实际就是“下单减库存”和 “付款减库存”两种方式的结合，将两次操作进行了前后关联，下单时预扣库存，付款时释放库存
    + 劣势：并没有彻底解决以上问题。比如针对恶意下单的场景，虽然可以把有效付款时间设置为 10 分钟，但恶意买家完全可以在 10 分钟之后再次下单
* 业界最为常见的是预扣库存。无论是外卖点餐还是电商购物，下单后一般都有个 “有效付款时间”，超过该时间订单自动释放，这就是典型的预扣库存方案。但如上所述，预扣库存还需要解决恶意下单的问题，保证商品卖的出去；另一方面，如何避免超卖，也是一个痛点
  - 卖的出去：恶意下单的解决方案主要还是结合安全和反作弊措施来制止。比如，识别频繁下单不付款的买家并进行打标，这样可以在打标买家下单时不减库存；再比如为大促商品设置单人最大购买件数，一人最多只能买 N 件商品；又或者对重复下单不付款的行为进行次数限制阻断等
  - 避免超卖：库存超卖的情况实际分为两种。对于普通商品，秒杀只是一种大促手段，即使库存超卖，商家也可以通过补货来解决；而对于一些商品，秒杀作为一种营销手段，完全不允许库存为负，也就是在数据一致性上，需要保证大并发请求时数据库中的库存字段值不能为负，一般有多种方案：
    + 在通过事务来判断，即保证减后库存不能为负，否则就回滚；
    + 直接设置数据库字段类型为无符号整数，这样一旦库存为负就会在执行 SQL 时报错；
    + 使用 CASE WHEN 判断语句: `UPDATE item SET inventory = CASE WHEN inventory >= xxx THEN inventory-xxx ELSE inventory END`
* 优化:读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化思路的本质还是基于 CAP 理论做平衡
  - 高并发读
    + 秒杀场景解决高并发读问题，关键词是“分层校验”。即在读链路时，只进行不影响性能的检查操作，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求等，而不做一致性校验等容易引发瓶颈的检查操作；直到写链路时，才对库存做一致性检查，在数据层保证最终准确性。
    + 在分层校验设定下，系统可以采用分布式缓存甚至LocalCache来抵抗高并发读。即允许读场景下一定的脏数据，这样只会导致少量原本无库存的下单请求被误认为是有库存的，等到真正写数据时再保证最终一致性，由此做到高可用和一致性之间的平衡。
    + 分层校验的核心思想是：不同层次尽可能过滤掉无效请求，只在“漏斗” 最末端进行有效处理，从而缩短系统瓶颈的影响路径
  - 高并发写
    + 更换DB选型
      * 秒杀商品和普通商品的减库存是有差异的，核心区别在数据量级小、交易时间短，因此能否把秒杀减库存直接放到缓存系统中实现呢，也就是直接在一个带有持久化功能的缓存中进行减库存操作，比如 Redis？
      * 如果减库存逻辑非常单一的话，比如没有复杂的 SKU 库存和总库存这种联动关系的话，个人认为是完全可以的。但如果有比较复杂的减库存逻辑，或者需要使用到事务，那就必须在数据库中完成减库存操作
    + 优化DB性能
      * 库存数据落地到数据库实现其实是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁。但并发越高，等待线程就会越多，TPS 下降，RT 上升，吞吐量会受到严重影响——注意，这里假设数据库已基于上文【性能优化】完成数据隔离，以便于讨论聚焦
      * 解决并发锁的问题，有两种办法：
        - 应用层排队:通过缓存加入集群分布式锁，从而控制集群对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用过多的数据库连接
        - 数据层排队:应用层排队是有损性能的，数据层排队是最为理想的。业界中，阿里的数据库团队开发了针对InnoDB 层上的补丁程序（patch），可以基于DB层对单行记录做并发排队，从而实现秒杀场景下的定制优化——注意，排队和锁竞争是有区别的，如果熟悉 MySQL 的话，就会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换都是比较消耗性能的

## 高可用

* 流量削峰:有效请求额度是有限的。并发度越高，无效请求也就越多。但秒杀作为一种商业营销手段，活动开始之前是希望有更多的人来刷页面，只是真正开始后，秒杀请求不是越多越好。因此系统可以设计一些规则，人为的延缓秒杀请求，甚至可以过滤掉一些无效请求
  - 添加答题:通过提升购买的复杂度，达到两个目的
    + 防止作弊。早期秒杀器比较猖獗，存在恶意买家或竞争对手使用秒杀器扫货的情况，商家没有达到营销的目的，所以增加答题来进行限制
    + 延缓请求。零点流量的起效时间是毫秒级的，答题可以人为拉长峰值下单的时长，由之前的 <1s 延长到 <10s。这个时间对于服务端非常重要，会大大减轻高峰期并发压力；另外，由于请求具有先后顺序，答题后置的请求到来时可能已经没有库存了，因此根本无法下单，此阶段落到数据层真正的写也就非常有限了
    + 需要对提交时间做验证，比如<1s 人为操作的可能性就很小，可以进一步防止机器答题的情况
    + 通过在入口层削减流量，从而让系统更好地支撑瞬时峰值
  - 排队：在业务层将一步操作转变成两步操作，从而起到缓冲的作用，鉴于此种方式的弊端，最终还是要基于业务量级和秒杀场景做出妥协和平衡
    + 手段
      * 使用消息队列，通过把同步的直接调用转换成异步的间接推送缓冲瞬时流量
      * 线程池加锁等待
      * 本地内存蓄洪等待
      * 本地文件序列化写，再顺序读
    + 弊端
      * 请求积压。流量高峰如果长时间持续，达到了队列的水位上限，队列同样会被压垮，这样虽然保护了下游系统，但是和请求直接丢弃也没多大区别
      * 用户体验。异步推送的实时性和有序性自然是比不上同步调用的，由此可能出现请求先发后至的情况，影响部分敏感用户的购物体验
  - 过滤：核心结构在于分层，通过在不同层次过滤掉无效请求，达到数据读写的精准触发。常见的过滤主要有以下几层：
    + 读限流：对读请求做限流保护，将超出系统承载能力的请求过滤掉
    + 读缓存：对读请求做数据缓存，将重复的请求过滤掉
    + 写限流：对写请求做限流保护，将超出系统承载能力的请求过滤掉
    + 写校验：对写请求做一致性校验，只保留最终的有效数据
  - 本质是在寻求商业诉求与架构性能之间的平衡
* Plan B
  - 涉及架构阶段、编码阶段、测试阶段、发布阶段、运行阶段，以及故障发生时，逐一进行分析：
    + 架构阶段：考虑系统的可扩展性和容错性，避免出现单点问题。例如多地单元化部署，即使某个IDC甚至地市出现故障，仍不会影响系统运转
    + 编码阶段：保证代码的健壮性，例如RPC调用时，设置合理的超时退出机制，防止被其他系统拖垮，同时也要对无法预料的返回错误进行默认的处理
    + 测试阶段：保证CI的覆盖度以及Sonar的容错率，对基础质量进行二次校验，并定期产出整体质量的趋势报告
    + 发布阶段：系统部署最容易暴露错误，因此要有前置的checklist模版、中置的上下游周知机制以及后置的回滚机制
    + 运行阶段：系统多数时间处于运行态，最重要的是运行时的实时监控，及时发现问题、准确报警并能提供详细数据，以便排查问题
    + 故障发生：首要目标是及时止损，防止影响面扩大，然后定位原因、解决问题，最后恢复服务
  - 手段
    + 预防：建立常态压测体系，定期对服务进行单点压测以及全链路压测，摸排水位
    + 管控：做好线上运行的降级、限流和熔断保护。需要注意的是，无论是限流、降级还是熔断，对业务都是有损的，所以在进行操作前，一定要和上下游业务确认好再进行。就拿限流来说，哪些业务可以限、什么情况下限、限流时间多长、什么情况下进行恢复，都要和业务方反复确认
    + 监控：建立性能基线，记录性能的变化趋势；建立报警体系，发现问题及时预警
    + 恢复：遇到故障能够及时止损，并提供快速的数据订正工具，不一定要好，但一定要有
* 稳定性是一个平时不重要，但出了问题就要命的事情，然而它的落地又是一个问题——平时业务发展良好，稳定性建设就会降级给业务让路。
* 解决：必须在组织上有所保障，比如让业务负责人背上稳定性绩效指标，同时在部门中建立稳定性建设小组，小组成员由每条线的核心力量兼任，绩效由稳定性负责人来打分，这样就可以把体系化的建设任务落实到具体的业务系统中了

## 全链路压测

压测优化过程就是一个不断优化不断改进的过程，事先通过测试不断发现问题，优化系统，避免问题，指定应急方案

* 分析需压测业务场景涉及系统
* 协调各个压测系统资源并搭建压测环境
* 压测数据隔离以及监控(响应时间、吞吐量、错误率等数据以图表形式实时显示)
* 压测结果统计(平均响应时间、平均吞吐量等数据以图表形式在测试结束后显示)
* 优化单个系统性能、关联流程以及整个业务流程

```sh
yum -y install httpd-tools
ab -v
ab --help

ab -n 1000 -c 100 http://127.0.0.1/
```

## 参考

* [小柒2012 / spring-boot-seckill](https://gitee.com/52itstyle/spring-boot-seckill):从0到1构建分布式秒杀系统 https://blog.52itstyle.com/archives/2853/
* [分布式秒杀系统构建中的多种限流实现](https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&mid=2650768375&idx=1&sn=0b1de5c41ac15db0fc53f279fcfa58b6&chksm=f3f93662c48ebf7481bd7ce8ca74a3f2ad66fd80e7f50e313d8ebd1152a094045d75113a832d)
* [秒杀系统的设计思考](https://mp.weixin.qq.com/s/CVFKTx016BqnOxdzxnW9dg)
