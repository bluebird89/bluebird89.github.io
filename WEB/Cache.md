# 缓存

* 关系型数据库的数据量比较小，以mysql为例，单表的量尽量控制在千万级别
* 关系型数据库在TPS上的瓶颈往往会比其他瓶颈更容易暴露出来,常用的MySQL数据库为例，常规情况下的TPS大概只有1500左右
* 有效的吸收不均匀的请求，抵挡流量波峰

## 性能指标

* 缓存空间的使用率
* topN 命令的执行次数
* 缓存的命中率：缓存命中率过低，失去缓存效果。一般对于热点数据而言，要保证命中率达到70%以上效果最佳
* 缓存的接口平均RT，最大RT，最小RT
* 缓存的QPS
* 网络出口流量
* 客户端连接数
* key个数统计

## 类型

* 浏览器缓存:当用户点击back按钮或是再次去访问某个页面的时候能够更快的响应
    - 返回码以下都可缓存 200 301 304 404 206
    - 对于缓存的处理是根据第一次请求资源时返回的响应头来确定的
        + 强缓存阶段:
            * `Cache-Control:max-age=2592000` HTTP/1.1定义的关于缓存的字段，它规定了缓存过期的一个相对时间
            * Expires是HTTP/1.0中的定义缓存的字段，它规定了缓存过期的一个绝对时间
            * 优先级:max-age > Expires
            * Firefox浏览器表现为一个灰色的200状态码。 Chrome浏览器状态码表现为 200  (from disk cache)或是200 OK (from memory cache)
                - Chrome会根据本地内存的使用率来决定缓存存放在哪，如果内存使用率很高，放在磁盘里面，内存的使用率很高会暂时放在内存里面
        + 协商缓存阶段
            * Last-Modified:文件最后一次修改的时间 `If-Moified-Since: Tue, 28 Nov 2017 05:14:02 GMT`
            * ETag是对文件的一个标记，具体生成方式HTTP并没有给出一个明确的方式，所以理论上只要不会重复生成方式无所谓，比如对资源内容使用抗碰撞散列函数，使用最近修改的时间戳的哈希值，甚至只是一个版本号。 `If-None-Match: W/"5a1cf09a-63c6"`
            * 发现缓存过期，于是会在本次请求的请求头里携带If-Moified-Since和If-None-Match这两个字段，服务器通过这两个字段来判断资源是否有修改，如果有修改则返回状态码200和新的内容，如果没有修改返回状态码304
        + 启发式缓存阶段:缓存过期时间的字段一个都没有,根据响应头中2个时间字段 Date 和 Last-Modified 之间的时间差值，取其值的10%作为缓存时间周期。
* 代理服务器缓存:存在于网络中，请求路由必须经过它们才会生效，所以实际上你可以去手动设置浏览器的代理，或是通过一个中间服务器来进行转发.一个共享缓存，不只为一个用户服务，经常为大量用户使用，因此在减少相应时间和带宽使用方面很有效：因为同一个缓存可能会被重用多次
* 网关缓存:也称为代理缓存或反向代理缓存，网关也是一个中间服务器，网关缓存一般是网站管理员自己部署，从让网站拥有更好的性能
* 客户端缓存：由于随机性比较强，请求分散，加上合理的缓存过期时间，给服务器的压力也很小
* 本地缓存：会减少网络层的交互，无论是本地内存还是磁盘，速度比较快。但对分布式系统来讲有一个缺点，当数据库更新时，没有一个简单有效的方法去更新本地缓存。
    - 适用场景：
        + 对缓存内容时效性要求不高，能接受一定的延迟，可以设置较短过期时间，被动失效更新保持数据的新鲜度。
        + 缓存的内容不会改变。比如订单号与uid的映射关系，一旦创建就不会发生改变。
    - 注意
        + 内存Cache数据条目上限控制，避免内存占用过多导致应用瘫痪。
        + 内存中的数据移出策略
        + 虽然实现简单，但潜在的坑比较多，最好选择一些成熟的开源框架
        + 容易让应用服务器带上“状态”，而且容易受内存大小的限制
* 分布式缓存：借助分布式的概念，集群化部署，独立运维，容量无上限，虽然会有网络传输的损耗，但这1~2ms的延迟相比其更多优势完成可以忽略
    - Memcached、Redis。对比关系型数据库和缓存存储，其在读和写性能上的差距可谓天壤之别，redis单节点已经可以做到8W+ QPS。设计方案时尽量把读写压力从数据库转移到缓存上，有效保护脆弱的关系型数据库。
    - 不足：需要跨服务器走网络传输,网络传输带来的性能损耗

## 更新策略

* 过期时间：热点数据都有过期时间，如果没有过期时间就造成了主存和缓存的数据不一致，因此过期时间一般都不会太长
    - 太短：造成频繁的从数据库中往缓存里写数据
    - 太长：内存浪费
* 被动失效
    - 通常会设置一个过期时间或者当数据库状态改变时，通过delete操作，使数据失效掉；当下次再去读取时，如果发现数据过期了或者不存在了，那么就重新去数据库读取，然后更新到缓存中
    - 风险：从缓存失效到数据再次被预热到cache这段时间，所有的读请求会直接打到DB上，对于一个高访问量的系统，很容易被击垮
* 主动更新
    - 数据库存储发生变化时，会直接同步更新到Cache，主要是为了解决cache空窗期引发的问题
    - 如果读多写多，同样会带来另一个问题，就是并发更新。多台应用服务器同时访问一份数据是很正常的，这样就会存在一台服务器读取并修改了缓存数据，但是还没来得及写入的情况下，另一台服务器也读取并修改旧的数据，这时候，后写入的将会覆盖前面的，从而导致数据丢失。解决的方式主要有三种
        + 锁控制：一般在客户端实现(在服务端加锁是另外一种情况)，其基本原理就是使用读写锁，即任何线程要调用写方法时，先要获取一个排他锁，阻塞住所有的其他访问，等自己完全修改完后才能释放。如果遇到其他线程也在修改或读取数据，那么则需要等待。 锁控制虽然是一种方案，但是很少有真的这样去做的，其缺点显而易见，其并发性只存在于读操作之间，只要有写操作存在，就只能串行
        + 单版本机制（乐观锁）：为每份数据保存一个版本号，当缓存数据写入时，需要回传这个版本号，然后服务端将传入的版本号和数据当前的版本号进行比对，如果等于当前版本号，则成功写入，否则失败。这样解决方式比较简单; 但是增加了高并发下客户端的写失败概率
        + 多版本机制：即存储系统为每个数据保存多份，每份都有自己的版本号，互不冲突，然后通过一定的策略来定期合并，再或者就是交由客户端自己去选择读取哪个版本的数据。

## 穿透/雪崩

* 缓存穿透 Cache Penetration
    - 一个req需要请求的key在缓存中没有，业务线程就会访问磁盘数据库系统，然而磁盘数据库也没有这个key，无奈业务线程只能返回null，白白处理一圈
    - 由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义
    - 小概率事件在高并发系统几乎要成为必然
    - 将不存在的key预先设定一个值。比如，”key” , “&&”， "null"，返回结果决定是否继续等待继续访问，还是放弃掉这次操作。如果继续等待访问，过一个时间轮询点后，再次请求这个key，如果取到的值不再是&&，则可以认为这时候key有值了
        * 缓存系统和数据库中存储大量无用key本身是无意义的数据
    - 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
        + 时间复杂度 O (1)，二进制位存储，省空间，20 亿的数组约占 238M
        * 垃圾邮件识别、搜索蜘蛛爬虫url去重等，主要借助K个哈希函数和一个超大的bit数组来降低哈希冲突本身带来的误判，从而提高识别准确性
        * 由于 hash 碰撞，只能支持未命中的判断，如果布隆过滤器认为值不存在，那么值一定是不存在的，无需查询缓存也无需查询数据库，存在极小概率的误判断。不支持元素删除
* 缓存雪崩 Cache Avalanche：缓存系统故障或者设置缓存时采用了相同的过期时间在某一时刻同时失效，大量的请求无法从缓存完成数据请求，全量汹涌冲向磁盘数据库系统，导致数据库被打死，整个系统彻底崩溃
    - 一般不会瞬间造成系统不可用，缓慢过程，报警，监控命中率
    - 风控层面做干预，识别非法来源
    - 用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上
    - 缓存失效时间分散开：在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，设置100ms的基础值，在此基础上正负浮动10ms，从而降低相同时刻出现CacheMiss的key的数量
    - 提前将数据预热到 cache
    - 灰度，逐步开放给新用户，做好流量阶梯缓冲
    - 计算好缓存过期时间
    - 缓存系统不够高可用：提高缓存系统的稳定性和可用性十分必要，对于使用Redis作为缓存的系统而言需要使用Sentinel哨兵机制、集群化、持久化等来提高缓存系统的HA
    - 服务本身需要支持降级：使用奈飞的Hystrix来实现服务的熔断、降级、限流来降低出现雪崩时的故障程度。做资源的隔离保护主线程池
* 缓存击穿 Hotspot Invalid：某时刻一批热点数据同时在缓存系统中过期失效，那么这部分数据就都将请求磁盘数据库系统
    - 和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key
    - 多线程加锁，其中第一个线程发现CacheMiss之后进行加锁，再从数据库获取内容之后写到缓存中，其他线程获取锁失败则阻塞数ms之后再进行缓存读取，这样可以降低访问数据数据库的线程数，需要注意在单机和集群需要使用不同的锁，集群环境使用分布式锁来实现，但是由于锁的存在也会影响并发效率
    - 使用互斥锁(mutex key)：在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
    - "提前"使用互斥锁(mutex key)：在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。 当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。
    - 在业务层对使用的热点数据查看是否即将过期，如果即将过期则去数据库获取最新数据进行更新并延长该热点key在缓存系统中的时间，从而避免后面的过期CacheMiss，相当于把事情提前解决
    - 缓存副本设计有一个细节需要注意，就是不同的缓存副本不要设置统一的过期时间，设定一个过期时间范围，不同的缓存副本的过期时间是指定范围内的随机值

* 并发更新：一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况
    - 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁
    - 其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询

## 一致性：当修改了数据库后，有没有及时修改缓存成功

* 原因
    - 缓存服务器挂了或者网络问题引起没有及时更新
    - 通过重试机制：启动一个异步任务定时去检测缓存服务器是否连接成功，一旦连接成功则从数据库中按顺序取出修改数据，依次进行缓存最新值的修改
* 缓存与数据库 必须保持一致性:读请求和写请求串行化，串到一个内存队列里去
    - 可以保证一定不会出现不一致的情况，但是也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上请求
* Cache Aside 旁路缓存策略
    - 读：先从缓存Cache中读取数据，如果缓存中没有，则从数据库中读取数据，取出数据后放入缓存，同时返回响应
    - 写：先把数据存到数据库中，成功后，再让缓存失效
        * 在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值.需要关联与计算
        * 更新缓存代价有时候是很高，是否一定要将其对应的缓存更新一份（缓存到底会不会被频繁 冷数据）
        * 删除缓存而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管会不会用到，而是让它到需要被使用的时候再重新计算
    - 问题
        + 变更数据库和变更缓存是两个独立操作，会因为写入顺序的不同造成数据的不一致
        * 线程A更新缓存过程中（读取DB），线程B更新了数据库并更新缓存，A用旧数据更新缓存：数据库与缓存不一致，引起脏数据
        * 删除缓存失败导致数据库中是新数据，缓存中是旧数据：先删除缓存，再修改数据库
        * 删除了缓存，还没来得及修改数据库，一个请求过来，去读缓存，发现缓存空了后去查询数据库，查到了修改前的旧数据，放到了缓存中
* Read/Write Through
    - 将 缓存服务 作为主要的存储，应用所有读写请求都是直接与缓存服务打交道
    - 缓存服务同步数据到数据库
    - 本地缓存，大量使用这种策略，如：Guava  Cache 中的 Loading Cache，预留扩展接口，只需要实现 CacheLoader 接口，如果缓冲没有该数据 kv 对，则自动调用接口方法获取
    - 缺点
        + 强依赖缓存了，对缓存服务的稳定性有较大要求
        + 增加新缓存节点时还会有初始状态空数据问题
        + 写数据库是同步的，对于性能有比较大的开销
* Write Behind
    - Read/Write Through 一个变种。区别缓存写数据库的是异步
    - 缓存服务异步将数据更新到数据库（通过异步任务）
    - 操作系统层面的 page cache 就是采用这种思想。就是操作系统在内存中给磁盘上的文件建立的缓存。在调用系统的 API 读写文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的都是 PageCache，也就是文件在内存中缓存的副本
    - 缺点：速度很快，效率会非常高，但是数据的一致性比较差，还可能会有数据的丢失情况，实现逻辑也较为复杂

## 序列化

分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一

* 序列化速度
* 对象压缩比例
* 支持的序列化数据类型范围
* 反序列化的速度
* 框架接入易用性
* 框架：
    - Java源生序列化
    - Hessian
    - Protobuf
    - Kryo

## 命中率较低，影响性能

* 过期时间太短， 这种场景可以根据实际情况适当增大过期时间
* 存在不合理缓存删除逻辑， 导致有效的缓存频繁被删除
* 不合理的key规则设计， 每次缓存访问的key都在变化， 导致无法命中缓存和频繁的新缓存创建
* key确实不存在，但是应用还是在频繁的访问， 这种应该从业务逻辑上杜绝

## 注意

* 评估当前业务使用的空间大小。避免空间不足，导致热数据被置换出去，影响缓存命中率
* 不要把缓存当DB使用，因为它会丢失
* 最好设置过期时间，可以自己回收
* key定义遵循一定规则，相同业务采用同一前缀
* 缓存对象粒度。高内聚低耦合，考虑尽可能复用，不要一个小字段修改导整个大对象全部失效
* 另外缓存对象大小要控制，不要过大，占用过多带宽。之前遇到过一个业务团队，单key下挂了5M的大对象，每次用时，从缓存中取出，反序列化，然后取其中一小部分。后来随着业务并发量上升，把网卡打爆，进而影响其它正常业务访问。
* 根据业务需求，选择合适的缓存框架，比如memcache只支持kv对存储，redis则支持较丰富的数据结构
* 是否要引入多级缓存，本地内存--》非持久化缓存（如memcache）---》持久化缓存---》DB，要注意数据一致性问题
    - 客户端浏览器缓存：减少对网站的访问
    - Web服务器缓存：减少应用服务器请求 模版缓存：动静分离
    - 数据库缓存：减少数据库的查询、减少文件系统I/O
    - 操作系统缓存：减少磁盘机械操作
* 提前考虑扩容问题

## 技巧

* 创建
    - 主动创建缓存:系统定时创建
    - 请求的时候设置标志位。第一个请求到达，标识这个 url 正在创建缓存，其他请求进入等待队列
* 失效
    - 主动失效：用 API 调用方式实现。比如删除 key,或者调用 CDN 接口进行删除操作
    - 自动失效：设置失效时间

## 模板语法

* Mustache
* jade
* hbs

## 框架

* Guave
