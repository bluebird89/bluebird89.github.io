# 缓存

有效的吸收不均匀的请求，抵挡流量波峰

* 分级缓存
    - 客户端浏览器缓存：减少对网站的访问
    - Web服务器缓存：减少应用服务器请求 模版缓存：动静分离
    - 数据库缓存：减少数据库的查询、减少文件系统I/O
    - 操作系统缓存：减少磁盘机械操作
* 时间过期：热点数据都有过期时间，如果没有过期时间就造成了主存和缓存的数据不一致，因此过期时间一般都不会太长
    - 太短：造成频繁的从数据库中往缓存里写数据
    - 太长：内存浪费
* 命中率：缓存命中率过低，失去缓存效果。一般对于热点数据而言，要保证命中率达到70%以上效果最佳
* 并发更新：一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况
    - 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁
    - 其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询
* 穿透/雪崩
    - 缓存穿透 Cache Penetration：一个req需要请求的key在缓存中没有，业务线程就会访问磁盘数据库系统，然而磁盘数据库也没有这个key，无奈业务线程只能返回null，白白处理一圈
        + 由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义
        + 小概率事件在高并发系统几乎要成为必然
        + 将不存在的key预先设定一个值。比如，”key” , “&&”， "null"，返回结果决定是否继续等待继续访问，还是放弃掉这次操作。如果继续等待访问，过一个时间轮询点后，再次请求这个key，如果取到的值不再是&&，则可以认为这时候key有值了
            * 缓存系统和数据库中存储大量无用key本身是无意义的数据
        + 选用布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
            * 布隆过滤器：垃圾邮件识别、搜索蜘蛛爬虫url去重等，主要借助K个哈希函数和一个超大的bit数组来降低哈希冲突本身带来的误判，从而提高识别准确性
            * 布隆过滤器存在一定的误判
    - 缓存雪崩 Cache Avalanche：缓存系统故障或者设置缓存时采用了相同的过期时间在某一时刻同时失效，大量的请求无法从缓存完成数据请求，全量汹涌冲向磁盘数据库系统，导致数据库被打死，整个系统彻底崩溃
        + 用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上
        + 在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，设置100ms的基础值，在此基础上正负浮动10ms，从而降低相同时刻出现CacheMiss的key的数量
        + 缓存系统不够高可用：提高缓存系统的稳定性和可用性十分必要，对于使用Redis作为缓存的系统而言需要使用Sentinel哨兵机制、集群化、持久化等来提高缓存系统的HA
        + 服务本身需要支持降级：使用奈飞的Hystrix来实现服务的熔断、降级、限流来降低出现雪崩时的故障程度。做资源的隔离保护主线程池
    * 缓存击穿 Hotspot Invalid：设想某时刻一批热点数据同时在缓存系统中过期失效，那么这部分数据就都将请求磁盘数据库系统
        - 和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key
        - 多线程加锁，其中第一个线程发现CacheMiss之后进行加锁，再从数据库获取内容之后写到缓存中，其他线程获取锁失败则阻塞数ms之后再进行缓存读取，这样可以降低访问数据数据库的线程数，需要注意在单机和集群需要使用不同的锁，集群环境使用分布式锁来实现，但是由于锁的存在也会影响并发效率。
        - 使用互斥锁(mutex key)：在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
        - "提前"使用互斥锁(mutex key)：在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。 当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。
        - 在业务层对使用的热点数据查看是否即将过期，如果即将过期则去数据库获取最新数据进行更新并延长该热点key在缓存系统中的时间，从而避免后面的过期CacheMiss，相当于把事情提前解决
* 一致性：当修改了数据库后，有没有及时修改缓存成功
    - 原因
        + 缓存服务器挂了
        + 因为网络问题引起的没有及时更新，可以通过重试机制来解决
    - 解决：可以将这条数据放到数据库中，同时启动一个异步任务定时去检测缓存服务器是否连接成功，一旦连接成功则从数据库中按顺序取出修改数据，依次进行缓存最新值的修改。
    - 缓存 + 数据库 必须保持一致性:读请求和写请求串行化，串到一个内存队列里去
        + 可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上请求
    - Cache Aside
        + 读：先从缓存Cache中读取数据，如果缓存中没有，则从数据库中读取数据，取出数据后放入缓存，同时返回响应
        + 写：先更新数据库，然后再删除缓存
            * 在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值.需要关联与计算
            * 更新缓存的代价有时候是很高的，是否一定要将其对应的缓存更新一份（缓存到底会不会被频繁 冷数据）
            * 删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算
        + 问题
            * A先读 B后更新数据库，B先更新缓存A后更新缓存：不管B是失效缓存还是更新缓存造成数据库与缓存不一致，引起脏数据
            * 删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据：先删除缓存，再修改数据库
            * 删除了缓存，还没来得及修改数据库，一个请求过来，去读缓存，发现缓存空了后去查询数据库，查到了修改前的旧数据，放到了缓存中
                - 每秒并发读很高时，会出现上面情况
    - Read/Write Through：将 缓存服务 作为主要的存储，应用的所有读写请求都是直接与缓存服务打交道，而不管最后端的数据库了，数据库的数据由缓存服务来维护和更新
        + 应用要读数据和更新数据都直接访问缓存服务
        + 缓存服务同步的将数据更新到数据库
        + 缺点：出现脏数据的概率就比较低，但是就强依赖缓存了，对缓存服务的稳定性有较大要求，另外，增加新缓存节点时还会有初始状态空数据问题。
    - Write Behind：是 Read/Write Through 模式 的一个变种。区别就是 Read/Write Through 模式的缓存写数据库的时候是同步的，而 Write Behind 模式 的缓存操作数据库是异步的
        - 应用要读数据和更新数据都直接访问缓存服务
        - 缓存服务异步的将数据更新到数据库（通过异步任务）
        - 缺点：速度很快，效率会非常高，但是数据的一致性比较差，还可能会有数据的丢失情况，实现逻辑也较为复杂。

## 技巧

* 创建
    - 主动创建缓存:系统定时创建
    - 请求的时候设置标志位。第一个请求到达，标识这个 url 正在创建缓存，其他请求进入等待队列
* 失效
    - 主动失效：用 API 调用方式实现。比如删除 key,或者调用 CDN 接口进行删除操作
    - 自动失效：设置失效时间

## 模板语法

* Mustache
* jade
* hbs
