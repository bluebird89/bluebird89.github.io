# 并发vs并行（concurrent vs parallel）

高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。

高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。

* 响应时间：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。
* 吞吐量：单位时间内处理的请求数量。
* QPS：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
* 并发用户数：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。


## 概念

用多线程只有一个目的，那就是更好的利用cpu的资源，因为所有的多线程代码都可以用单线程来实现。说这个话其实只有一半对，因为反应“多角色”的程序代码，最起码每个角色要给他一个线程吧，否则连实际场景都无法模拟，当然也没法说能用单线程来实现：比如最常见的“生产者，消费者模型”。

比如学习并发编程时，首先学习JDK源码，然后学进去之后，开始看JVM源码，最后看CPU架构，在技术点逐渐深度研究的过程中，广度也得到了完善。

* 线程(thead)：指的是这个程序（一个进程）运行时产生了不止一个线程
* 并行与并发：
    - 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。
    - 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力。
* 线程安全：经常用来描绘一段代码。指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。这个时候使用多线程，我们只需要关注系统的内存，cpu是不是够用即可。反过来，线程不安全就意味着线程的调度顺序会影响最终结果
* 同步：Java中的同步指的是通过人为的控制和调度，保证共享资源的多线程访问成为线程安全，来保证结果的准确。如上面的代码简单加入@synchronized关键字。在保证结果准确的同时，提高性能，才是优秀的程序。线程安全的优先级高于性能。

![](../_static/thead-status.png)
* 线程在Running的过程中可能会遇到阻塞(Blocked)情况:对Running状态的线程加同步锁(Synchronized)使其进入(lock blocked pool ),同步锁被释放进入可运行状态(Runnable)。从jdk源码注释来看，blocked指的是对monitor的等待（可以参考下文的图）即该线程位于等待区。
* 线程在Running的过程中可能会遇到等待（Waiting）情况:线程可以主动调用object.wait或者sleep，或者join（join内部调用的是sleep，所以可看成sleep的一种）进入。从jdk源码注释来看，waiting是等待另一个线程完成某一个操作，如join等待另一个完成执行，object.wait()等待object.notify()方法执行。

### 互联网分层架构

![Alt text](../_static/layer.png "Optional title")
* 客户端层：典型调用方是浏览器browser或者手机应用APP
* 反向代理层：系统入口，反向代理
* 站点应用层：实现核心应用逻辑，返回html或者json
* 服务层：如果实现了服务化，就有这一层
* 数据-缓存层：缓存加速访问存储
* 数据-数据库层：数据库固化数据存储

## 方法

方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。

垂直扩展：提升单机处理能力。垂直扩展的方式又有两种：
* 增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；如果预算不是问题，强烈建议使用“增强单机硬件性能”的方式提升系统并发能力，因为这个阶段，公司的战略往往是发展业务抢时间，而“增强单机硬件性能”往往是最快的方法。
* 提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；
* 单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是水平扩展。
* 水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践。

### 实践

* 反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。
* 站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf，可以设置多个web后端。当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。
* 服务层的水平扩展，是通过“服务连接池”实现的。站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。
* 在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。
    - 按照范围水平拆分：每一个数据服务，存储一定范围的数据，user0库，存储uid范围1-1kw，user1库，存储uid范围1kw-2kw
        + 规则简单，service只需判断一下uid范围就能路由到对应的存储服务；
        + 数据均衡性较好；
        + 比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务；
        + 请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大；
    - 按照哈希水平拆分:每一个数据库，存储某个key值hash后的部分数据，user0库，存储偶数uid数据,user1库，存储奇数uid数据
        + 规则简单，service只需对uid进行hash能路由到对应的存储服务；
        + 数据均衡性较好；
        + 请求均匀性较好；
        + 不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移；
    - 水平拆分来扩充系统性能vs主从同步读写分离
        + 水平拆分扩展数据库性能：
            * 每个服务器上存储的数据量是总量的1/n，所以单机的性能也会有提升；
            * n个服务器上的数据没有交集，那个服务器上数据的并集是数据的全集；
            * 数据水平拆分到了n个服务器上，理论上读性能扩充了n倍，写性能也扩充了n倍（其实远不止n倍，因为单机的数据量变为了原来的1/n）；
        + 通过主从同步读写分离扩展数据库性能：
            * 每个服务器上存储的数据量是和总量相同；
            * n个服务器上的数据都一样，都是全集；
            * 理论上读性能扩充了n倍，写仍然是单点，写性能不变；

## 线程数设计

* 服务器CPU核数有限，能够同时并发的线程数有限，单核CPU设置10000个工作线程没有意义(工作线程数是不是设置的越大越好)
* 线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低
* 调用sleep()函数的时候，线程不占用一直占用CPU，等待时会把CPU让出来，给其他需要CPU资源的线程使用。
    - 阻塞accept()，等待客户端连接都不占用CPU资源
    - 阻塞recv()，等待下游回包都不占用CPU资源
* 即使是单核，使用多线程也是有意义的，大多数情况也能提高并发
    - 多线程编码可以让代码更加清晰，还能提高吞吐量。例如：IO线程收发包，Worker线程进行任务处理，Timeout线程进行超时检测
    - 如果有一个任务一直占用CPU资源在进行计算，此时增加线程并不能增加并发，例如以下代码会一直占用CPU，并使得CPU占用率达到100%：`while(1){ i++; }`
    - 通常来说，Worker线程一般不会一直占用CPU进行计算，此时即使CPU是单核，增加Worker线程也能够提高并发，因为这个线程在休息的时候，其他的线程可以继续工作

### 现场模型

IO线程与工作现场通过任务队列解耦
![Alt text](../_static/thead_model.png "Optional title")
大部分Web-Server与服务框架都是使用这样的一种“IO线程与Worker线程通过队列解耦”类线程模型.这个线程模型的特点是，工作线程内部是同步阻塞执行任务的,因此可以通过增加Worker线程数来增加并发能力.:

* 有少数几个IO线程监听上游发过来的请求，并进行收发包（生产者）
* 有一个或者多个任务队列，作为IO线程与Worker线程异步解耦的数据传输通道（临界资源）
* 有多个工作线程执行正真的任务（消费者）

纯异步线程模型
没有阻塞，这种线程模型只需要设置很少的线程数就能够做到很高的吞吐量，该模型的缺点是：
* 如果使用单线程模式，难以利用多CPU多核的优势
* 程序员更习惯写同步代码，callback的方式对代码的可读性有冲击，对程序员的要求也更高
* 框架更复杂，往往需要server端收发组件，server端队列，client端收发组件，client端队列，上下文管理组件，有限状态机组件，超时管理组件的支持

### 工作线程

* 从工作队列里拿出任务，进行一些本地初始化计算，例如http协议分析、参数解析、参数校验等
* 访问cache拿一些数据
* 拿到cache里的数据后，再进行一些本地计算，这些计算和业务逻辑相关
* 通过RPC调用下游service再拿一些数据，或者让下游service去处理一些相关的任务
* RPC调用结束后，再进行一些本地计算，怎么计算和业务逻辑相关
* 访问DB进行一些数据操作
* 操作完数据库之后做一些收尾工作，同样这些收尾工作也是本地计算，和业务逻辑相关

详细流程

* 请求在网络上传输到下游的cache、service、DB
* 下游cache、service、DB进行任务处理
* cache、service、DB将报文在网络上传回工作线程

### 线程数

Worker线程在执行的过程中，有一部计算时间需要占用CPU，另一部分等待时间不需要占用CPU，通过量化分析，例如打日志进行统计，可以统计出整个Worker线程执行过程中这两部分时间的比例，例如：
执行计算，占用CPU的时间（粉色时间轴）是100ms
等待时间，不占用CPU的时间（橙色时间轴）也是100ms

得到的结果是，这个线程计算和等待的时间是1：1，即有50%的时间在计算（占用CPU），50%的时间在等待（不占用CPU）：
假设此时是单核，则设置为2个工作线程就可以把CPU充分利用起来，让CPU跑到100%
假设此时是N核，则设置为2N个工作现场就可以把CPU充分利用起来，让CPU跑到N*100%
 
结论：
N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。
 
经验：
一般来说，非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务），瓶颈都在后端数据库访问或者RPC调用，本地CPU计算的时间很少，所以设置几十或者几百个工作线程是能够提升吞吐量的。


## 参考

* [究竟啥才是互联网架构“高并发”](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959830&idx=1&sn=ce1c5a58caed227d7dfdbc16d6e1cea4&chksm=bd2d07ca8a5a8edc45cc45c4787cc72cf4c8b96fb43d2840c7ccd44978036a7d39a03dd578b5)
* [工作线程数究竟要设置为多少](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651960260&idx=1&sn=051fd566d43d7fd35724bdf55484ee5f&chksm=bd2d06188a5a8f0e64467381c7b3df5bdcb7f81ba055d5d21ec2f8b888492be15527d23070b0)
并发：<https://www.zhihu.com/question/19683490>

分布式系统：<https://www.zhihu.com/question/37051661>

http://ifeve.com/talk-concurrency/

http://www.jianshu.com/p/40d4c7aebd66