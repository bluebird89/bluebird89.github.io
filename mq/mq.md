# 消息队列 message queues

* 一种应用间使用队列来通信的组件，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。
* 解决系统间异步通信的中间件,用于解决系统解耦和请求的削峰平谷的问题.消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的
* 功能
  - 排序保证：先投递先到达的保证是一个消息队列
  - 异步处理：增强业务系统的异步处理能力，减少甚至几乎不可能出现并发现象.减少请求的等待，还能让服务异步并发处理，提升系统总体性能
  - 系统解耦 ：防止引入过多的 API 给系统的稳定性带来风险；调用方使用不当会给被调用方系统造成压力，被调用方处理不当会降低调用方系统的响应能力。如果一个系统挂了，则不会影响另外个系统的继续运行。
    + 下游系统处理异常，上游系统如何处理
    + 系统宕机的情况下会不会导致数据丢失
    + 当有业务数据异常时，如何去定位是上游系统发送出了问题还是下游系统的问题
    + 如果需要同时将信息发送给多个下游系统，其中一个处理有问题会不会导致其它系统受影响
    + 注意
      * 考虑下游系统处理异常，上游系统如何处理？
      * 系统宕机的情况下会不会导致数据丢失？
      * 当有业务数据异常时，如何去定位是上游系统发送出了问题还是下游系统的问题？
      * 如果需要同时将信息发送给多个下游系统，其中一个处理有问题会不会导致其它系统受影响？
  - 流量削峰和流控：消息生产者不会堵塞，突发消息缓存在队列中，消费者按照实际能力读取消息。业务系统往往要求响应能力特别强，能够起到削峰填谷的作用
  - 广播
* 优势
  - 复用：一次发布多方订阅
  - 健壮性 消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行
  - 缓冲:在服务层和缓慢的落地层作为缓冲层存在，作用与削峰类似，但主要用于服务内数据流转。比如批量短信发送
  - 冗余:消息数据能够采用一对多的方式，供多个毫无关联的业务使用
* 业务系统往往有对消息的高可靠要求，以及有对复杂功能如 Ack 的要求

## 协议

* JMS（Java Message Service）： JMS 本质上是 JAVA API。在 JMS 中定义了 Producer，Consumer，Provider 三种角色
  - Producer 作为消息的发送方，Consumer 作为消息的接收方，Provider 作为服务的提供者，Producer 和 Consumer 统称为 Client。
  - JMS 定义了点对点和发布订阅两种消息模型
    + 发布订阅模型中，通过 topic 对消息进行路由，生产者可以将消息发到指定的 topic，消费者订阅这个 topic 即可收到生产者发送的消息。一个生产者可以向一个或多个 topic 中发送消息，一个消费者也可以消费一个或多个 topic 中的消息，一个 topic 也可以有多个生产者或消费者，生产者和消费者只需要关联 topic，而不用关心这消息由谁发送或者消费。
      - Provider 为每一个 topic 维护一个或多个 queue 来保存消息，消息在 queue 中是有序的，遵循先进先出的原则，不同 queue 间的消息是无序的。
    - 点对点模式中没有 topic 的概念，生产者直接将消息发送到指定 queue，消费者也指定 queue 进行消费，消息只能被一个消费者消费，不可以被多个消费者消费。Kafka 和 RocketMQ 都实现了或部分实现了 JMS 协议。
* AMQP（Advanced Message Queuing Protocol）： 与 JMS 不同，AMQP 是一个应用层的网络传输协议，对报文格式进行定义，与开发语言无关。在 AMQP 中同样有生产者，消费者两种角色，消息也是保存在 queue 中的。 但不同于 JMS 用 topic 对消息进行路由，AMQP 的路由方式由 exchange 和 binding 决定。
  * client 可以创建 queue，并在创建 queue 的同时通知 exchange 这个 queue 接受符合什么条件的消息，这个条件即为 Bingding key。
  * 生产者发送消息到 exchange 的时候会指定一个 router key，exchange 收到消息后会与自己所维护的 Bingding key 做比较，发送到符合条件的 queue 中。消费者在消费时指定 queue 进行消费。
  * RabbitMQ 实现了 AMQP 协议。
* MQTT（Message Queuing Telemetry Transport）：MQTT 协议是一种基于发布订阅的轻量级协议，支持 TCP 和 UDP 两种连接方式，主要应用于即时通讯，小型设备，移动应用等领域。 MQTT 中有发布者（Publish），订阅者（Subscribe）和代理服务器（Broker）三种角色。
  - Broker 是服务的提供者，发布者和前两种协议中的生产者相同，将消息（Message）发送到 Broker，Subscribe 从 Broker 中获取消息并做业务处理。MQTT 的 Message 中固定消息头（Fixed header）仅有 2 字节，开销极小，除此之外分为可变头（Variable header）和消息体（payload）两部分。固定头中包含消息类型，消息级别，变长头的大小以及消息体的总长度等信息。 变长头则根据消息类别，含有不同的标识信息。
  - MQTT 允许客户端动态的创建主题，发布者与服务端建立会话（session）后，可以通过 Publish 方法发送数据到服务端的对应主题
  - 订阅者通过 Subscribe 订阅主题后，服务端就会将主题中的消息推送给对应的订阅者。

## 设计

* 先build一个整体的数据流，利用RPC将数据流串起来。然后考虑RPC的高可用性，尽量做到无状态，方便水平扩展。
  - 服务端提供两个RPC服务，一个用来接收消息，一个用来确认消息收到。并且做到不管哪个server收到消息和确认消息，结果一致即可
  - broker必须保证感知的到所有consumer的存在
  - producer尽量选择就近的机房就好了
* 考虑如何承载消息堆积，然后在合适的时机投递消息
  - 处理堆积的最佳方式，就是存储，存储的选型需要综合考虑性能/可靠性和开发维护成本等诸多因素
  - 存储子系统选择
    + 速度：文件系统>分布式KV（持久化）>分布式文件系统>数据库，可靠性却截然相反
* 实现广播功能，必须要维护消费关系，可以利用zk/config server等保存消费关系
  - 维护广播关系所要做的事情基本是一致的:
    + 发送关系的维护
    + 发送关系变更时的通知

## 术语

* 发送消息方为生产者 Producer
* 接受消费消息方为消费者Consumer
* 消息队列服务端为Broker
  - 消息的转储，在更合适的时间点投递，或者通过一系列手段辅助消息最终能送达消费机。

  - 规范一种范式和通用的模式，以满足解耦、最终一致性、错峰等需求。
* 最简单的消息队列可以做成一个消息转发器，把一次RPC做成两次RPC。发送者把消息投递到服务端（以下简称broker），服务端再将消息转发一手到接收端
* 消息从Producer发往Broker，Broker将消息存储至本地，然后Consumer从Broker拉取消息，或者Broker推送消息至Consumer，最后消费
* 为了提高并发度，往往发布/订阅模型还会引入队列或者分区的概念。即消息是发往一个主题下的某个队列或者某个分区中。RocketMQ中叫队列，Kafka叫分区
* 与之对应的消费者一般都有组的概念 Consumer Group,即消费者都是属于某个消费组的。一条消息会发往多个订阅了这个主题的消费组
  - 假设现在有两个消费组分别是Group 1 和 Group 2，它们都订阅了Topic-a。此时有一条消息发往Topic-a，那么这两个消费组都能接收到这条消息。
  - 这条消息实际是写入Topic某个队列中，消费组中的某个消费者对应消费一个队列的消息。
* 在物理上除了副本拷贝之外，一条消息在Broker中只会有一份，每个消费组会有自己的offset即消费点位来标识消费到的位置。在消费点位之前的消息表明已经消费过了。当然这个offset是队列级别的。每个消费组都会维护订阅的Topic下的每个队列的offset

## 异步消息

* 可以作为解耦消息的生产和处理的一种解决方案。两种主要的消息模式——消息队列和发布/订阅模式
* 队列模型
  - 多个生产者可以向同一个消息队列发送消息
  - 一个队列也可以有多个消费者,消费者之间是竞争关系，即每条消息只能被一个消费者消费
  - 消息在队列上会被锁住或者被移除并且其他消费者无法处理该消息。也就是说**一个具体的消息只能由一个消费者消费**
  - 如果消费者处理一个消息失败了，消息系统一般会把这个消息放回队列，这样其他消费者可以继续处理
  - 能够对生产者和消费者进行独立的伸缩（scale），以及提供对错误处理的容错能力
* 发布/订阅模型(群聊)
  - **单个消息可以被多个订阅者并发的获取和处理**
  - 在许多队列系统中常常用主题（topics）指代发布/订阅模式
  - 将消息发往一个Topic即主题中，所有订阅了这个 Topic 的订阅者都能消费这条消息
  - 类型：
    + 临时（ephemeral）订阅:只有在消费者启动并且运行的时候才存在。一旦消费者退出，相应的订阅以及尚未处理的消息就会丢失。
    + 持久（durable）订阅:会一直存在，除非主动去删除。消费者退出后，消息系统会继续维护该订阅，并且后续消息可以被继续处理
* 通过多队列全量存储相同的消息，即数据的冗余可以实现一条消息被多个消费者消费。RabbitMQ 就是采用队列模型，通过 Exchange 模块来将消息发送至多个队列，解决一条消息需要被多个消费者消费问题。
* RabbitMQ 采用队列模型，RocketMQ和Kafka 采用发布/订阅模型。
  - RabbitMQ中，主题就是发布/订阅模式的一种具体实现（更准确点说是交换器（exchange）的一种）
* 任何的RPC都是存在客户端异步与服务端异步的，而且是可以任意组合的
  - RPC只有客户端能做异步，服务端不能
  - 异步只能通过线程池
* 服务端异步：解放了线程和I/O

## 推/拉模式

* 消息到消费端方式
* Push 推模式：即服务端收到消息后，主动将消息推送给消费者，由消费者进行处理，具有更高的实时性
  - 服务端收到Message后，首先会记录消息的信息，并且从自己的元信息数据库中查询对应的消息的Consumer有谁
  - 服务器和Consumer在链接的时候建立了长链接，因此可以直接发送消息到Consumer
  - 慢消费：很难适应消费速率不同的消费者，因为消费发送速率是由 Broker 决定的，目标是尽可能以最快的的速度传递消息
  - 由于服务端不能准确评估消费端的消费性能，有可能造成消息推送过多使客户端来不及处理收到的消息,典型的表现就是拒绝服务以及网络拥塞
  - 缺点
    + 由于服务器需要记录对应的Consumer的元信息，包括消息该发给谁，offset是多少，同时需要向Consumer推送消息，必然会带来系列的问题
    + 假如一刻网络不好，Consumer没有收到，消息没有发成功怎么办？假设消息发出去了，怎么知道它有没有收到？
    + 因此服务器和Consumer之间需要首先多层确认口令，以达到至少消费一次，仅且消费一次等特性
* pull：拉模式  服务端收到消息后将消息保存在服务端，被动的等待客户端来拉取消息
  - 为了提升性能和减少开支，部分Client还会设计成批量发送
  - 也不会维持和记录消息的offset
  - Consumer 会自动设置定时器到服务端去询问是否有新的消息产生
  - 以消费者的消费能力以适当的速率消费消息
  - 一旦产生新的消息则会同步到本地，并且修改和记录offset，服务端可以辅助存储offset，但是不会主动记录和校验offset的合理性，同时Consumer可以完全自主的维护offset以便实现自定义的信息读取
  - 消息处理可能有延迟，不过可以通过长轮询的方式来提高实时性
  - 缺点
    + 消息延迟与忙等
* RocketMq里有一种优化的做法-长轮询，来平衡推拉模型各自的缺点。基本思路是:消费者如果尝试拉取失败，不是直接return,而是把连接挂在那里wait,服务端如果有新的消息到来，把连接notify起来，这也是不错的思路。但海量的长连接block对系统的开销还是不容小觑的，还是要合理的评估时间间隔，给wait加一个时间上限比较好

## 消息不丢失最终一致性

* 方法
  - producer往broker发送消息之前，需要做一次落地
  - 请求到server后，server确保数据落地后再告诉客户端发送成功
  - 支持广播的消息队列需要对每个待发送的endpoint，持久化一个发送状态，直到所有endpoint状态都OK才可删除消息
* 生产消息: 生产者发送消息至Broker，需要处理Broker的响应，不论是同步还是异步发送消息，同步和异步回调都需要做好try-catch，妥善的处理响应，如果Broker返回写入失败等错误消息，需要重试发送。当多次发送失败需要作报警，日志记录等。
* 存储消息:存储消息阶段需要在消息刷盘之后再给生产者响应，假设消息写入缓存中就返回响应，那么机器突然断电这消息就没了，而生产者以为已经发送成功了。单机情况下是消息刷盘后返回响应，集群多副本情况下，即发送至两个副本及以上的情况下再返回响应。
* 消费消息：应该在消费者真正执行完业务逻辑之后，再发送给Broker消费成功，这才是真正的消费了

## 消息重发

* 如何鉴别消息重复，并幂等的处理重复消息
  - 每一个消息应该有它的唯一身份
    + 版本号
      * 下游对于每次消息的处理，同时维护一个版本号。每次只接受比当前版本号大的消息,如果版本号是3.则是真实的下线消息。如果是1，则是重复投递的消息
      * 如果想让乱序的消息最后能够正确的被组织，那么就应该只接收比当前版本号大一的消息。并且在一个session周期内要一直保存各个消息的版本号
    + 状态机:业务方只需要自己维护一个状态机，定义各种状态的流转关系
* 一个消息队列如何尽量减少重复消息的投递
- 原因
  + Broker已经写入了，当时响应由于网络原因生产者没有收到，然后生产者又重发了一次，此时消息就重复
  + 业务逻辑已经走完了，事务提交了，此时需要更新Consumer offset了，然后这个消费者挂了，另一个消费者顶上，此时Consumer offset还没更新，于是又拿到刚才那条消息，业务又被执行了一遍
- 幂等：在业务上处理重复消息所带来的影响
  + 同样的参数多次调用同一个接口和调用一次产生的结果是一致的
  + 做前置条件判断:`pdate t1 set money = 150 where id = 1 and money = 100; 执行多少遍money都是150`
  + 通过数据库的约束例如唯一键,处理订单这种，记录订单ID，假如有重复的消息过来，先判断下这个ID是否已经被处理过了，如果没处理再进行下一步
  + 记录关键的key
- 减少
  + broker记录MessageId，直到投递成功后清除，重复的ID到来不做处理，这样只要发送者在清除周期内能够感知到消息投递成功，就基本不会在server端产生重复消息。
  + 对于server投递到consumer的消息，由于不确定对端是在处理过程中还是消息发送丢失的情况下，有必要记录下投递的IP地址。决定重发之前询问这个IP，消息处理成功了吗？如果询问无果，再重发。

## 消息级别

* 至多一次（Qos=0）：下游允许部分消息丢失，不进行处理，这种方式一般适用于监控信息和 log 的传递，少一两条影响不大
  - 生产者只需要异步发送，在发送失败或者消费失败的时候不做任何处理即可
  - MQ 在消费者拉走消息后，就直接将消息标记为已经消费或者删除消息
* 至少一次（Qos=1）：消息必须全部送达，不允许任何消息丢失，但是可以接受部分消息重复，此种方式一般适用于订单，支付等场景（当然，这要求下游系统实现去重或幂等）
  - 生产者发消息到 MQ，MQ 收到消息后返回确认信息（ACK）给生产者，生产者收到确认信息后生产过程完成，如果在一定时间内，生产者没有收到确认信息，生产者重新发送消息。
  - 重新发送的过程可以是立即发送，也可以将处理异常的消息持久化，比如保存到数据库中，然后定时重试知道成功。
  - 消费者从 MQ 获取到消息后，当业务逻辑处理完成，向 MQ 返回 ACK 信息。
  - 存在下面一种情况，当 MQ 收到消息并发送 ACK，或者消费者消费完成发送 ACK 信息之后，由于网络，系统故障等问题，ACK 信息没有成功送达，就会导致消息重复发送。
  - 对于大部分消息队列的实现来说（如 kafka，RocketMQ）对于消息重复的处理方式，就是不处理，交由消费者根据业务逻辑自己实现去重或幂等。
  - 消费者根据业务逻辑自己实现去重或幂等。消费者根据业务逻辑自己实现去重或幂等。 重要的事情说三遍。有些人或许会觉得这是常识和基本素养，但也有部分同学过于相信 MQ 系统和网络环境的稳定性，不做去重导致业务出现问题，比如优惠卷系统没有做去重处理，本来只能领取一张的优惠券，结果给用户发了多张。
* 正好一次（Qos=2）：最严格的要求，就是消息只能送达一次，不能多也不能少，每次消息传递过程正需要四次通信。物联网场景下，大部分终端是嵌入式系统，处理能力会比服务器低很多，所以服务端需要帮助终端实现去重，简化终端的业务逻辑
  - 发送端发消息给接收端，接收端收到消息后持久化保存消息 ID 并返回 REC 信息给发送端，通知生产端我已经收到这个消息了
  - 这时消息是一种中间态，接受端不会进行业务逻辑的处理。这个过程中，如果 REC 消息丢失，服务端重传了消息， 接受端接受到消息后会和本地保存到消息 ID 做对比，如果重复，就丢弃消息不做处理，避免消息被处理多次，而且消息 ID 会持久化到硬盘，防止因为断电内存中数据丢失倒是消息被重复处理
  - 发送端收到接收端返回的 rec 消息后，发送一个 rel 请求给消费端，告诉消费端我确认收到了你的确认消息，接收端收到 rel 请求后才会进行具体的业务逻辑处理，并返回 comp 信息给发送端，同时在本地删除保存的消息 ID
  - 如果发送端没有收到 comp 信息，会重发 rel 请求而不会重发消息

## 消息有序性

* 全局有序
  - 只能由一个生产者往Topic发送消息，并且一个Topic内部只能有一个队列（分区）。消费者也必须是单线程消费这个队列。这样的消息就是全局有序的
  - 一般情况下我们都不需要全局有序，即使是同步MySQL Binlog也只需要保证单表消息有序即可
* 部分有序
  - 每个队列对应一个单线程处理的消费者

## 消息堆积

* 因为生产者的生产速度与消费者的消费速度不匹配
* 先定位消费慢的原因
  - 如果是bug则处理 bug
  - 优化下消费逻辑
  - 水平扩容:增加Topic的队列数和消费者数量，注意队列数一定要增加，不然新增加的消费者是没东西消费的。一个Topic中，一个队列只会分配给一个消费者
+ 基于一个prefetch count来控制这个unack message的数量，通过 “channel.basicQos(10)” 这个方法来设置当前channel的prefetch count
  * 正在投递到channel过程 + 服务在处理中 + 异步ack之后还没完
  * 超过了prefetch count指定的数量，此时RabbitMQ就会停止给这个channel投递消息了，必须要等待已经投递过去的消息被ack了，此时才能继续投递下一个消息
  * 设置在100~300之间
+ 设置太高 在高并发下服务直接被击垮了，内存溢出，OOM，服务宕机，然后大量unack的消息会被重新投递给其他的消费者服务，此时其他消费者服务一样的情况，直接宕机，最后造成雪崩效应
+ 过小导致吞吐量过低

## 消息可靠性

* 选择将数据持久化到硬盘，这样当机器故障恢复后数据还在，消费者可以继续消费之前没有消费完的数据。但是，如果仅仅持久化到硬盘，当服务器发生磁盘故障，Raid 卡故障时，数据依然存在丢失的风险。
* 引入了复制 / 多副本的概念，将每份数据都保存在多台服务器上，而且一般这些服务器还要尽可能多实现跨机架甚至跨数据中心
* 复制可以是同步的也可以是异步的，可以是一主一从，也可以是一主多从，也可以基于 Raft，Paxos 等算法实现多副本

## 文件结构

* 消息队列实现根据自己的定位，会选择不同的复制的实现方式以及持久化时的文件结构
* Kafka 会在 Broker 上为每一个 topic 创建一个独立的 partiton 文件，Broker 接受到消息后，会按主题在对应的 partition 文件中顺序的追加消息内容。
* RocketMQ 则会创建一个 commitlog 的文件来保存分片上所有主题的消息
  - Broker 接收到任意主题的消息后，都会将消息的 topic 信息，消息大小，校验和等信息以及消息体的内容顺序追加到 Commitlog 文件中，Commitlog 文件一般为固定大小，当前文件达到限定大小时，会创建一个新的文件，文件以起始便宜位置命名。
  - Broker 会为每一个主题维护各自的 ConsumerQueue 文件，文件中记录了该主题消息的索引，包括在 Commitlog 中的偏移位置，消息大小及校验和，以便于在消费时快速的定位到消息位置。
  - ConsumerQueue 的维护是异步进行的，不影响消息生产的主流程，即使 ConsumerQueue 没有及时更新的 情况下，服务异常终止，下次启动时也可以根据 Commitlog 文件中的内容对 ConsumerQueue 进行恢复。
  - 在消费时，内存加载时会加载一整个 Commitlog 文件，如果同一个 Broker 上的两个主题，一个主题的消息积压了很长时间开始才开始消费，而另一个主题在及时消费新发送的消息时，Broker 可能会频发的读取文件更新到缓存中，造成磁盘性能损耗，进而影响到生产时的发送性能。所以虽然 RocketMQ 支持海量消息积压，但如果是在共享的集群中，还是建议用户最好能做到及时消费，保证集群中所有主题都在消费相近时间段的消息，这样命中内存缓存的概率会比较高，消费时不会带来额外的磁盘开销。
  - 需要同步刷盘保证数据可靠性的应用，磁盘读写性能的重要性一般来讲也会远高于磁盘的空间大小。 成本上来讲，如果可以显著的提高单机性能，虽然单价来看固态硬盘更加昂贵，但是如果可以节省部分 CPU，内存和机架位置，还是很划算的
* 在同步刷盘的场景下，RocketMQ 是顺序写，而 Kafka 是随机写。通常情况下，我们认为顺序写的性能远高于随机写，尤其时对于传统的机械硬盘来讲更是如此。 且当 Broker 上的 topic 数量增多时，RocketMQ 在写消息的性能上几乎不会受到影响，而对 Kafka 的影响则会较大。

## 消费

* 把消息的送达和消息的处理分开，这样才真正的实现了消息队列的本质-解耦
* 消费者从RabbitMQ获取消息的时候，都是通过一个channel的概念来进行的
* 对消息的消费、ack等操作，全部都是基于这个channel来进行的
* 批量发送ack消息（基于同一个channel）给RabbitMQ，这样可以提升整体的性能和吞吐量
* 标记消费确认：
  - 自动ack，是非常简单的。RabbitMQ只要投递一个消息出去给仓储服务，那么他立马就把这个消息给标记为删除，因为他是不管仓储服务到底接收到没有，处理完没有的。性能很好，但是数据容易丢失
  - 手动ack，那么就是必须等仓储服务完成商品调度发货以后，才会手动发送ack给RabbitMQ，此时RabbitMQ才会认为消息处理完毕，然后才会标记消息为删除
    + 服务宕机，RabbitMQ会重发消息给另外一个服务实例，保证数据不丢
* 处理某个消息失败
  - 使用nack操作：通知RabbitMQ没处理成功消息，然后让RabbitMQ将这个消息再次投递给其他服务实例尝试去完成
  - reject 建议做成滑动窗口/线程池类似的模型来控制

## 可用性

复制与 failover 机制

* RPC 高可用
* 消息队列高可用
  - 只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的，这样就把消息队列的可用性，转交给RPC框架来处理了
  - 幂等
    + 共享存储；broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的
* RocketMQ
  - 由两个 Broker 实例组成一组服务，一个作为主节点，提供读写服务，一个作为从节点，在正常情况下只从主节点同步数据不提供读写服务，且每个 topic 都会分配到多个 Broker 分组上。
  - 当某个从节点发生故障时，可以禁止主节点的写入，依然允许消费者继续消费该节点中未处理完成的消息。而生产者有新消息过来时，由其它主从都健康的分组提供服务， 直到故障机器恢复后主节点重新提供读写服务。
  - 如果故障机器无法恢复，只需等积压消息全部消费完，替换故障机器即可。
  - 如果主节点故障，则可以在从节点进行消费，其它处理方式与从节点故障处理方式一致。
  - 这种方式的优点是逻辑简单，实现也简单，简单意味着稳定，隐藏的 bug 少。且数据只需要一份冗余，对磁盘空间的开销相对较少，可以保证大多数情况下的数据可靠性和服务可用性。
* Kafka 的复制策略，使用的是 ISR（可用服务列表）的方式，对于每一个 partiton，可以分配一个或多个 Broker。 其中一个作为主节点，剩余的作为跟随者，跟随者会保存一个 partition 副本
  - 生产者将消息发送到主节点后，主节点会广播给所有跟随者，跟随者收到后返回确认信息给主节点。
  - 用户可以自由的配置副本数及当有几个副本写成功后，则认为消息成功保存。且同时，会在 ZooKeeper 上维护一个可用跟随者列表，列表中记录所有数据和主节点完全同步的跟随者列表。
  - 当主节点发生故障时，在列表中选择一个跟随者作为新的主节点提供服务。
  - 在这种策略下，假设总共有 m 个副本，要求至少有 n 个`（0<n<m+1）`副本写成功，则系统可以在最多 m-n 个机器故障的情况下保证可用性。
* 基于 Raft 算法实现的多副本机制
  - 集群一般由奇数节点构成，如果要保证集群在 n 个节点故障的情况下可用，则至少需要有 2n+1 个节点。
  - 与 ISR 方式相比，Raft 需要耗费更多的资源，但是整个复制和选举过程都是集群中的节点自主完成，不需要依赖 ZooKeeper 等第三者。 理论上 Raft 集群规模可以无限扩展而 ISR 模式下集群规模会受限于 ZooKeeper 集群的处理能力

## 高级特性

* 顺序消息:消息分布在不同的 Broker 上，且有多个客户端同时消费，各实例间的网络状态和处理能力都是不一定的，所以分布式消息系统是没有办法保证消息的处理顺序的
  - 以保证同一个 partition 或者同一个 ConsumerQueue 内的消息是可以保证顺序的。
  - 需要做的就是将需要保证顺序的消息放入到同一个 partiton 或者 queue 中就好了， 最简单的方式是我们只为主题分配一个 partition 或者 queue，这样就可以保证严格的顺序，但是这样就不能体现分布式系统的性能优势了，集群的处理能力没有办法横向扩展。
  - Kafka 提供了指定 partition 发送的功能，使用者可以在客户端根据业务逻辑自行处理，还有的消息队列支持根据某个字段的值，将消息 hash 到消息指定消息队列中。 指定 partition 和 hash 两种方式的主要区别，就是当有某个分片故障时，指定 partition 的方式会导致部分消息发送失败，而 hash 的方式有可能造成少量消息的乱序。
* 事物消息:消息生产过程中，需要确保发送操作和其它业务逻辑处理结果的一致性，要么都成功要么都失败。实现一般是依赖两步提交策略,以已写库并发消息为例
  - 客户端将消息发送到 Broker，Broker 收到消息后，给客户端返回一个确认信息。 这时消息在服务端是处于一种中间状态，消费者不可以消费这种状态的消息。
  - 客户端收到确认消息后，执行写数据库的操作，写库成功后，向 Broker 再发送一个提交信息。
  - 服务端收到提交信息后将消息更改就绪状态，允许消费者正常消费。
  - 同时，生产者客户端还要提供一个回调方法，当 Broker 收到消息后，长时间没有收到确认信息时，调用客户端提供的回调方法进行回滚，如重置数据库。
* 消息回放：重新消费已经消费完的消息。需要保证消息不会在消费成功之后立刻删除，而是保存一段时间后，根据一定策略，如一周后删除。同时，还需要对消费者当前消费的消费位置进行记录
  - RocketMQ 和 Kafka 都会通过一个 Offset 文件来记录消费者的消费位置，当消费者消费完成功，更新并提交 Offset。一般来说，Offset 文件中还需要记录最大消费位置，即已经入队的最新一条消息所在的位置和最小消费位置，即还没删除的最老的消息所在的位置。
  - Offset 文件可以保存在服务端，也可以保存在客户端，也可以保存在 ZooKeeper 中，或者其它如 Redis 之类的第三方存储。
    + Kafka 将 Offset 保存到 Broker 对应的 topic 中
    + RocketMQ 则支持有两种模式，默认是集群模式，topic 中的每条消息只会集群中的一个实例消费，这种模式由服务端管理 Offset，还有一种是广播模式，集群中的所有实例都会消费一份全量消息，这种模式由客户端管理 Offset。
* 批量
  - 消费动作都是事件驱动，包括：
   + 攒够了一定数量。
   + 到达了一定时间。
   + 队列里有新的数据到来。
 - 提高性能
   + 减少无谓的请求头
   + 减少回复的ack包个数

## 数据准确性

* 消费机器 收到消息后未处理宕机
  - MQ系统机制：只要服务收到一个消息，RabbitMQ就会立马把这条订单消息给标记为删除，这个行为叫做自动ack
  - 关闭autoAck的行为，手动发送ack消息
    + 消费者服务实例会自己注册到RabbitMQ,RabbitMQ其实是知道有哪些消费者服务实例存在的
    + RabbitMQ就会通过自己内部的一个“basic.delivery”方法来投递消息到仓储服务里去，让他消费消息
    + 投递的时候，会给这次消息的投递带上一个重要的东西，就是“delivery tag”，可以认为是本次消息投递的一个唯一标识。通过这个唯一ID，可以定位一次消息投递
    + 每次消费了一条消息，处理完毕完成调度发货之后，就会发送一个ack消息给RabbitMQ服务器，这个ack消息是会带上自己本次消息的delivery tag的
    + RabbitMQ根据哪个channel的哪个delivery tag，对那条消息删除，标识为已经处理完毕
* 中间件机器宕机
  - 消息的持久化
    + 自动恢复queue
    + 消息持久化
* 未来得及持久化到磁盘上，同时也还没来得及投递到作为消费，中间件机器宕机

## 单机性能因素

* 硬件层面
  - 硬盘：一般来说消息队列的瓶颈主要在磁盘 IO，更好的硬盘会带来更高的性能，正常情况性能由高到低排序为 NVMe > 传统 SSD（Non-Volatile Memory express） >SAS >SATA。 对于 SAS 盘和 SATA 盘这种机械硬盘来说，还要看具体硬盘的转速。
  - Raid 卡: Raid 卡的型号和性能，以及是否带有 Raid 卡缓存，Raid 卡的鞋策略是 WriteThough 还是 WriteBack 也会影响到服务的 I/O 性能进而影响到吞吐量。
* 系统层面
  - Raid 级别：当有 4 块盘时，Raid0，Raid5 和 Raid10 三种形式的 Raid 会对 I/O 性能造成不同的影响。Raid0 因为不需要任何其它操作，速度是最快的，几乎等于单盘写速度的四倍。Raid10 需要写一份数据和一份镜像，写性能是略小于单盘写速度的两倍的；Raid5 每次写入可以有三个盘提供写服务，另一个盘来存放校验和，由于计算校验和存在一定的性能损耗，写速度略小于单盘写速度的三倍，而且随着硬盘数量的增多，Raid5 计算校验和造成的开销会随之增大，如果没有 Raid 卡缓存支撑的话，对于 SSD 硬盘，由于 partial-stripe 些问题，raid5 性能可能会低于 Raid10 的。
  - Linux I/O 调度算法：Linux 内核包含 Noop，Deadline，CFG, Anticipatory 四种 I/O 调度算法，需要结合应用特性和硬件选择合适的调度算法。 据说 SSD 硬盘更适合使用 Noop 算法。
  - 文件系统的 block size：调整合适的文件系统的 block size 也会提高吞吐量。
  - SWAP 的使用： SWAP 空间使用过程中会造成一定的 I/O 开销，如果内存充足的情况下，可以关闭 SWAP 功能。
* 应用层面
  - 文件读写的方式：一般来说，顺序读写速度远高于随机读写，且一次性读写的文件越大相对来说效率越高。应用可以据此来对文件结构和读写方式做一定优化。
  - 缓存策略： 应用可以通过一定的缓存策略，提前将可能用到的数据读到内存中，当收到请求时，如果能命中缓存中的数据，在缓存中直接读取效率远高于读写磁盘。同样，写操作时也可以通过缓存将零散的写操作进行汇集，提高写操作的效率。 所有适合的缓存策略将显著提高 Broker 的处理能力。

## 对比

* 社区活跃度：按照目前网络上的资料，RabbitMQ 、activeM 、ZeroMQ 三者中，综合来看，RabbitMQ 是首选。
* 持久化消息比较：ZeroMq 不支持，ActiveMq 和RabbitMq 都支持。持久化消息主要是指我们机器在不可抗力因素等情况下挂掉了，消息不会丢失的机制。
* 综合技术实现
  - 可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。RabbitMq / Kafka 最好，ActiveMq 次之，ZeroMq 最差。当然ZeroMq 也可以做到，不过自己必须手动写代码实现，代码量不小。尤其是可靠性中的：持久性、投递确认、发布者证实和高可用性。
* 高并发：毋庸置疑，RabbitMQ 最高，原因是它的实现语言是天生具备高并发高可用的erlang 语言。
* RabbitMQ vs Kafka
  + RabbitMq 比Kafka 成熟，在可用性上，稳定性上，可靠性上，  RabbitMq  胜于  Kafka  （理论上）。
  + Kafka 的定位主要在日志等方面， 因为Kafka 设计的初衷就是处理日志的，可以看做是一个日志（消息）系统一个重要组件，针对性很强，所以 如果业务方面还是建议选择 RabbitMq 。
  + Kafka 的性能（吞吐量、TPS ）比RabbitMq 要高出来很多

## 产品

* [PhxQueue](https://github.com/Tencent/phxqueue):[介绍](https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=2650997820&idx=1&sn=c21021580f5474e6f570d1a1eada22bd&chksm=bdbefc6f8ac975791c85d2e9e8cb58a2c384d3daf29c4ac808789aa2281d2dd53c4d2baaf33d&mpshare=1&scene=1&srcid=09141b12nitpm39kMwTLxSIg&pass_ticket=T61h6XjBkARmtNGuhNVdyhTXYAlGFU%2Brx%2FhZrUNp8OOKx9ul0UwejPXkjaJ%2F3yFI#rd)
* [nsq](https://github.com/nsqio/nsq)[文档](http://nsq.io/overview/quick_start.html)
* [Apache ActiveMQ](link)
* [Celery](http://www.celeryproject.org):Distributed Task Queue
