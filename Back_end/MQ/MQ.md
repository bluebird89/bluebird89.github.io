# 消息队列

一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。解决系统间异步通信的中间件,用于解决系统解耦和请求的削峰平谷的问题.消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。作为成熟的异步通信模式，对比常用的同步通信模式，有如下优势：

* 排序保证：先投递先到达的保证是一个消息队列
* 异步调用：增强业务系统的异步处理能力，减少甚至几乎不可能出现并发现象
* 系统解耦 ：防止引入过多的 API 给系统的稳定性带来风险；调用方使用不当会给被调用方系统造成压力，被调用方处理不当会降低调用方系统的响应能力。如果一个系统挂了，则不会影响另外个系统的继续运行。
    - 下游系统处理异常，上游系统如何处理
    - 系统宕机的情况下会不会导致数据丢失
    - 当有业务数据异常时，如何去定位是上游系统发送出了问题还是下游系统的问题
    - 如果需要同时将信息发送给多个下游系统，其中一个处理有问题会不会导致其它系统受影响
    - 注意
        + 考虑下游系统处理异常，上游系统如何处理？
        + 系统宕机的情况下会不会导致数据丢失？
        + 当有业务数据异常时，如何去定位是上游系统发送出了问题还是下游系统的问题？
        + 如果需要同时将信息发送给多个下游系统，其中一个处理有问题会不会导致其它系统受影响？
* 流量削峰和流控：消息生产者不会堵塞，突发消息缓存在队列中，消费者按照实际能力读取消息。业务系统往往要求响应能力特别强，能够起到削峰填谷的作用。
* 复用：一次发布多方订阅
* 冗余
* 业务系统往往有对消息的高可靠要求，以及有对复杂功能如 Ack 的要求

## 协议

* JMS（Java Message Service）： JMS 本质上是 JAVA API。在 JMS 中定义了 Producer，Consumer，Provider 三种角色
    - Producer 作为消息的发送方，Consumer 作为消息的接收方，Provider 作为服务的提供者，Producer 和 Consumer 统称为 Client。
    - JMS 定义了点对点和发布订阅两种消息模型
        + 发布订阅模型中，通过 topic 对消息进行路由，生产者可以将消息发到指定的 topic，消费者订阅这个 topic 即可收到生产者发送的消息。一个生产者可以向一个或多个 topic 中发送消息，一个消费者也可以消费一个或多个 topic 中的消息，一个 topic 也可以有多个生产者或消费者，生产者和消费者只需要关联 topic，而不用关心这消息由谁发送或者消费。
            - Provider 为每一个 topic 维护一个或多个 queue 来保存消息，消息在 queue 中是有序的，遵循先进先出的原则，不同 queue 间的消息是无序的。
        - 点对点模式中没有 topic 的概念，生产者直接将消息发送到指定 queue，消费者也指定 queue 进行消费，消息只能被一个消费者消费，不可以被多个消费者消费。Kafka 和 RocketMQ 都实现了或部分实现了 JMS 协议。
* AMQP（Advanced Message Queuing Protocol）： 与 JMS 不同，AMQP 是一个应用层的网络传输协议，对报文格式进行定义，与开发语言无关。在 AMQP 中同样有生产者，消费者两种角色，消息也是保存在 queue 中的。 但不同于 JMS 用 topic 对消息进行路由，AMQP 的路由方式由 exchange 和 binding 决定。
    * client 可以创建 queue，并在创建 queue 的同时通知 exchange 这个 queue 接受符合什么条件的消息，这个条件即为 Bingding key。
    * 生产者发送消息到 exchange 的时候会指定一个 router key，exchange 收到消息后会与自己所维护的 Bingding key 做比较，发送到符合条件的 queue 中。消费者在消费时指定 queue 进行消费。
    * RabbitMQ 实现了 AMQP 协议。
* MQTT（Message Queuing Telemetry Transport）：MQTT 协议是一种基于发布订阅的轻量级协议，支持 TCP 和 UDP 两种连接方式，主要应用于即时通讯，小型设备，移动应用等领域。 MQTT 中有发布者（Publish），订阅者（Subscribe）和代理服务器（Broker）三种角色。
    - Broker 是服务的提供者，发布者和前两种协议中的生产者相同，将消息（Message）发送到 Broker，Subscribe 从 Broker 中获取消息并做业务处理。MQTT 的 Message 中固定消息头（Fixed header）仅有 2 字节，开销极小，除此之外分为可变头（Variable header）和消息体（payload）两部分。固定头中包含消息类型，消息级别，变长头的大小以及消息体的总长度等信息。 变长头则根据消息类别，含有不同的标识信息。
    - MQTT 允许客户端动态的创建主题，发布者与服务端建立会话（session）后，可以通过 Publish 方法发送数据到服务端的对应主题
    - 订阅者通过 Subscribe 订阅主题后，服务端就会将主题中的消息推送给对应的订阅者。

## 推 / 拉两种模式

* Push:推模式即服务端收到消息后，主动将消息推送给消费者，由消费者进行处理，这种模式具有更高的实时性，
    - 由于服务端不能准确评估消费端的消费性能，所以有可能造成消息推送过多使客户端来不及处理收到的消息
* pull：拉模式则是服务端收到消息后将消息保存在服务端，被动的等待客户端来拉取消息，这种模式下客户端可以根据自己的处理能力来决定拉消息的频率
    - 消息处理可能有延迟，不过可以通过长轮询的方式来提高实时性

## 消息级别

* 问题
    - 消息丢失
    - 消息重发
    - 消息积压
        + 基于一个prefetch count来控制这个unack message的数量，通过 “channel.basicQos(10)” 这个方法来设置当前channel的prefetch count
            * 正在投递到channel过程 + 服务在处理中 + 异步ack之后还没完
            * 超过了prefetch count指定的数量，此时RabbitMQ就会停止给这个channel投递消息了，必须要等待已经投递过去的消息被ack了，此时才能继续投递下一个消息
            * 设置在100~300之间
        + 设置太高 在高并发下服务直接被击垮了，内存溢出，OOM，服务宕机，然后大量unack的消息会被重新投递给其他的消费者服务，此时其他消费者服务一样的情况，直接宕机，最后造成雪崩效应
        + 过小导致吞吐量过低
* 至多一次（Qos=0）：下游允许部分消息丢失，不进行处理，这种方式一般适用于监控信息和 log 的传递，少一两条影响不大
    - 生产者只需要异步发送，在发送失败或者消费失败的时候不做任何处理即可
    - MQ 在消费者拉走消息后，就直接将消息标记为已经消费或者删除消息
* 至少一次（Qos=1）：消息必须全部送达，不允许任何消息丢失，但是可以接受部分消息重复，此种方式一般适用于订单，支付等场景（当然，这要求下游系统实现去重或幂等）
    - 生产者发消息到 MQ，MQ 收到消息后返回确认信息（ACK）给生产者，生产者收到确认信息后生产过程完成，如果在一定时间内，生产者没有收到确认信息，生产者重新发送消息。
    - 重新发送的过程可以是立即发送，也可以将处理异常的消息持久化，比如保存到数据库中，然后定时重试知道成功。
    - 消费者从 MQ 获取到消息后，当业务逻辑处理完成，向 MQ 返回 ACK 信息。
    - 存在下面一种情况，当 MQ 收到消息并发送 ACK，或者消费者消费完成发送 ACK 信息之后，由于网络，系统故障等问题，ACK 信息没有成功送达，就会导致消息重复发送。
    - 对于大部分消息队列的实现来说（如 kafka，RocketMQ）对于消息重复的处理方式，就是不处理，交由消费者根据业务逻辑自己实现去重或幂等。
    - 消费者根据业务逻辑自己实现去重或幂等。消费者根据业务逻辑自己实现去重或幂等。 重要的事情说三遍。有些人或许会觉得这是常识和基本素养，但也有部分同学过于相信 MQ 系统和网络环境的稳定性，不做去重导致业务出现问题，比如优惠卷系统没有做去重处理，本来只能领取一张的优惠券，结果给用户发了多张。
* 正好一次（Qos=2）：最严格的要求，就是消息只能送达一次，不能多也不能少，每次消息传递过程正需要四次通信。物联网场景下，大部分终端是嵌入式系统，处理能力会比服务器低很多，所以服务端需要帮助终端实现去重，简化终端的业务逻辑
    - 发送端发消息给接收端，接收端收到消息后持久化保存消息 ID 并返回 REC 信息给发送端，通知生产端我已经收到这个消息了
    - 这时消息是一种中间态，接受端不会进行业务逻辑的处理。这个过程中，如果 REC 消息丢失，服务端重传了消息， 接受端接受到消息后会和本地保存到消息 ID 做对比，如果重复，就丢弃消息不做处理，避免消息被处理多次，而且消息 ID 会持久化到硬盘，防止因为断电内存中数据丢失倒是消息被重复处理
    - 发送端收到接收端返回的 rec 消息后，发送一个 rel 请求给消费端，告诉消费端我确认收到了你的确认消息，接收端收到 rel 请求后才会进行具体的业务逻辑处理，并返回 comp 信息给发送端，同时在本地删除保存的消息 ID
    - 如果发送端没有收到 comp 信息，会重发 rel 请求而不会重发消息

## 消息可靠性

* 选择将数据持久化到硬盘，这样当机器故障恢复后数据还在，消费者可以继续消费之前没有消费完的数据。但是，如果仅仅持久化到硬盘，当服务器发生磁盘故障，Raid 卡故障时，数据依然存在丢失的风险。
* 引入了复制 / 多副本的概念，将每份数据都保存在多台服务器上，而且一般这些服务器还要尽可能多实现跨机架甚至跨数据中心
* 复制可以是同步的也可以是异步的，可以是一主一从，也可以是一主多从，也可以基于 Raft，Paxos 等算法实现多副本

## 文件结构

* 消息队列实现根据自己的定位，会选择不同的复制的实现方式以及持久化时的文件结构
* Kafka 会在 Broker 上为每一个 topic 创建一个独立的 partiton 文件，Broker 接受到消息后，会按主题在对应的 partition 文件中顺序的追加消息内容。
* RocketMQ 则会创建一个 commitlog 的文件来保存分片上所有主题的消息
    - Broker 接收到任意主题的消息后，都会将消息的 topic 信息，消息大小，校验和等信息以及消息体的内容顺序追加到 Commitlog 文件中，Commitlog 文件一般为固定大小，当前文件达到限定大小时，会创建一个新的文件，文件以起始便宜位置命名。
    - Broker 会为每一个主题维护各自的 ConsumerQueue 文件，文件中记录了该主题消息的索引，包括在 Commitlog 中的偏移位置，消息大小及校验和，以便于在消费时快速的定位到消息位置。
    - ConsumerQueue 的维护是异步进行的，不影响消息生产的主流程，即使 ConsumerQueue 没有及时更新的 情况下，服务异常终止，下次启动时也可以根据 Commitlog 文件中的内容对 ConsumerQueue 进行恢复。
    - 在消费时，内存加载时会加载一整个 Commitlog 文件，如果同一个 Broker 上的两个主题，一个主题的消息积压了很长时间开始才开始消费，而另一个主题在及时消费新发送的消息时，Broker 可能会频发的读取文件更新到缓存中，造成磁盘性能损耗，进而影响到生产时的发送性能。所以虽然 RocketMQ 支持海量消息积压，但如果是在共享的集群中，还是建议用户最好能做到及时消费，保证集群中所有主题都在消费相近时间段的消息，这样命中内存缓存的概率会比较高，消费时不会带来额外的磁盘开销。
    - 需要同步刷盘保证数据可靠性的应用，磁盘读写性能的重要性一般来讲也会远高于磁盘的空间大小。 成本上来讲，如果可以显著的提高单机性能，虽然单价来看固态硬盘更加昂贵，但是如果可以节省部分 CPU，内存和机架位置，还是很划算的
* 在同步刷盘的场景下，RocketMQ 是顺序写，而 Kafka 是随机写。通常情况下，我们认为顺序写的性能远高于随机写，尤其时对于传统的机械硬盘来讲更是如此。 且当 Broker 上的 topic 数量增多时，RocketMQ 在写消息的性能上几乎不会受到影响，而对 Kafka 的影响则会较大。

## 消费

* 消费者从RabbitMQ获取消息的时候，都是通过一个channel的概念来进行的
* 对消息的消费、ack等操作，全部都是基于这个channel来进行的
* 批量的发送ack消息（基于同一个channel）给RabbitMQ，这样可以提升整体的性能和吞吐量
* 标记
    - 自动ack，是非常简单的。RabbitMQ只要投递一个消息出去给仓储服务，那么他立马就把这个消息给标记为删除，因为他是不管仓储服务到底接收到没有，处理完没有的。性能很好，但是数据容易丢失
    - 手动ack，那么就是必须等仓储服务完成商品调度发货以后，才会手动发送ack给RabbitMQ，此时RabbitMQ才会认为消息处理完毕，然后才会标记消息为删除
        + 服务宕机，RabbitMQ会重发消息给另外一个服务实例，保证数据不丢
* 处理某个消息失败
    - 使用nack操作：通知RabbitMQ没处理成功消息，然后让RabbitMQ将这个消息再次投递给其他服务实例尝试去完成

## 可用性

复制与 failover 机制

* RocketMQ
    - 由两个 Broker 实例组成一组服务，一个作为主节点，提供读写服务，一个作为从节点，在正常情况下只从主节点同步数据不提供读写服务，且每个 topic 都会分配到多个 Broker 分组上。
    - 当某个从节点发生故障时，可以禁止主节点的写入，依然允许消费者继续消费该节点中未处理完成的消息。而生产者有新消息过来时，由其它主从都健康的分组提供服务， 直到故障机器恢复后主节点重新提供读写服务。
    - 如果故障机器无法恢复，只需等积压消息全部消费完，替换故障机器即可。
    - 如果主节点故障，则可以在从节点进行消费，其它处理方式与从节点故障处理方式一致。
    - 这种方式的优点是逻辑简单，实现也简单，简单意味着稳定，隐藏的 bug 少。且数据只需要一份冗余，对磁盘空间的开销相对较少，可以保证大多数情况下的数据可靠性和服务可用性。
* Kafka 的复制策略，使用的是 ISR（可用服务列表）的方式，对于每一个 partiton，可以分配一个或多个 Broker。 其中一个作为主节点，剩余的作为跟随者，跟随者会保存一个 partition 副本
    - 生产者将消息发送到主节点后，主节点会广播给所有跟随者，跟随者收到后返回确认信息给主节点。
    - 用户可以自由的配置副本数及当有几个副本写成功后，则认为消息成功保存。且同时，会在 ZooKeeper 上维护一个可用跟随者列表，列表中记录所有数据和主节点完全同步的跟随者列表。
    - 当主节点发生故障时，在列表中选择一个跟随者作为新的主节点提供服务。
    - 在这种策略下，假设总共有 m 个副本，要求至少有 n 个`（0<n<m+1）`副本写成功，则系统可以在最多 m-n 个机器故障的情况下保证可用性。
* 基于 Raft 算法实现的多副本机制
    - 集群一般由奇数节点构成，如果要保证集群在 n 个节点故障的情况下可用，则至少需要有 2n+1 个节点。
    - 与 ISR 方式相比，Raft 需要耗费更多的资源，但是整个复制和选举过程都是集群中的节点自主完成，不需要依赖 ZooKeeper 等第三者。 理论上 Raft 集群规模可以无限扩展而 ISR 模式下集群规模会受限于 ZooKeeper 集群的处理能力

## 高级特性

* 顺序消息:消息分布在不同的 Broker 上，且有多个客户端同时消费，各实例间的网络状态和处理能力都是不一定的，所以分布式消息系统是没有办法保证消息的处理顺序的
    - 以保证同一个 partition 或者同一个 ConsumerQueue 内的消息是可以保证顺序的。
    - 需要做的就是将需要保证顺序的消息放入到同一个 partiton 或者 queue 中就好了， 最简单的方式是我们只为主题分配一个 partition 或者 queue，这样就可以保证严格的顺序，但是这样就不能体现分布式系统的性能优势了，集群的处理能力没有办法横向扩展。
    - Kafka 提供了指定 partition 发送的功能，使用者可以在客户端根据业务逻辑自行处理，还有的消息队列支持根据某个字段的值，将消息 hash 到消息指定消息队列中。 指定 partition 和 hash 两种方式的主要区别，就是当有某个分片故障时，指定 partition 的方式会导致部分消息发送失败，而 hash 的方式有可能造成少量消息的乱序。
* 事物消息:消息生产过程中，需要确保发送操作和其它业务逻辑处理结果的一致性，要么都成功要么都失败。实现一般是依赖两步提交策略,以已写库并发消息为例
    - 客户端将消息发送到 Broker，Broker 收到消息后，给客户端返回一个确认信息。 这时消息在服务端是处于一种中间状态，消费者不可以消费这种状态的消息。
    - 客户端收到确认消息后，执行写数据库的操作，写库成功后，向 Broker 再发送一个提交信息。
    - 服务端收到提交信息后将消息更改就绪状态，允许消费者正常消费。
    - 同时，生产者客户端还要提供一个回调方法，当 Broker 收到消息后，长时间没有收到确认信息时，调用客户端提供的回调方法进行回滚，如重置数据库。
* 消息回放：重新消费已经消费完的消息。需要保证消息不会在消费成功之后立刻删除，而是保存一段时间后，根据一定策略，如一周后删除。同时，还需要对消费者当前消费的消费位置进行记录
    - RocketMQ 和 Kafka 都会通过一个 Offset 文件来记录消费者的消费位置，当消费者消费完成功，更新并提交 Offset。一般来说，Offset 文件中还需要记录最大消费位置，即已经入队的最新一条消息所在的位置和最小消费位置，即还没删除的最老的消息所在的位置。
    - Offset 文件可以保存在服务端，也可以保存在客户端，也可以保存在 ZooKeeper 中，或者其它如 Redis 之类的第三方存储。
        + Kafka 将 Offset 保存到 Broker 对应的 topic 中
        + RocketMQ 则支持有两种模式，默认是集群模式，topic 中的每条消息只会集群中的一个实例消费，这种模式由服务端管理 Offset，还有一种是广播模式，集群中的所有实例都会消费一份全量消息，这种模式由客户端管理 Offset。

## 数据准确性

* 消费机器 收到消息后未处理宕机
    - MQ系统机制：只要服务收到一个消息，RabbitMQ就会立马把这条订单消息给标记为删除，这个行为叫做自动ack
    - 关闭autoAck的行为，手动发送ack消息
        + 消费者服务实例会自己注册到RabbitMQ,RabbitMQ其实是知道有哪些消费者服务实例存在的
        + RabbitMQ就会通过自己内部的一个“basic.delivery”方法来投递消息到仓储服务里去，让他消费消息
        + 投递的时候，会给这次消息的投递带上一个重要的东西，就是“delivery tag”，可以认为是本次消息投递的一个唯一标识。通过这个唯一ID，可以定位一次消息投递
        + 每次消费了一条消息，处理完毕完成调度发货之后，就会发送一个ack消息给RabbitMQ服务器，这个ack消息是会带上自己本次消息的delivery tag的
        + RabbitMQ根据哪个channel的哪个delivery tag，对那条消息删除，标识为已经处理完毕
* 中间件机器宕机
    - 消息的持久化
        + 自动恢复queue
        + 消息持久化
* 未来得及持久化到磁盘上，同时也还没来得及投递到作为消费，中间件机器宕机

## 单机性能因素

* 硬件层面
    - 硬盘：一般来说消息队列的瓶颈主要在磁盘 IO，更好的硬盘会带来更高的性能，正常情况性能由高到低排序为 NVMe > 传统 SSD（Non-Volatile Memory express） >SAS >SATA。 对于 SAS 盘和 SATA 盘这种机械硬盘来说，还要看具体硬盘的转速。
    - Raid 卡: Raid 卡的型号和性能，以及是否带有 Raid 卡缓存，Raid 卡的鞋策略是 WriteThough 还是 WriteBack 也会影响到服务的 I/O 性能进而影响到吞吐量。
* 系统层面
    - Raid 级别：当有 4 块盘时，Raid0，Raid5 和 Raid10 三种形式的 Raid 会对 I/O 性能造成不同的影响。Raid0 因为不需要任何其它操作，速度是最快的，几乎等于单盘写速度的四倍。Raid10 需要写一份数据和一份镜像，写性能是略小于单盘写速度的两倍的；Raid5 每次写入可以有三个盘提供写服务，另一个盘来存放校验和，由于计算校验和存在一定的性能损耗，写速度略小于单盘写速度的三倍，而且随着硬盘数量的增多，Raid5 计算校验和造成的开销会随之增大，如果没有 Raid 卡缓存支撑的话，对于 SSD 硬盘，由于 partial-stripe 些问题，raid5 性能可能会低于 Raid10 的。
    - Linux I/O 调度算法：Linux 内核包含 Noop，Deadline，CFG, Anticipatory 四种 I/O 调度算法，需要结合应用特性和硬件选择合适的调度算法。 据说 SSD 硬盘更适合使用 Noop 算法。
    - 文件系统的 block size：调整合适的文件系统的 block size 也会提高吞吐量。
    - SWAP 的使用： SWAP 空间使用过程中会造成一定的 I/O 开销，如果内存充足的情况下，可以关闭 SWAP 功能。
* 应用层面
    - 文件读写的方式：一般来说，顺序读写速度远高于随机读写，且一次性读写的文件越大相对来说效率越高。应用可以据此来对文件结构和读写方式做一定优化。
    - 缓存策略： 应用可以通过一定的缓存策略，提前将可能用到的数据读到内存中，当收到请求时，如果能命中缓存中的数据，在缓存中直接读取效率远高于读写磁盘。同样，写操作时也可以通过缓存将零散的写操作进行汇集，提高写操作的效率。 所有适合的缓存策略将显著提高 Broker 的处理能力。

## 产品

* [PhxQueue](https://github.com/Tencent/phxqueue):[介绍](https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=2650997820&idx=1&sn=c21021580f5474e6f570d1a1eada22bd&chksm=bdbefc6f8ac975791c85d2e9e8cb58a2c384d3daf29c4ac808789aa2281d2dd53c4d2baaf33d&mpshare=1&scene=1&srcid=09141b12nitpm39kMwTLxSIg&pass_ticket=T61h6XjBkARmtNGuhNVdyhTXYAlGFU%2Brx%2FhZrUNp8OOKx9ul0UwejPXkjaJ%2F3yFI#rd)
* [nsqio/nsq](https://github.com/nsqio/nsq) [文档](http://nsq.io/overview/quick_start.html)
* [apache/incubator-rocketmq](https://github.com/apache/incubator-rocketmq) a distributed messaging and streaming platform with low latency, high performance and reliability, trillion-level capacity and flexible scalability.
* [Apache ActiveMQ](link)
* [Celery](http://www.celeryproject.org):Distributed Task Queue
* [kr/beanstalkd](https://github.com/kr/beanstalkd):Beanstalk is a simple, fast work queue. http://kr.github.io/beanstalkd/
* 对比
    - 从社区活跃度：按照目前网络上的资料，RabbitMQ 、activeM 、ZeroMQ 三者中，综合来看，RabbitMQ 是首选。
    - 持久化消息比较：ZeroMq 不支持，ActiveMq 和RabbitMq 都支持。持久化消息主要是指我们机器在不可抗力因素等情况下挂掉了，消息不会丢失的机制。
    - 综合技术实现：可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。RabbitMq / Kafka 最好，ActiveMq 次之，ZeroMq 最差。当然ZeroMq 也可以做到，不过自己必须手动写代码实现，代码量不小。尤其是可靠性中的：持久性、投递确认、发布者证实和高可用性。
    - 高并发：毋庸置疑，RabbitMQ 最高，原因是它的实现语言是天生具备高并发高可用的erlang 语言。
    - 比较关注的比较， RabbitMQ 和 Kafka
        + RabbitMq 比Kafka 成熟，在可用性上，稳定性上，可靠性上，  RabbitMq  胜于  Kafka  （理论上）。
        + Kafka 的定位主要在日志等方面， 因为Kafka 设计的初衷就是处理日志的，可以看做是一个日志（消息）系统一个重要组件，针对性很强，所以 如果业务方面还是建议选择 RabbitMq 。
        + Kafka 的性能（吞吐量、TPS ）比RabbitMq 要高出来很多

## 工具

* [apache/pulsar](https://github.com/apache/pulsar):Apache Pulsar - distributed pub-sub messaging system https://pulsar.apache.org
